Notes-project04-comparison.txt


</entry>



<entry [Fri Jun 12 12:14:22 EDT 2009] DELETE ALL CLUSTER JOBS>




qdel `qstat | grep syoung | cut -c 1,2,3,4,5`




</entry>



<entry [Sun Jun  7 23:44:30 EDT 2009] RUN ELAND ON ARTIFICIAL READS AND CONVERT ELAND TO MAQ AND CALL SNPs>



1. 
cd /home/syoung/base/bin/nextgen
./eland.pl \
--inputfile /home/syoung/base/pipeline/herpes-eland/assembly/herpes.fasta \
--outputfile /home/syoung/base/pipeline/herpes-eland/assembly/herpes-eland-contigs.fa \
--refdir /home/syoung/base/pipeline/herpes-eland/data \
--length 30


Convert eland alignment to MAQ .map file

eland2maq	maq eland2maq [-q defqual] out.map in.list in.eland

in.list FILE = sequence names that appear at the seventh column of the eland alignment file in.eland and the name you expect to see in maq alignment.

EXAMPLE OF THE in.list FILE:

  cX.fa chrX
  c1.fa chr1
  c2.fa chr2




TEST
Usage: maq eland2maq [-q qual] <out.map> <in.list> <in.eland>

cd 
/nethome/syoung/base/apps/maq/0.7.1/maq eland2maq 



SOLiD Related

fasta2csfa	maq fasta2csfa in.nucl-ref.fasta > out.colour-ref.fasta
Convert nucleotide FASTA to colour-coded FASTA. Flag -c should be then applied to map command. In the output, letter ‘A’ stands for color 0, ‘C’ for 1, ‘G’ for 2 and ‘T’ for 3. Each sequence in the output is 1bp shorter than the input.

csmap2nt	maq csmap2nt out.nt.map in.ref.nt.bfa in.cs.map
Convert color alignment to nucleotide alignment. The input in.ref.nt.bfa is the nucleotide binary FASTA reference file. It must correspond to the original file from which the color reference is converted. Nucleotide consensus can be called from the resultant alignment.





</entry>



<entry [Sun Jun  7 23:44:30 EDT 2009] TEST ELAND, BOWTIE, MAQ, NOVOALIGN, SOAP AND SHRIMP ON SIMULATE PAIRED END READS GENERATED BY MAQ>



REFERENCE: 	/nethome/syoung/base/pipeline/comparison/maq/CCDS_nucleotide.20090327.fa
READS: 		/nethome/syoung/base/pipeline/comparison/


BOWTIE
------

1. BUILD REFERENCE ebwt FILE FOR BOWTIE

/nethome/syoung/base/apps/bowtie/0.9.4/bowtie-build \
-f /nethome/syoung/base/pipeline/comparison/mtDNA-AC_000021.fa \
/nethome/syoung/base/pipeline/comparison/bowtie/mtDNA-AC_000021.ebwt 
	
	-rw-r--r-- 1 syoung bioinfo 4.1M Jun  8  2009 mtDNA-AC_000021.ebwt.1.ebwt
	-rw-r--r-- 1 syoung bioinfo 2.2K Jun  8  2009 mtDNA-AC_000021.ebwt.2.ebwt
	-rw-r--r-- 1 syoung bioinfo 4.1M Jun  8  2009 mtDNA-AC_000021.ebwt.rev.1.ebwt
	-rw-r--r-- 1 syoung bioinfo 2.2K Jun  8  2009 mtDNA-AC_000021.ebwt.rev.2.ebwt
	
	
2. RUN bowtie

COPY SIMREAD FILES FROM maq TO bowtie FOLDER

cp ../maq/simread_* ./


RUN bowtie
	Usage: bowtie [options]* <ebwt> {-1 <mates1> -2 <mates2> | <singles>} [<hits>] 

cd /nethome/syoung/base/pipeline/comparison/bowtie
/nethome/syoung/base/apps/bowtie/0.9.4/bowtie -q /nethome/syoung/base/pipeline/comparison/bowtie/mtDNA-AC_000021.ebwt /nethome/syoung/base/pipeline/comparison/bowtie/simread_1.fastq,/nethome/syoung/base/pipeline/comparison/bowtie/simread_2.fastq /nethome/syoung/base/pipeline/comparison/bowtie/mtDNA-simread-match.txt

	-rw-r--r-- 1 syoung bioinfo 163G Jun  8  2009 mtDNA-simread-match.txt

VERY LARGE OUTPUT FILE





</entry>



<entry [Sun Jun  7 23:44:30 EDT 2009] GENERATE SIMULATED PAIRED END READS WITH MAQ>



/nethome/syoung/base/bin/nextgen/run-maq.pl --outputdir /nethome/syoung/base/pipeline/comparison/maq --inputfile /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt --referencefile /nethome/syoung/base/pipeline/comparison/CCDS_nucleotide.20090327.fa &> /nethome/syoung/base/pipeline/comparison/maq/s_4_sequence-maq-runlog.txt

1. GENERATE in.simupars.dat

simutrain GENERATES THE FILE in.simupars.dat, WHICH DETERMINES THE READ LENGTHS AND QUALITY

Usage: maq simutrain <simupars.dat> <known_reads.fastq>

time /nethome/syoung/base/apps/maq/0.7.1/maq simutrain /nethome/syoung/base/pipeline/comparison/maq/in.sumupars.dat /nethome/syoung/base/pipeline/comparison/maq/s_4_sequence.txt 

	-rw-r--r-- 1 syoung bioinfo 164K Jun  8  2009 in.sumupars.dat

2. RUN simulate

GENERATE SIMULATED PAIRED END simread_1.fastq AND simread_2.fastq FILES:

cd /nethome/syoung/base/pipeline/comparison/maq 
time /nethome/syoung/base/apps/maq/0.7.1/maq simulate \
-d 170 -s 20 -N 1000000 -1 32 -2 32 -r 0.001 -R 0.1 \
simread_1.fastq simread_2.fastq \
/nethome/syoung/base/pipeline/comparison/maq/mtDNA-AC_000021.fa \
/nethome/syoung/base/pipeline/comparison/maq/in.sumupars.dat \
&> /nethome/syoung/base/pipeline/comparison/maq/simulate-log.txt 

	real    0m24.909s
	user    0m13.625s
	sys     0m4.533s

	-rw-r--r-- 1 syoung bioinfo 113M Jun  8  2009 simread_1.fastq
	-rw-r--r-- 1 syoung bioinfo 113M Jun  8  2009 simread_2.fastq

	
head /nethome/syoung/base/pipeline/comparison/maq/simulate-log.txt 
	
	-- 1 sequences, total length: 16569
	gi|115315570|ref|AC_000021.2|   403     T       K       +
	gi|115315570|ref|AC_000021.2|   482     -       A       -
	gi|115315570|ref|AC_000021.2|   571     C       T       -
	gi|115315570|ref|AC_000021.2|   1695    C       -       +
	gi|115315570|ref|AC_000021.2|   4548    T       W       +
	gi|115315570|ref|AC_000021.2|   4678    T       W       +
	gi|115315570|ref|AC_000021.2|   4798    C       S       +
	gi|115315570|ref|AC_000021.2|   6120    A       R       +
	gi|115315570|ref|AC_000021.2|   6359    A       M       +
	gi|115315570|ref|AC_000021.2|   6920    C       M       +
	gi|115315570|ref|AC_000021.2|   8559    C       Y       +
	gi|115315570|ref|AC_000021.2|   8637    C       T       -
	gi|115315570|ref|AC_000021.2|   9155    A       T       -
	gi|115315570|ref|AC_000021.2|   10000   G       R       +
	gi|115315570|ref|AC_000021.2|   11192   G       A       -
	gi|115315570|ref|AC_000021.2|   12686   T       G       -
	gi|115315570|ref|AC_000021.2|   13486   C       A       -
	gi|115315570|ref|AC_000021.2|   14011   G       C       -





NOTES:


    fakemut     simulate references: randomly generate mutations
    simutrain   train parameters for simulation
    simulate    simulate reads: randomly generate sequencing errors
    simucns     evaluate consensus based on simulation
    simustat    evaluate alignment based on simulation


simulate	maq simulate [-d insize] [-s stdev] [-N nReads] [-1 readLen1] [-2 readLen2] [-r mutRate] [-R indelFrac] [-h] out.read1.fastq out.read2.fastq in.ref.fasta in.simupars.dat

Simulate paired end reads. File in.simupars.dat determines the read lengths and quality distribution. It is generated from simutrain, or can be downloaded from Maq website. In the output read files, a read name consists of the reference sequence name and the outer coordinates of the pair of simulated reads. By default, simulate assumes reads come from a diploid sequence which is generated by adding two different sets of mutations, including one base-pair indels, to in.ref.fasta.

OPTIONS:
-d INT	 mean of the outer distance of insert sizes [170]
-s INT	 standard deviation of insert sizes [20]
-N INT	 number of pairs of reads to be generated [1000000]
-1 INT	 length of the first read [set by in.simupars.dat]
-2 INT	 length of the second read [set by in.simupars.dat]
-r FLOAT	 mutation rate [0.001]
-R FLOAT	 fraction of 1bp indels [0.1]
-h	 add all mutations to in.ref.fasta and generate reads from the single mutated sequence (haploid mode)
NOTE:
*	 Reads generated from this command are independent, which deviates from the truth. Whereas alignment evaluation is less affected by this, evaluation on SNP calling should be performed with caution. Error dependency may be one of the major causes of wrong SNP calls.
simustat	maq simustat in.simu-aln.map > out.simustat
Evaluate mapping qualities from simulated reads.




fakemut	maq fakemut [-r mutrate] [-R indelfrac] in.ref.fasta > out.fakeref.fasta 2> out.fake.snp

Randomly introduce substitutions and indels to the reference. Substitutions and sinlge base-pair indels can be added.

OPTIONS:
-r FLOAT	 Mutation rate [0.001]
-R FLOAT	 Fraction of mutations to be indels [0.1]
simutrain	maq simutrain out.simupars.dat in.read.fastq
Estimate/train parameters for read simulation.


time /nethome/syoung/base/apps/maq/0.7.1/maq fakemut  mtDNA-AC_000021.fa > mtDNA-mut-R0.1-r0.001

	gi|115315570|ref|AC_000021.2|   1294    G       A       99
	gi|115315570|ref|AC_000021.2|   1513    G       A       99
	gi|115315570|ref|AC_000021.2|   2991    G       T       99
	gi|115315570|ref|AC_000021.2|   3583    T       A       99
	gi|115315570|ref|AC_000021.2|   4052    G       C       99
	gi|115315570|ref|AC_000021.2|   5630    G       A       99
	gi|115315570|ref|AC_000021.2|   6794    T       A       99
	gi|115315570|ref|AC_000021.2|   6865    A       T       99
	gi|115315570|ref|AC_000021.2|   8705    C       T       99
	gi|115315570|ref|AC_000021.2|   9233    A       T       99
	gi|115315570|ref|AC_000021.2|   9805    A       C       99
	gi|115315570|ref|AC_000021.2|   10813   A       C       99
	gi|115315570|ref|AC_000021.2|   11286   C       T       99
	gi|115315570|ref|AC_000021.2|   11995   -       C       99
	gi|115315570|ref|AC_000021.2|   12592   A       C       99
	gi|115315570|ref|AC_000021.2|   12999   T       G       99
	gi|115315570|ref|AC_000021.2|   13997   T       C       99
	gi|115315570|ref|AC_000021.2|   14224   G       C       99
	gi|115315570|ref|AC_000021.2|   15970   C       T       99
	
	real    0m0.147s
	user    0m0.004s
	sys     0m0.018s



</entry>



<entry [Thu Jun  4 18:53:47 EDT 2009] RUN TEST OF BOWTIE, MAQ, SOAP, ELAND, ETC ON ngsdev (kronos IS DOWN, NO MOUNT OF pluto)>



http://vancouvershortr.wiki.sourceforge.net/MaqPetToBedFormat


HUMAN mtDNA VS UNKNOWN READS
----------------------------

1. RUN MAQ

/nethome/syoung/base/bin/nextgen/run-maq.pl --outputdir /nethome/syoung/base/pipeline/comparison/maq --inputfile /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt --referencefile /nethome/syoung/base/pipeline/comparison/mtDNA-AC_000021.fa &> /nethome/syoung/base/pipeline/comparison/maq/s_4_sequence-maq-runlog.txt

	Run time: 00:03:08
	Completed /nethome/syoung/base/bin/nextgen/run-maq.pl
	10:42PM, 7 June 2009
	****************************************

PROBLEM:

NO RESULT IN OUTPUT FILES

SOLUTION:

GENERATE SIMULATED READS WITH MAQ (SEE ABOVE)



CCDS VS UNKNOWN READS
---------------------

1. DOWNLOAD CCDS 

CCDS HOMEPAGE
http://www.ncbi.nlm.nih.gov/projects/CCDS/CcdsBrowse.cgi

cd /nethome/syoung/base/pipeline/ccds

CCDS GENOME POSITIONS
wget ftp://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS.20090327.txt

CCDS FASTA
wget ftp://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS_nucleotide.20090327.fna.gz

CCDS REFERENCE LOCATION
/nethome/syoung/base/pipeline/ccds/CCDS_nucleotide.20090327.fna

head /nethome/syoung/base/pipeline/ccds/CCDS_nucleotide.20090327.fna

	>CCDS2.2|Hs36.3|chr1
	ATGTCCAAGGGGATCCTGCAGGTGCATCCTCCGATCTGCGACTGCCCGGGCTGCCGAATA
	TCCTCCCCGGTGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGCCTGCCGCC
	CGGAACCTGAAGAAGGAGCGAACTCCCAGCTTCTCTGCCAGCGATGGTGACAGCGACGGG
	AGTGGCCCCACCTGTGGGCGGCGGCCAGGCTTGAAGCAGGAGGATGGTCCGCACATCCGT
	ATCATGAAGAGAAGAGTCCACACCCACTGGGACGTGAACATCTCTTTCCGAGAGGCGTCC
	TGCAGCCAGGACGGCAACCTTCCCACCCTCATATCCAGCGTCCACCGCAGCCGCCACCTC
	GTTATGCCCGAGCATCAGAGCCGCTGTGAATTCCAGAGAGGCAGCCTGGAGATTGGCCTG
	CGACCCGCCGGTGACCTGTTGGGCAAGAGGCTGGGCCGCTCCCCCCGTATCAGCAGCGAC
	TGCTTTTCAGAGAAGAGGGCACGAAGCGAATCGCCTCAAGAGGCGCTGCTGCTGCCGCGG


2. GET READS FOR TESTING

(183,035 READS)
cp /nethome/syoung/base/pipeline/velvet/s_4_sequence.txt /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt

READS LOCATION
/nethome/syoung/base/pipeline/comparison/s_4_sequence.txt


3. BUILD REFERENCE ebwt FILE FOR BOWTIE

/nethome/syoung/base/apps/bowtie/0.9.4/bowtie-build -f /nethome/syoung/base/pipeline/ccds/CCDS_nucleotide.20090327.fna /nethome/syoung/base/pipeline/comparison/bowtie/CCDS_nucleotide.20090327.ebwt 



4. RUN bowtie

	Usage: bowtie [options]* <ebwt> {-1 <mates1> -2 <mates2> | <singles>} [<hits>] 

#TRIM ONE 3'
/nethome/syoung/base/apps/bowtie/0.9.4/bowtie -q -3 1 /nethome/syoung/base/pipeline/comparison/bowtie/CCDS_nucleotide.20090327.ebwt /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt /nethome/syoung/base/pipeline/comparison/bowtie/match-q-31.txt

#DEFAULT
/nethome/syoung/base/apps/bowtie/0.9.4/bowtie -q /nethome/syoung/base/pipeline/comparison/bowtie/CCDS_nucleotide.20090327.ebwt /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt /nethome/syoung/base/pipeline/comparison/bowtie/match-q.txt


5. RUN MAQ

/nethome/syoung/base/bin/nextgen/run-maq.pl --outputdir /nethome/syoung/base/pipeline/comparison/maq --inputfile /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt --referencefile /nethome/syoung/base/pipeline/comparison/CCDS_nucleotide.20090327.fa &> /nethome/syoung/base/pipeline/comparison/maq/s_4_sequence-maq-runlog.txt
	
	Run time: 00:03:11
	Completed /nethome/syoung/base/bin/nextgen/run-maq.pl
	10:22PM, 7 June 2009
	****************************************



RUN bwa


[syoung@ngsdev 0.4.9]$ ./bwa

Program: bwa (alignment via Burrows-Wheeler transformation)
Version: 0.4.9
Contact: Heng Li <lh3@sanger.ac.uk>

Usage:   bwa <command> [options]

Command: index         index sequences in the FASTA format
         aln           gapped/ungapped alignment
         samse         generate alignment (single ended)
         sampe         generate alignment (paired ended)

         fa2pac        convert FASTA to PAC format
         pac2bwt       generate BWT from PAC
         pac2bwtgen    alternative algorithm for generating BWT
         bwtupdate     update .bwt to the new format
         pac_rev       generate reverse PAC
         bwt2sa        generate SA from BWT and Occ
         pac2cspac     convert PAC to color-space PAC
         stdsw         standard SW/NW alignment








**** BELOW IS A TEST WITH UNKNOWN READS, PROBABLY HUMAN MITOCHONDRIAL




1. DOWNLOAD CCDS 

CCDS HOMEPAGE
http://www.ncbi.nlm.nih.gov/projects/CCDS/CcdsBrowse.cgi

cd /nethome/syoung/base/pipeline/ccds

CCDS GENOME POSITIONS
wget ftp://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS.20090327.txt

CCDS FASTA
wget ftp://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS_nucleotide.20090327.fna.gz

CCDS REFERENCE LOCATION
/nethome/syoung/base/pipeline/ccds/CCDS_nucleotide.20090327.fna

head /nethome/syoung/base/pipeline/ccds/CCDS_nucleotide.20090327.fna

	>CCDS2.2|Hs36.3|chr1
	ATGTCCAAGGGGATCCTGCAGGTGCATCCTCCGATCTGCGACTGCCCGGGCTGCCGAATA
	TCCTCCCCGGTGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGCCTGCCGCC
	CGGAACCTGAAGAAGGAGCGAACTCCCAGCTTCTCTGCCAGCGATGGTGACAGCGACGGG
	AGTGGCCCCACCTGTGGGCGGCGGCCAGGCTTGAAGCAGGAGGATGGTCCGCACATCCGT
	ATCATGAAGAGAAGAGTCCACACCCACTGGGACGTGAACATCTCTTTCCGAGAGGCGTCC
	TGCAGCCAGGACGGCAACCTTCCCACCCTCATATCCAGCGTCCACCGCAGCCGCCACCTC
	GTTATGCCCGAGCATCAGAGCCGCTGTGAATTCCAGAGAGGCAGCCTGGAGATTGGCCTG
	CGACCCGCCGGTGACCTGTTGGGCAAGAGGCTGGGCCGCTCCCCCCGTATCAGCAGCGAC
	TGCTTTTCAGAGAAGAGGGCACGAAGCGAATCGCCTCAAGAGGCGCTGCTGCTGCCGCGG


2. GET READS FOR TESTING

(183,035 READS)
cp /nethome/syoung/base/pipeline/velvet/s_4_sequence.txt /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt

READS LOCATION
/nethome/syoung/base/pipeline/comparison/s_4_sequence.txt

head /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt
	@HWI-EAS185_1_JIA_cDNA_JH:4:150:316:264
	TCAGTTCCATCAACATCATAGCCAGATGCCCTGA
	+HWI-EAS185_1_JIA_cDNA_JH:4:150:316:264
	]]]]]]]]]]]]]]]]][]]]]]]][][[[[[[Z
	@HWI-EAS185_1_JIA_cDNA_JH:4:150:660:361
	CGCTCTCCGTCTTTCTCCATTGCGTCGTGGCCTT
	+HWI-EAS185_1_JIA_cDNA_JH:4:150:660:361
	]][X]]]]][]]][][]]][]]]]]]][]]ZWZZ
	@HWI-EAS185_1_JIA_cDNA_JH:4:150:355:335
	TTTTTGAGATGGCAGCAACGGAAACCATAACGAG


3. BUILD REFERENCE ebwt FILE FOR BOWTIE

/nethome/syoung/base/apps/bowtie/0.9.4/bowtie-build -f /nethome/syoung/base/pipeline/ccds/CCDS_nucleotide.20090327.fna /nethome/syoung/base/pipeline/comparison/bowtie/CCDS_nucleotide.20090327.ebwt 

OUTPUT FILES:

ll /nethome/syoung/base/pipeline/comparison/bowtie
	-rw-r--r-- 1 syoung bioinfo  17M Jun  7  2009 CCDS_nucleotide.20090327.ebwt.1.ebwt
	-rw-r--r-- 1 syoung bioinfo 4.3M Jun  7  2009 CCDS_nucleotide.20090327.ebwt.2.ebwt
	-rw-r--r-- 1 syoung bioinfo  17M Jun  7  2009 CCDS_nucleotide.20090327.ebwt.rev.1.ebwt
	-rw-r--r-- 1 syoung bioinfo 4.3M Jun  7  2009 CCDS_nucleotide.20090327.ebwt.rev.2.ebwt
	

	./bowtie-build
	No input sequence or sequence file specified!
	Usage: bowtie-build [options]* <reference_in> <ebwt_outfile_base>
		reference_in            comma-separated list of files with ref sequences
		ebwt_outfile_base       write Ebwt data to files with this dir/basename
	Options:
		-f                      reference files are Fasta (default)
		-c                      reference sequences given on cmd line (as <seq_in>)
		--bmax <int>            max bucket sz for blockwise suffix-array builder
		--bmaxmultsqrt <int>    max bucket sz as multiple of sqrt(ref len)
		--bmaxdivn <int>        max bucket sz as divisor of ref len
		--dcv <int>             diff-cover period for blockwise (default: 1024)
		--nodc                  disable difference cover (blockwise is quadratic)
		-o/--offrate <int>      SA index is kept every 2^offRate BWT chars
		-t/--ftabchars <int>    # of characters in initial lookup table key
		--big --little          endianness (default: little, this host: little)
		--seed <int>            seed for random number generator
		--cutoff <int>          truncate reference at prefix of <int> bases
		-v/--verbose            verbose output (for debugging)
		--version               print version information and quit



4. RUN bowtie

	Usage: bowtie [options]* <ebwt> {-1 <mates1> -2 <mates2> | <singles>} [<hits>] 

/nethome/syoung/base/apps/bowtie/0.9.4/bowtie -q /nethome/syoung/base/pipeline/comparison/bowtie/CCDS_nucleotide.20090327.ebwt /nethome/syoung/base/pipeline/comparison/s_4_sequence.txt /nethome/syoung/base/pipeline/comparison/bowtie/match.txt

OUTPUT FILE (ONLY ONE LINE!!):

ll /nethome/syoung/base/pipeline/comparison/bowtie/match.txt
	-rw-r--r-- 1 syoung bioinfo      143 Jun  7  2009 match.txt

head match.txt 
	HWI-EAS185_1_JIA_cDNA_JH:4:157:364:45   +       CCDS8596.2|Hs36.3|chr12 1696    TCTCCCCCTCCCAGCAGCTTCCAGGAGCAGAAGT      ]]]]]]]]]]]]]]]]]]]]]][]]]]][]\[[Z 0



	Usage: bowtie [options]* <ebwt_base> <query_in> [<hit_outfile>]
	  <ebwt_base>        ebwt filename minus trailing .1.ebwt/.2.ebwt
	  <query_in>         comma-separated list of files containing query reads
						 (or the sequences themselves, if -c is specified)
	  <hit_outfile>      file to write hits to (default: stdout)
	Options:
	  -q                 query input files are FASTQ .fq/.fastq (default)
	  -f                 query input files are (multi-)FASTA .fa/.mfa
	  -r                 query input files are raw one-sequence-per-line
	  -c                 query sequences given on command line (as <query_in>)
	  -e/--maqerr <int>  max sum of mismatch quals (rounds like maq; default: 70)
	  -l/--seedlen <int> seed length (default: 28)
	  -n/--seedmms <int> max mismatches in seed (can be 0-3, default: 2)
	  -v <int>           report end-to-end hits w/ <=v mismatches; ignore qualities
	  -5/--trim5 <int>   trim <int> bases from 5' (left) end of reads
	  -3/--trim3 <int>   trim <int> bases from 3' (right) end of reads
	  -u/--qupto <int>   stop after the first <int> reads
	  -t/--time          print wall-clock time taken by search phases
	  --solexa-quals     convert FASTQ qualities from solexa-scaled to phred
	  --ntoa             Ns in reads become As; default: Ns match nothing
	  --concise          write hits in a concise format
	  --maxns <int>      skip reads w/ >n no-confidence bases (default: no limit)
	  -o/--offrate <int> override offrate of Ebwt; must be <= value in index
	  --seed <int>       seed for random number generator
	  --verbose          verbose output (for debugging)
	  --version          print version information and quit


5. CONVERT BOWTIE OUTPUT TO 


5. RUN MAQ





</entry>



<entry [Thu Jun  4 18:53:47 EDT 2009] RUN WHOLE SAMPLING PIPELINE USING Sampler.pm>



fastaInfos
-----------

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 \
--cluster \
--queue "-q psmall" \
--jobs 10

	OK

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 \
--cluster \
--queue "-q psmall" \
--jobs 10
	
	Run time: 00:47:36
	Completed /nethome/syoung/base/bin/comparison/fastaInfos.pl
	2:37AM, 5 June 2009
	****************************************

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 \
--cluster \
--queue "-q psmall" \
--jobs 50

	OK

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 \
--cluster \
--queue "-q psmall" \
--jobs 50

	RUNNING Fri Jun  5 01:47:53 EDT 2009
	Run time: 00:06:43
	Completed /nethome/syoung/base/bin/comparison/fastaInfos.pl
	1:53AM, 5 June 2009
	****************************************

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 \
--cluster \
--queue "-q psmall" \
--jobs 20

	RUNNING Fri Jun  5 01:47:53 EDT 2009
	Run time: 00:45:25
	Completed /nethome/syoung/base/bin/comparison/fastaInfos.pl
	2:33AM, 5 June 2009
	****************************************

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 \
--cluster \
--queue "-q psmall" \
--jobs 20

	RUNNING Fri Jun  5 01:47:53 EDT 2009
	Run time: 00:25:51
	Completed /nethome/syoung/base/bin/comparison/fastaInfos.pl
	2:15AM, 5 June 2009
	****************************************

	
	
listFiles
---------

RERUN Fri Jun 12 01:30:50 EDT 2009

screen -S listFiles

/nethome/syoung/base/bin/comparison/listFiles.pl \
--inputdir \
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta \
--size 100000000 \
&> /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/listfiles.out5


tail -f /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/listfiles.out5

/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/SRR00227/SRR002272_1.fasta.37.list


	Run time: 02:19:02
	Completed /nethome/syoung/base/bin/comparison/listFiles.pl
	4:13AM, 12 June 2009
	****************************************


	total: 111737062
	
	directory       total reads
	SRX000600/fasta 2902742286
	SRX000603/fasta 111737062
	SRX000602/fasta 243457620
	SRX001540/fasta 192132426
	SRX000601/fasta 52767544
	
	global reads: 3502836938
	
	directory       fraction
	SRX000600/fasta 0.828683246573666
	SRX000603/fasta 0.0318990189888194
	SRX000602/fasta 0.0695029840980853
	SRX001540/fasta 0.0548505195647791
	SRX000601/fasta 0.0150642307746499



# CLEAN UP THE DIRECTORIES TO RUN listFiles.pl AGAIN

/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507

cd SRX001539
mv fasta fasta.bkp5
mkdir fasta
mv fasta.bkp5/*fasta fasta
mv fasta.bkp5/*qual fasta
mv fasta.bkp5/*info fasta
cd ..
ll SRX001539/fasta


cd SRX001540
mv fasta fasta.bkp5
mkdir fasta
mv fasta.bkp5/*fasta fasta
mv fasta.bkp5/*qual fasta
mv fasta.bkp5/*info fasta
cd ..
ll SRX001540/fasta


cd SRX000600
mv fasta fasta.bkp5
mkdir fasta
mv fasta.bkp5/*fasta fasta
mv fasta.bkp5/*qual fasta
mv fasta.bkp5/*info fasta
cd ..
ll SRX000600/fasta


cd SRX000601
mv fasta fasta.bkp5
mkdir fasta
mv fasta.bkp5/*fasta fasta
mv fasta.bkp5/*qual fasta
mv fasta.bkp5/*info fasta
cd ..
ll SRX000601/fasta


cd SRX000602
mv fasta fasta.bkp5
mkdir fasta
mv fasta.bkp5/*fasta fasta
mv fasta.bkp5/*qual fasta
mv fasta.bkp5/*info fasta
cd ..
ll SRX000602/fasta


cd SRX000603
mv fasta fasta.bkp5
mkdir fasta
mv fasta.bkp5/*fasta fasta
mv fasta.bkp5/*qual fasta
mv fasta.bkp5/*info fasta
cd ..
ll SRX000603/fasta


printFiles
----------

cd /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507
SRX001539/1539-printFiles.sh &> 1539-printFiles.out
SRX001540/1540-printFiles.sh &> 1540-printFiles.out
SRX000600/0600-printFiles.sh &> 0600-printFiles.out
SRX000601/0601-printFiles.sh &> 0601-printFiles.out
SRX000602/0602-printFiles.sh &> 0602-printFiles.out
SRX000603/0603-printFiles.sh &> 0603-printFiles.out


SRX001539/1539-printFiles.sh &> 1539-printFiles.out

	FASTQ
	Run time: 01:06:29
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	1:27PM, 12 June 2009
	****************************************

SRX001540/1540-printFiles.sh &> 1540-printFiles.out
	
	FASTQ
	Run time: 00:14:53
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	3:49PM, 12 June 2009
	****************************************

SRX000600/0600-printFiles.sh &> 0600-printFiles.out

	FASTQ
	Run time: 01:46:59
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	10:42AM, 12 June 2009
	****************************************

SRX000601/0601-printFiles.sh &> 0601-printFiles.out

	FASTA
	Run time: 00:36:45
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	12:55AM, 12 June 2009
	****************************************

	QUAL
	Run time: 00:43:58
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	1:39PM, 12 June 2009
	****************************************
	
	FASTQ
	Run time: 00:48:58
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	2:28PM, 12 June 2009
	****************************************


SRX000602/0602-printFiles.sh &> 0602-printFiles.out

	FASTQ
	Run time: 01:03:27
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	3:06PM, 12 June 2009
	****************************************

SRX000603/0603-printFiles.sh &> 0603-printFiles.out
	
	FASTQ
	Run time: 01:14:04
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	3:28PM, 12 June 2009
	****************************************





EXAMPLE SRX001539/sampler-1539.sh:

#!/bin/sh

#PBS -j oe
###PBS -m b
###PBS -M syoung@med.miami.edu


/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples \
--mode fasta \
--cluster \
--queue "-q psmall" 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples \
--mode qual \
--cluster \
--queue "-q psmall" 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples \
--mode fastq \
--cluster \
--queue "-q psmall" 





mergeFiles
----------


/nethome/syoung/base/bin/comparison/mergeFiles.pl \
--inputdir \
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta,\
/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples \
--mode fasta





TEST
----

fastaInfos
----------

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test2 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

listFiles
---------

/nethome/syoung/base/bin/comparison/listFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--size 10000

printFiles
----------

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/samples \
--mode fasta \
--cluster \
--queue "-q psmall" 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/samples \
--mode qual \
--cluster \
--queue "-q psmall" 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/samples \
--mode fastq \
--cluster \
--queue "-q psmall" 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--mode fasta \
--cluster \
--queue "-q psmall" 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--mode qual \
--cluster \
--queue "-q psmall" 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--mode fastq \
--cluster \
--queue "-q psmall" 


mergeFiles
----------

/nethome/syoung/base/bin/comparison/mergeFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/samples \
--mode fastq




</entry>



<entry [Wed June  3 23:29:43 EDT 2009] RUN NEW VERSION OF printFile.pl (PRINTS FIRST TO LOCAL TEMPDIR):>



1. KILLED RUNNING VERSION

/nethome/syoung/base/bin/comparison/printFiles.pl --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta --outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples --cluster --queue "-q psmall" --mode qual >&printFiles-qual.out


2. KILL ALL RUNNING QUEUE JOBS

qdel `qstat | grep syoung | cut -c 1,2,3,4,5`


3. RUN NEW VERSION OF printFile.pl

cd /mihg/data/NGS/syoung/base/pipeqstatline/SRA/NA18507/SRX000600
emacs printFile.sh
#!/bin/sh

#PBS -j oe
#PBS -m bea
#PBS -M syoung@med.miami.edu

echo "Running printFile..."
/home/syoung/base/bin/comparison/printFile.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/SRR004829_2.fasta --outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples --mode qual --width 60 --dot 100000
echo "printFile completed."
echo "Sleeping 300 seconds..."
sleep 300;
echo "done."


qsub -q psmall printFile.sh






</entry>



<entry [Mon June  1 23:29:43 EDT 2009] KILL ALL gsmall JOBS AND RUN WITH psmall>



KILL ALL gsmall JOBS:

qdel `qstat | grep syoung | grep "Q gsmall" | cut -c 1,2,3,4,5`


RUN JOBS WITH psmall

/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--compress gzip \
--cluster \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10  &> fastaInfos.out

	Run time: 02:26:53
	Completed /nethome/syoung/base/bin/comparison/fastaInfos.pl
	4:04AM, 2 June 2009
	****************************************


/nethome/syoung/base/bin/comparison/listFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples \
--mode samples \
--size 10000000 &> listFiles.out

	Run time: 01:41:39
	Completed /nethome/syoung/base/bin/comparison/listFiles.pl
	5:46AM, 2 June 2009
	****************************************


/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples \
--cluster \
--mode fasta &> printFiles-fasta.out

	
	Run time: 18:02:55
	Completed /nethome/syoung/base/bin/comparison/printFiles.pl
	11:49PM, 2 June 2009
	****************************************


/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples \
--cluster \
--queue "-q psmall" \
--mode qual  &> printFiles-qual.out

	NOT FINISHED


/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRA/NA18507/SRX000600/fasta/SRR002271_1.fasta.sh


/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/samples \
--cluster \
--queue "-q psmall" \
--mode fastq &> printFiles-fastq.out






</entry>



<entry [Mon June  1 23:29:43 EDT 2009] MAKE NODE c26 SLEEP TO EXCLUDE FROM JOB>




NB: THIS REQUESTS 26 NODES

echo sleep 600 | qsub -l nodes=26:ppn=8

###echo sleep 600 | qsub -l nodes=26:ppn=8,walltime=1000


How do I exclude a node from running a job?


Sometimes one need to be able to exclude a node from running a job.
Sometimes it is useful to exclude a specific node from running your jobs. This can be due to hardware or software problems on that node. For instance the node seems to have problems with the interconnect.

The simplest way to do this is to submit a dummy job to this node:

echo sleep 600 | qsub -lnodes=cX-Y:ppn=8,walltime=1000


Then this job will be running a sleep job for 600 seconds and you can submit your real job afterwards that will run on other nodes. This will cost you some cpu hours off your quota, but let us know and we will refund this to you later.

Please let us know if you think some nodes have problems.


[syoung@ngsdev SRX001539]$ qsub -q psmall samplePrep.sh
40553.kronos.ccs.miami.edu
[syoung@ngsdev SRX001539]$ date
Mon Jun  1 14:27:56 EDT 2009



</entry>



<entry [Fri May 29 04:29:43 EDT 2009] RUN ELAND>



1. RUN elandChromosomes.pl WITH runSamples.pl


/nethome/syoung/base/bin/comparison/elandChromosomes.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed \
--readfile /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/reads.1-12.fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/eland \
--length 36 \
--multi 



TEST elandChromosomes.pl

/nethome/syoung/base/bin/comparison/elandChromosomes.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed \
--readfile /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/reads.1-12.fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/eland \
--length 36 \
--multi 

	...
	Comment: >chr4
	finished making FileReader
	Finishing block: 13
	... done User: 30.8553s System: 0.041993s Actual: 31.073s Efficiency: 99.4345%
	FileReader: unmapping 47815680 bytes of memory
	FileReader: unmapping 366 bytes of memory
	Will look for index file /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr4/chr4.fa.idx
	... not found, will not index
	Outputting results: User: 0s System: 0.002s Actual: 0.01023s Efficiency: 19.5503%
	Info: 124420 matches were stored
	Info: 497680 bytes of temp storage used for oligo numbers
	Info: 497680 bytes of temp storage used for match positions
	... done User: 0.096985s System: 0.008999s Actual: 0.107851s Efficiency: 98.2689%
	Run complete! Time now: Fri May 29 04:27:38 2009
	
	Run time: 00:01:31
	Completed /home/syoung/base/bin/comparison/../nextgen/eland.pl
	4:27AM, 29 May 2009
	****************************************




</entry>



<entry [Thu May 28 23:26:52 EDT 2009] INSTALL ALIGNERS - SOAP, SHRimP, Bowtie, Novoalign>




ELAND
MAQ
SOAP
Mosaik
SHRimP		OK
Novoalign
Bowtie


At different coverages:

total coverage: 38X
global reads: 3,498,519,123
batches: 	50M reads x 70
			20M reads x 175 
			10M reads x 350 

OApprox file sizes (36 bp reads)
1 million reads = 15 MB
10 million reads = 150 MB
100 million reads = 1.5 GB


Coverage vs reads

3.5 B reads = 38X
2.9 B reads = 30X
1.8 B reads = 20X
0.9 B reads = 10X
0.45 B reads = 5X


On reads from these genomes:

NA18507 genome
Yanhuang genome
X chromosome (NA073540???)
Complete genomics Cau
Other deep-coverage SRA genomes?


Evaluate SNP callers:

MAQ             
CASSAVA         
SSAHASNP        http://www.sanger.ac.uk/Software/analysis/ssahaSNP/
PolyBayesShort  http://bioinformatics.bc.edu/marthlab/PbShort


Later:

Create an application for detecting large chromosomal rearrangments using different sets of reads (paired with varying insert, single)


</entry>



<entry [Thurs May 28 23:02:26 EDT 2009] DATA PREPARATION PIPELINE - TWO STEPS>



TEST readsFastqFasta.pl

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 


TEST sampleReads.pl

/nethome/syoung/base/bin/comparison/sampleReads.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta1 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta1/sample \
--compress gzip \
--mode samples \
--size 60000 \
&> /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/sample/sampleReads.out




</entry>



<entry [Wed May 27 23:02:26 EDT 2009] DATA PREPARATION PIPELINE>



1. DOWNLOAD NA18507 READS
2. RUN fastaInfos.pl TO CREATE FIXED-LENGTH FASTA, QUAL AND info FILES
3. RUN listFiles.pl TO RANDOMLY SAMPLE FASTA AND QUAL RECORDS
3. RUN printFiles.pl TO GENERATE RANDOMLY SAMPLED FASTA AND QUAL FILES


1. DOWNLOAD NA18507 READS

SHOULD GET THESE NUMBERS OF FILES

/nethome/syoung/base/bin/comparison/sampleReads.pl --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta --compress gzip --mode total
Number files: 367
Total reads: 2794499393

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta 
Number files: 10
Total reads: 52767544

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta 
Number files: 34
Total reads: 243457620

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta 
Number files: 12
Total reads: 111737062

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/f
asta 
Number files: 4
Total reads: 103925078

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta 
Number files: 8
Total reads: 192132426


DOWNLOAD ON PLUTO:

cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507

screen -S deepvac-SRX000600
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl \
--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600 \
--outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600

	ONGOING

screen -S deepvac-SRX000601
cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl \
--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000601 \
--outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601

	Run time: 00:22:46
	Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
	0:38AM, 28 May 2009
	****************************************


screen -S deepvac-SRX000602
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl \
--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000602 \
--outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602

	Run time: 01:39:45
	Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
	2:18AM, 28 May 2009
	****************************************

screen -S deepvac-SRX000603
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl \
--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000603 \
--outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603


cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
mkdir SRX001539
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl \
--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX001539 \
--outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539

	Run time: 00:25:57
	Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
	10:43AM, 28 May 2009
	****************************************

cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
mkdir SRX001540
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl \
--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX001540 \
--outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540
	
	Run time: 00:33:49
	Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
	1:14PM, 28 May 2009
	****************************************




###ON MENDEL3
###
###NO CONTENTS!!!
###screen -S deepvac-SRX000600
###/nethome/syoung/base/bin/utils/deepvac.pl \
###--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600 \
###--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600
###
###NO CONTENTS!!!
###screen -S deepvac-SRX000602
###/nethome/syoung/base/bin/utils/deepvac.pl \
###--url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000602 \
###--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602




----------
2. RERUN fileInfos.pl TO CREATE FIXED-LENGTH FASTA, QUAL AND info FILES


1539 
----

screen -S readsFq-1539

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta \
--compress gzip \
--cluster \
--jobs 10 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

	COMPLETED

1540 
----

screen -S readsFq-1540

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--compress gzip \
--cluster \
--jobs 10 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

	COMPLETED

0601
----

screen -S readsFq-0601

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta \
--compress gzip \
--cluster \
--jobs 8 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

	RUNNING
	Fri May 29 04:51:45 EDT 2009
	Current pids list: 38210 38211 38212 38213 38214 38215 38216 38217
	Doing sleep...


0602
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta \
--compress gzip \
--cluster \
--jobs 8 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

	RUNNING
	Fri May 29 04:49:39 EDT 2009
	
	Job id                    Name             User            Time Use S Queue
	------------------------- ---------------- --------------- -------- - -----
	38194.kronos              ...1.fastq.gz.sh syoung                 0 R psmall         
	38195.kronos              ...2.fastq.gz.sh syoung                 0 R psmall         
	38196.kronos              ...1.fastq.gz.sh syoung                 0 R psmall         
	38197.kronos              ...2.fastq.gz.sh syoung                 0 Q psmall         
	38198.kronos              ...1.fastq.gz.sh syoung                 0 Q psmall         
	38199.kronos              ...2.fastq.gz.sh syoung                 0 Q psmall         
	38200.kronos              ...1.fastq.gz.sh syoung                 0 Q psmall         
	38201.kronos              ...2.fastq.gz.sh syoung                 0 Q psmall         


0603
----

screen -S readsFq-0603

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta \
--compress gzip \
--cluster \
--jobs 8 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

	RUNNING
	Fri May 29 04:51:08 EDT 2009

0600
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--compress gzip \
--cluster \
--jobs 60 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

	COMPLETED




DO TEST :


/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta \
--cluster \
--jobs 60 \
--queue "-q psmall" \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 


/nethome/syoung/base/bin/comparison/fastaInfos.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test2 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--cluster \
--jobs 60 \
--queue "-q psmall" \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 






3. RUN listFiles.pl TO GENERATE RANDOMIZED LISTS OF READ BYTE POSITIONS IN FASTA FILES


TESTING - REQUEST 8 CPUS TO RUN TESTS

msub -I -l nodes=1:ppn=8 -q gdebug

	qsub: waiting for job 39355.kronos.ccs.miami.edu to start
	qsub: job 39355.kronos.ccs.miami.edu ready
	
	[syoung@c22 ~]$ 


/nethome/syoung/base/bin/comparison/listFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta/samples \
--mode samples \
--size 100000000




/nethome/syoung/base/bin/comparison/listFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/samples \
--mode samples \
--size 10000

	OK








4. RUN printFiles.pl TO PRINT FASTA, QUAL AND FASTQ FILES


/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/samples \
--mode fasta \
--size 10000 


/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/samples \
--mode qual \
--size 10000 

/nethome/syoung/base/bin/comparison/printFiles.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/test2/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test/fasta/samples \
--mode fastq \
--size 10000 







emacs /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA18507-10M/sampleReads-10M.sh 

#!/bin/sh

/nethome/syoung/base/bin/comparison/sampleReads.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA18507-10M \
--compress gzip \
--mode samples \
--size 10000000 \
&> /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA18507-10M/sampleReads.out


qsub -q psmall /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA18507-10M/sampleReads-10M.sh 


	39362.kronos.ccs.miami.edu
	Sat May 30 01:19:41 EDT 2009


KILL ALL gsmall JOBS:

qdel `cat mshow | grep syoung | grep Idle | cut -c 1,2,3,4,5`






</entry>



<entry [Wed May 27 00:00:30 EDT 2009] RUN sampleReads.pl ON NA18507 DATA>



1. ALL FOLDERS
2. 10M READ CHUNKS
3. OUTPUT TO /mihg/data/NGS/syoung/base/pipeline/SRA/samples/NA17507-10M

mkdir -p /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA17507-10M
cd /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA17507-10M

emacs sampleReads.sh

#!/bin/sh

/nethome/syoung/base/bin/comparison/sampleReads.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA17507-10M \
--compress gzip \
--mode samples \
--size 10000000 \
&> /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/NA17507-10M/sampleReads.out


chmod 755 sampleReads.sh

qsub -q psmall sampleReads.sh

36205.kronos.ccs.miami.edu
Wed May 27 16:51:22 EDT 2009


	directory       total reads
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta 2794499393
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta 111737062
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta 243457620
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta 192132426
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta 103925078
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta 52767544
	global reads: 3,498,519,123
	directory       fraction
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta 0.798766362209763
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta 0.0319383882355872
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta 0.0695887635426825
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta 0.0549182151776393
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta 0.0297054480327904
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta 0.0150828228015377
	Generating read list files...


[syoung@kronos NA17507-10M]$ qstat -f 36205
Job Id: 36205.kronos.ccs.miami.edu
    Job_Name = sampleReads.sh
    Job_Owner = syoung@kronos.ccs.miami.edu
    resources_used.cput = 00:03:41
    resources_used.mem = 13044kb
    resources_used.vmem = 220256kb
    resources_used.walltime = 00:05:15
    job_state = R
    queue = psmall
    server = kronos.ccs.miami.edu
    Checkpoint = u
    ctime = Wed May 27 17:05:21 2009
    Error_Path = kronos.ccs.miami.edu:/mihg/data/NGS/syoung/base/pipeline/SRA/
        NA18507/samples/NA17507-10M/sampleReads.sh.e36205
    exec_host = n10/0
    Hold_Types = n
    Join_Path = n
    Keep_Files = n
    Mail_Points = a
    mtime = Wed May 27 17:05:24 2009
    Output_Path = kronos.ccs.miami.edu:/mihg/data/NGS/syoung/base/pipeline/SRA
        /NA18507/samples/NA17507-10M/sampleReads.sh.o36205
    Priority = 0
    qtime = Wed May 27 17:05:21 2009
    Rerunable = True
    session_id = 21870
    Variable_List = PBS_O_HOME=/nethome/syoung,PBS_O_LANG=en_US.UTF-8,
        PBS_O_LOGNAME=syoung,
        PBS_O_PATH=/sw/bin:/nethome/syoung/base/bin:/usr/X11R6/bin:/nethome/s
        young/base/bin/utils:/home/syoung/base/bin/nextgen:/home/syoung/base/a
        pps/amos/bin:/usr/local/qt/bin:/home/apps/alta-cyclic/0.1.0/external.p
        rograms/libsvm-2.86:/home/apps/alta-cyclic/0.1.0/blat/bin/i386:/home/a
        pps/alta-cyclic/0.1.0/perlmods/lib64/perl5/site_perl/5.8.8/x86_64-linu
        x-thread-multi/auto:/home/apps/alta-cyclic/0.1.0/perlexternal:/home/bi
        oinfo/apps/ngs/bin/nextgen:/home/bioinfo/apps/ngs/bin/exome:/home/bioi
        nfo/apps/ngs/bin/utils:/home/bioinfo/apps/ngs/bin:/usr/local/bin:/bin:
        /usr/bin,PBS_O_MAIL=/var/spool/mail/syoung,PBS_O_SHELL=/bin/bash,
        PBS_SERVER=kronos.ccs.miami.edu,PBS_O_HOST=kronos.ccs.miami.edu,
        PBS_O_WORKDIR=/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples
        /NA17507-10M,PBS_O_QUEUE=psmall
    etime = Wed May 27 17:05:21 2009
    submit_args = -q psmall sampleReads.sh 


</entry>



<entry [Wed May 27 00:00:30 EDT 2009] TROUBLESHOOTING sampleReads.pl>




CHECK RECORDS IN .fasta.gz FILES:

/nethome/syoung/base/bin/comparison/getIndex.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta/SRR005720_1.fasta.gz --width 57 --index 27157344 --compress gzip

	>SRR005720.1          
	GGGGGAAATTCACTCCTGTGAAATTGCCTACGCA

PRINTED FASTA SMALL FILE:

/nethome/syoung/base/bin/utils/getFasta.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta.1-6.fasta --id SRR005720.1

cd /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540
grep -n SRR005720.1 fasta.1-6.fasta

	18095624:>SRR005720.1          
	65145940:>SRR005720.1


GET LINES FROM PRINTED FASTA FILE:

/nethome/syoung/base/bin/utils/getLines.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta.1-6.fasta --number 18095624 --lines 20

	>SRR005734.4009523    
	GCAGCTT
	>SRR005720.1          
	GGGGGAAATTCACTCCTGTGAAATTGCCTACGCA
	TA
	>SRR005720.2          
	AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
	AAAAA
	>SRR005720.3          
	GAAAATATAAGTTGACCCCTAACTAGGG
	TTGCCCCA
	>SRR005720.4          
	GTTTCAGGAGATTGCAGTCTGAATG
	TTGGCTGGGTC
	>SRR005720.5          
	GGTGTTTTTTTTTTTCTTTTAT
	TTCTTTTTCTCCAT
	>SRR005720.6          
	GGGAGGAAATTAGTTCATG
	AGGGTAGACACAGCTGA
	
	
	TIDIED UP:
	
	>SRR005734.4009523    
	GCAGCTT
	>SRR005720.1          
	GGGGGAAATTCACTCCTGTGAAATTGCCTACGCATA
	>SRR005720.2          
	AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
	>SRR005720.3          
	GAAAATATAAGTTGACCCCTAACTAGGGTTGCCCCA
	>SRR005720.4          
	GTTTCAGGAGATTGCAGTCTGAATGTTGGCTGGGTC
	>SRR005720.5          
	GGTGTTTTTTTTTTTCTTTTATTTCTTTTTCTCCAT
	>SRR005720.6          
	GGGAGGAAATTAGTTCATGAGGGTAGACACAGCTGA


/nethome/syoung/base/bin/utils/getLines.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta.1-6.fasta --number 65145938 --lines 20

	>SRR005720.1          
	GCATTTCTGTGAAAACTGCATAGCAGGATCATGT
	GA
	>SRR005720.2          
	AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
	AAAAA
	>SRR005720.3          
	ACTCATCATTTTTAATGTAAGTATGTTT
	CATGCAAT
	>SRR005720.4          
	TGCAGAAGAAAAGATTGGAGCTAGC
	AGAGCTTGGTT
	>SRR005720.5          
	ATGACATGATACTGCAAATTCC
	ACAGGGCAGGCAAA
	>SRR005720.6          
	TTAAAGTATATATAGGATT
	TTATAGTTTTTGTACTT
	>SRR005720.7          
	AACATAAGCAGATTGT


FIND THE SAME RECORDS IN THE ORIGINAL FASTA FILE:

/nethome/syoung/base/bin/utils/getFasta.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta/SRR005720_1.fasta.gz --id SRR005720.1 --compress




SRX001540
---------
[syoung@kronos fasta]$ tail -n 1 SRR0057*_*.fasta.gz.1.list


==> SRR005720_1.fasta.gz.1.list <==
1259078073

==> SRR005720_2.fasta.gz.1.list <==
1259077959

==> SRR005721_1.fasta.gz.1.list <==
575506143

==> SRR005721_2.fasta.gz.1.list <==
575506086

==> SRR005734_1.fasta.gz.1.list <==
1202856465

==> SRR005734_2.fasta.gz.1.list <==
1202856465

==> SRR005735_1.fasta.gz.1.list <==
1586469258

==> SRR005735_2.fasta.gz.1.list <==
	1586469087

SRX001539
---------

==> SRR005718_1.fasta.gz.1.list <==
1547968608

==> SRR005718_2.fasta.gz.1.list <==
1547968437

==> SRR005719_1.fasta.gz.1.list <==
953119857

==> SRR005719_2.fasta.gz.1.list <==
953119857


</entry>



<entry [Mon May 25 17:25:09 EDT 2009] SAMPLE READS WITH sampleReads.pl FOR NA18507>



/nethome/syoung/base/bin/comparison/sampleReads.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--compress gzip \
--mode samples \
--size 100000000


/nethome/syoung/base/bin/comparison/sampleReads.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--compress gzip \
--mode samples \
--size 100000000


/nethome/syoung/base/bin/comparison/sampleReads.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta,/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/1539,1540-50M \
--compress gzip \
--mode samples \
--size 50000000

	WITHOUT MERGE

	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta.5-6.fasta
	/mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta.6-6.fasta
	Finished generating fasta files
	
	Run time: 00:15:03
	Completed /nethome/syoung/base/bin/comparison/sampleReads.pl
	5:25PM, 26 May 2009
	****************************************

	MERGE ONLY
	
	Run time: 00:10:04
	Completed /nethome/syoung/base/bin/comparison/sampleReads.pl
	7:08PM, 26 May 2009
	****************************************
	
	
	cd  /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/samples/1539,1540-50M/
	[syoung@kronos 1539,1540-50M]$ ls -alh
	total 16G
	drwxrwx---+ 2 syoung bioinfo 4.0K May 26 18:59 .
	drwxrwx---+ 4 syoung bioinfo   45 May 26 18:48 ..
	-rw-rw----+ 1 syoung bioinfo 2.8G May 26 18:51 reads.1-6.fasta
	-rw-rw----+ 1 syoung bioinfo 2.8G May 26 18:52 reads.2-6.fasta
	-rw-rw----+ 1 syoung bioinfo 2.8G May 26 18:55 reads.3-6.fasta
	-rw-rw----+ 1 syoung bioinfo 2.8G May 26 18:57 reads.4-6.fasta
	-rw-rw----+ 1 syoung bioinfo 2.8G May 26 18:59 reads.5-6.fasta
	-rw-rw----+ 1 syoung bioinfo 2.5G May 26 19:01 reads.6-6.fasta



/nethome/syoung/base/bin/comparison/sampleReads.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/test,/mihg/data/NGS/syoung/base/pipeline/SRA/test2 \
--compress gzip \
--mode samples \
--size 100000000





	SUBROUTINE		samples
	
	PURPOSE
	
		EXTRACT FASTA RECORDS FROM FILES IN THE INPUT DIRECTORY

			1. GET READ COUNTS AND RECORD LENGTHS FROM .info FILES
			
			1. GENERATE READ LISTS FOR divide PORTIONS PER FILE WITH RANDOMISER

				1) PRINT divide NUMBER OF .N.readlist FILES PER .info FILE,
				
					ONE READ LOCATION PER LINE
				
			2. GENERATE SAMPLED .N.fasta FILES FROM .N.readlist FILES, ONE
			
				FOR EACH ORIGINAL READ FILE
			
			3. CONCAT FASTA FILES IN EACH FOLDER INTO SINGLE FASTA FILE





</entry>



<entry [Mon May 25 17:25:09 EDT 2009] GET TOTAL READS WITH sampleReads.pl FOR NA18507>



    TAKE INCRMENTS OF 100,000,000 READS (~1X COVERAGE AT READ LENGTH = 36 BP)

    NA18507 READS AND COVERAGE  
	Experiment	Reads	
	SRX000600	2,794,499,393	
	SRX000601	52,767,544	
	SRX000602	243,457,620	
	SRX000603	111,737,062	
	SRX001539	103,925,078	
	SRX001540	192,132,426	
	Total	3,498,519,123	
			
	Bp per read	36	
	Total bps	125,946,688,428	
	Genome length	3,170,000,000	
	Coverage (X-fold)	39.73	


/nethome/syoung/base/bin/comparison/sampleReads.pl --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta --compress gzip --mode total
Number files: 367
Total reads: 2794499393

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta 
Number files: 10
Total reads: 52767544

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta 
Number files: 34
Total reads: 243457620

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta 
Number files: 12
Total reads: 111737062

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/f
asta 
Number files: 4
Total reads: 103925078

/nethome/syoung/base/bin/comparison/sampleReads.pl --compress gzip --mode total --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta 
Number files: 8
Total reads: 192132426

    Run time: 00:00:00
    Completed /nethome/syoung/base/bin/comparison/sampleReads.pl
    5:30PM, 25 May 2009
    ****************************************





</entry>



<entry [Sun May 24 13:44:09 EDT 2009] Wang et al. 2008 HAN CHINESE GENOME>




du -hs /data/NGS/syoung/base/pipeline/SRA/yanhuang/paired
    37G     paired

du -hs /data/NGS/syoung/base/pipeline/SRA/yanhuang/single
    66G     single


1. DOWNLOAD SINGLE END READS DATA
------------------------------
ftp://ftp.era-xml.ebi.ac.uk/ERA000/ERA000005/single_end_data/

MENDEL4

cd /data/NGS/syoung/base/pipeline/SRA/yanhuang
/nethome/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.era-xml.ebi.ac.uk/ERA000/ERA000005/single_end_data/ --outputdir /data/NGS/syoung/base/pipeline/SRA/yanhuang/single --inputfile ERA000005-single.txt

    Run time: 09:21:58
    Completed /nethome/syoung/base/bin/utils/deepvac.pl
    11:08PM, 25 May 2009
    ****************************************


####TEST - OKAY
####cd /data/NGS/syoung/base/pipeline/SRA/yanhuang
####wget ftp://ftp.era-xml.ebi.ac.uk/ERA000/ERA000005/single_end_data/071031_S85_FC7167_L5_YHCDSA.fq.gz

#### THIS DOESN'T WORK (HANGS)
####/nethome/syoung/base/bin/utils/ftpAgent.pl --url ftp://ftp.era-xml.ebi.ac.uk/ERA000/ERA000005/single_end_data/ --outputdir /data/NGS/syoung/base/pipeline/SRA/yanhuang/single --regex "\.gz$" &> ftpAgent-single-mendel4.out



2. DOWNLOAD PAIRED END READS DATA
------------------------------
ftp://ftp.era-xml.ebi.ac.uk/ERA000/ERA000005/pair_end_data/

cd /data/NGS/syoung/base/pipeline/SRA/yanhuang
/nethome/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.era-xml.ebi.ac.uk/ERA000/ERA000005/pair_end_data/ --outputdir /data/NGS/syoung/base/pipeline/SRA/yanhuang/paired --inputfile ERA000005-paired.txt

    Run time: 05:36:36
    Completed /nethome/syoung/base/bin/utils/deepvac.pl
    7:24PM, 25 May 2009
    ****************************************


####TEST - OKAY
####cd /data/NGS/syoung/base/pipeline/SRA/yanhuang
####wget ftp://ftp.era-xml.ebi.ac.uk/ERA000/ERA000005/pair_end_data/071022_HWI-EAS68_0001_FC12991_L1_YHPE_PE1.fq.gz

#### THIS DOESN'T WORK
./ftpAgent.pl \
--url ftp://yh.genomics.org.cn/Rawdata \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/yanhuang  \
--username yhdata \
--password yhdownload \
--regex "\.gz$"

#### THIS DOES WORK
/nethome/syoung/base/bin/utils/ftpAgent.pl \
--url http://yh.genomics.org.cn/download.jsp \
--outputdir /data/NGS/syoung/base/pipeline/SRA/yanhuang  \
--username yhdata \
--password yhdownload \
--regex "\.gz$"



3. DOWNLOAD REFERENCE GENOME, SNPs, ETC. USING ftpAgent.pl

MENDEL1
-------
cd /data/NGS/syoung/base/pipeline/SRA/yanhuang
/nethome/syoung/base/bin/utils/ftpAgent.pl --url http://yh.genomics.org.cn/download.jsp --outputdir /data/NGS/syoung/base/pipeline/SRA/yanhuang  --username yhdata --password yhdownload --regex "\.gz$" &> ftpAgent-mendel1.out

MENDEL2
-------
cd /data/NGS/syoung/base/pipeline/SRA/yanhuang
/nethome/syoung/base/bin/utils/ftpAgent.pl --url http://yh.genomics.org.cn/download.jsp --outputdir /data/NGS/syoung/base/pipeline/SRA/yanhuang  --username yhdata --password yhdownload --regex "\.gz$" &> ftpAgent-mendel2.out

MENDEL3
-------
cd /data/NGS/syoung/base/pipeline/SRA/yanhuang
/nethome/syoung/base/bin/utils/ftpAgent.pl --url http://yh.genomics.org.cn/download.jsp --outputdir /data/NGS/syoung/base/pipeline/SRA/yanhuang  --username yhdata --password yhdownload --regex "\.gz$" &> ftpAgent-mendel3.out



YANHUANG README

This directory contains the SNP calls and hapotypes for the 1000 Genomes Pilot 1 release of April 2009.

There are separate files for each population: CEU, YRI and JPTCHB.

In each case, there is a site file, e.g. CEU.sites.2009_04, with typical line:

1	211	A	G	0.201754

<chromosome>, <position>, <ref base>, <non-reference (variant) base>, <inferred non-reference allele frequency>

and a haplotype file, e.g. CEU.hap, with typical line

1	211	aaaaagaaaaaaAAaaaaaagggaaaggGAaaAAAAaaaaaaaaggagaaaggaaaagaaaaggagaaaaAAaaAAaaaaagaagaaaaaaaaaaaAAAGaagaaaAAgagaga

<chromosome>, <position>, 2N*haplotype calls

where the first two calls correspond to the phased alleles of first
sample, calls three and four to the phased alleles of the second
sample etc.

The sample order is given in CEU.Samples etc., which have one line per sample as below:

NA06985
NA06986
NA06994
...

Quang Le <lsq@sanger.ac.uk> and Richard Durbin <rd@sanger.ac.uk>



YANHUANG WEBSITE
http://yh.genomics.org.cn/

YH genome was assembled based on 3.3 billion reads generated by Illumina Genome Analyzer. We achieved 117.7G nucleotides data and the genome was sequenced to 36-fold average coverage. By aligning the short reads with SOAP, 102.9G nucleotides are mapped onto the NCBI reference genome and 99.97% of the genome has been covered. The raw sequences, aligments, consensus genome, variants and relevant tools are released for public use. And the documents about donor consent and sample collection are avialable at the bottom of this page.

Note:BGI FTP username: yhdata password:yhdownload

Raw Data   

  a)    Single_end_data  FTP1  FTP2

  b)    Pair_end_data  FTP1  FTP2

Processed Data

1 YH genome sequence

a) Fasta by chromosome   FTP1

These files are YH chromosome sequences in FASTA format. In order to make them easy to use, all indels are not taken into the sequences, so the sequences have the same coordinates as UCSC build hg18, which is essentially same to NCBI human v36.1.

b)Fasta.qual by chromosome  FTP1

The files contain quality information of consensus bases.

c) Total genome : YH Fasta  YH Fasta.qual
The files are concatenated from above FASTA sequences and the quality information.



2 YH variants and annotations

These files are variants results extracted from SOAP alignments.

    * SNPs:YH-SNPs.gff Download  Open
    * Indels :YH-Indels.gff Download  Open
    * Structural Variations : YH-sv.gff Download  Open


README: GFFDefinitions.doc


3 Short read alignments

    * Alignment by chr  FTP1
      These files are alignments in format of SOAP output. 


README: AlignmentDTD.doc


4 Genotyping

    * Genotyping  FTP1


README:README


5 Original Illumina 1M Duo genotyping result.

    * FTP1

      These are the original base-calls from Illumina 1M Duo bead chip. These include sites that are inconsistent between the two replicates and those failed. 


6 Phased haplotype blocks of YH based on HapMap data.

    * FTP1




About donor consent

These are documents about donor consent to participate.

    * Donor consent of the Yanhuang Project-Phase I(in chinese): Download
    * IRB Validation: Download
    * The Informed Consent forms: Download
    * The Protocol: Download



#### NOT FOUND ON SRA
SRA ACCESSION ERA000005
The data have been deposited in the EBI/NCBI short read archive (accession number ERA000005).
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene&cmd=search&term=ERA000005


These data, together with all the associated analyses, are freely availably at
http://yh.genomics.org.cn

SNPs and indels have been submitted to NCBI dbSNP and will be available in dbSNP version 130
http://yh.genomics.org.cn/download.jsp

ftp://yh.genomics.org.cn/Rawdata


SRA README
http://www.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?cmd=show&f=faspftp_analyses&m=downloads&s=analyses

Data production and short read alignment

The genomic DNA used in this study came from an anonymous male Han Chinese individual who has no known genetic diseases. The donor gave written consent for public release of the genomic data for use in scientific research (see Supplementary Information for consent forms).

We carried out G-banded karyotyping to check the overall structural suitability of this DNA for use as a genomic standard for other genetic comparison and found no obvious chromosomal abnormalities (Supplementary Fig. 1). We then proceeded with whole-genome sequencing of the individual's DNA (hereafter referred to as YH) using Illumina Genome Analysers (GA; see Methods for details). To minimize the likelihood of systematic biases in genome representation, multiple DNA libraries were prepared and data were generated from eight single-end and two paired-end libraries (Supplementary Table 1). The read lengths averaged 35 base pairs (bp), and the two paired-end libraries had a span size of 135 bp and 440 bp, respectively. We collected a total of 3.3 billion reads of high-quality data: approximately 117.7 gigabases (Gb) of sequence (72 Gb from single-end reads and 45.7 Gb from paired-end reads). The data have been deposited in the EBI/NCBI Short Read Archive (accession number ERA000005). (See Supplementary Information for details concerning the availability of all data.)

Using the Short Oligonucleotide Alignment Program (SOAP)6, 102.9 Gb of sequence (87.4% of all data) was properly aligned to the NCBI human reference genome (build 36.1; hereafter called NCBI36). This resulted in a 36-fold average coverage of NCBI36 (Table 1). The effective genome coverage of the single- and paired-end sequencing was 22.5-fold and 13.5-fold, respectively. In total, 99.97% of NCBI36 (excluding Ns, which are undetermined sequence of the reference genome) was covered by at least one uniquely or repeatedly aligned read (uniquely aligned reads had only one best hit on NBCI36; repeatedly aligned reads had multiple possible alignments; see Methods for details).


</entry>



<entry [Sun May 24 13:44:09 EDT 2009] RUN readsFastqFasta.pl TO CREATE FIXED-LENGTH FASTA FILES>




1540
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--compress gzip \
--cluster \
--jobs 10 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 


1539
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta \
--compress gzip \
--cluster \
--jobs 10 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 


0601
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta \
--compress gzip \
--cluster \
--jobs 8 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 


0602
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta \
--compress gzip \
--cluster \
--jobs 8 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 



0603
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta \
--compress gzip \
--cluster \
--jobs 8 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 


0600
----

/nethome/syoung/base/bin/comparison/readsFastqFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--compress gzip \
--cluster \
--jobs 60 \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 




Run time: 01:34:47
Completed /nethome/syoung/base/bin/comparison/readsFastqFasta.pl
0:05AM, 25 May 2009
****************************************


[syoung@kronos fasta]$ date
Wed May 27 21:36:42 EDT 2009
[syoung@kronos fasta]$ /nethome/syoung/base/bin/comparison/readsFastqFasta.pl --inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 --outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta --compress gzip --cluster --jobs 60 --queue "-q psmall" --compress gzip --fixed --id_length 21 --sequence_length 36 --dot 10



</entry>



<entry [Sat May 23 23:44:09 EDT 2009] INSTALL COMPLETE GENOMICS API>



This API is delivered as a set of source code files that can be compiled to produce a statically linkable library for accessing and using data delivered by Complete Genomics to its customers.

These instructions have several pre-requisites including:

1. A successfully installed Centos 5.2 64 Bit Intel based computer with at least 200 GB of disk space available. Allow the installer to update the installation with all available updates.

2. An installed distribution of GCC 4.1.1, or later

    Using built-in specs.
    Target: x86_64-redhat-linux
    Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-libgcj-multifile --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --enable-plugin --with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre --with-cpu=generic --host=x86_64-redhat-linux
    Thread model: posix
    gcc version 4.1.2 20071124 (Red Hat 4.1.2-42)
    

3. An installed distribution of Xerces 2.8.

Xerces IS AN XML PARSER
http://xerces.apache.org/xerces-c/download.cgi

If using a source distribution be sure that you read and follow the Xerces-C installation instructions. There are decisions to be made that could involve bypassing many manual steps but need care and understanding before making these decisions.


In the case of a default installation of Centos 5.2, the following commands represent one example:

sudo su
mkdir /usr/local/apache
cd /usr/local/apache
wget http://apache.seekmeup.com/xerces/c/2/sources/xerces-c-src_2_8_0.tar.gz
tar xvfz xerces-c-src_2_8_0.tar.gz
cd xerces-c-src_2_8_0/src/xercesc/
export XERCESCROOT="/usr/local/apache/xerces-c-src_2_8_0"
./configure 
make
make install

    OK

    ...    
    /usr/bin/install -c .libs/XInclude /usr/local/bin/XInclude
    make[2]: Nothing to be done for `install-data-am'.
    make[2]: Leaving directory `/usr/local/apache/xerces-c-3.0.1/samples'
    make[1]: Leaving directory `/usr/local/apache/xerces-c-3.0.1/samples'
    make[1]: Entering directory `/usr/local/apache/xerces-c-3.0.1'
    make[2]: Entering directory `/usr/local/apache/xerces-c-3.0.1'
    make[2]: Nothing to be done for `install-exec-am'.
    test -z "/usr/local/lib/pkgconfig" || /bin/mkdir -p "/usr/local/lib/pkgconfig"
     /usr/bin/install -c -m 644 'xerces-c.pc' '/usr/local/lib/pkgconfig/xerces-c.pc'
    make[2]: Leaving directory `/usr/local/apache/xerces-c-3.0.1'
    make[1]: Leaving directory `/usr/local/apache/xerces-c-3.0.1'


#### INSTALLED THIS VERSION BUT GOT ERROR WHEN COMPILING complete
####wget http://mirrors.isc.org/pub/apache/xerces/c/3/sources/xerces-c-3.0.1.tar.gz
####tar xvfz xerces-c-3.0.1.tar.gz
#####cd xerces-c-3.0.1/src/xercesc/
####
####export XERCESCROOT="/usr/local/apache/xerces-c-3.0.1"
####./configure 
####make
####make install
####
####    OK
####
####    ...    
####    /usr/bin/install -c .libs/XInclude /usr/local/bin/XInclude
####    make[2]: Nothing to be done for `install-data-am'.
####    make[2]: Leaving directory `/usr/local/apache/xerces-c-3.0.1/samples'
####    make[1]: Leaving directory `/usr/local/apache/xerces-c-3.0.1/samples'
####    make[1]: Entering directory `/usr/local/apache/xerces-c-3.0.1'
####    make[2]: Entering directory `/usr/local/apache/xerces-c-3.0.1'
####    make[2]: Nothing to be done for `install-exec-am'.
####    test -z "/usr/local/lib/pkgconfig" || /bin/mkdir -p "/usr/local/lib/pkgconfig"
####     /usr/bin/install -c -m 644 'xerces-c.pc' '/usr/local/lib/pkgconfig/xerces-c.pc'
####    make[2]: Leaving directory `/usr/local/apache/xerces-c-3.0.1'
####    make[1]: Leaving directory `/usr/local/apache/xerces-c-3.0.1'



????? After building Xerces-C you may wish to modify the contents of the src/makefile and examples/dump-dnbs/makefile file to point to your installed directory.



4. An installed distribution of Boost 1.37, including bjam.


Centos 5.2 may require a manual build of Boost if you wish to use some of the later versions. The distribution may be easily built and instructions can be found on the boost.org web site. This can typically be done using two web download operations and two command lines.

BOOST

A collection of C libraries aimed at boosting productivity.

mkdir -p /nethome/syoung/base/apps/complete/1.1.0/boost
cd /nethome/syoung/base/apps/complete/1.1.0/boost

#### THIS DOESN'T WORK: wget http://sourceforge.net/project/downloading.php?group_id=7586&filename=boost_1_39_0.tar.gz&a=89204328
DOWNLOAD FROM boost.jam (~40MB)

tar xvfz  boost_1_39_0.tar.gz
cd /nethome/syoung/base/apps/complete/1.1.0/boost/boost_1_39_0

    OK




./bootstrap.sh


cd /nethome/syoung/base/apps/complete/1.1.0/boost
chmod 777 boost_1_39_0 
chmod 777 boost-jam-3.1.17-1-linuxx86
cd boost_1_39_0

ls
    boost            boost.css  bootstrap.bat  CMakeLists.txt  index.htm   INSTALL  libs             more    README.txt  status  wiki
    boost-build.jam  boost.png  bootstrap.sh   doc             index.html  Jamroot  LICENSE_1_0.txt  people  rst.css     tools


sudo su
./bootstrap.sh 

    Building Boost.Jam with toolset gcc... tools/jam/src/bin.linuxx86_64/bjam
    Detecting Python version... 2.4
    Detecting Python root... /usr
    Unicode/ICU support for Boost.Regex?... not found.
    Generating Boost.Build configuration in project-config.jam...
    
    Bootstrapping is done. To build, run:
    
        ./bjam
        
    To adjust configuration, edit 'project-config.jam'.
    Further information:
    
       - Command line help:
         ./bjam --help
         
       - Getting started guide: 
         http://www.boost.org/more/getting_started/unix-variants.html
         
       - Boost.Build documentation:
         http://www.boost.org/boost-build2/doc/html/index.html


BOOST JAM

sudo su
cd /nethome/syoung/base/apps/complete/1.1.0/boost
./bjam install


5. An installed copy of the Code Synthesis distribution.

This distribution is a run time for C++ of the XML DOM and can be obtained from http://www.codesynthesis.com/products/xsd/download.xhtml as an easily installed RPM.

Here are some example commands used to download and use the 3.0 version of the code synthesis runtime.


CODE SYNTHESIS
--------------

mkdir -p /nethome/syoung/base/apps/complete/1.1.0/code-synthesis
cd /nethome/syoung/base/apps/complete/1.1.0/code-synthesis

wget http://codesynthesis.com/download/xsd/3.0/linux-gnu/i686/xsd-3.0.0-1.i686.rpm
chmod 755 *
sudo su
rpm -i xsd-3.0.0-1.i686.rpm

    OK




6. REPLACE BOOST AND BOOSTJAM REFERENCES IN COMPLETE GENOMICS 1.1.0 AND 1.0.1 makefiles 

cd /nethome/syoung/base/apps/complete/1.1.0/src
emacs makefile

    CC=g++
    CCFLAGS= -Wall -g -c -I/usr/local/include/boost-1_37 \
             -I. -I./common -I./libdnbcollection -I./libpipeline -I./libmapper \
             -I/usr/local/apache/xerces-c-src_2_8_0/include \
             -D__STDC_CONSTANT_MACROS -DCGI_MAX_DNB_BASE_COUNT=70
    ...

INCORRECT:

boost-1_37
xerces-c-src_2_8_0

CORRECT:

boost-1_39
xerces-c-3.0.1


7. RUN make IN src FOLDER

cd /nethome/syoung/base/apps/complete/1.1.0/src
make

GIVES THIS ERROR (WITH USER root):

    In file included from libdnbcollection/CollectionUtilities.hpp:40,
                     from libdnbcollection/DnbCollection.cpp:58:
    libdnbcollection/Collection.hxx:4775:42: error: xercesc/dom/DOMInputSource.hpp: No such file or directory
    

THE FILE SYSTEM IS THERE BUT NO FILE xercesc/dom/DOMInputSource.hpp:
ll
/nethome/syoung/base/apps/complete/1.1.0/xerces/xerces-c-3.0.1/src/xercesc/dom





To commence installation you must first obtain a copy of the Apache 2.0 licensed source code distribution from Complete Genomics.
Unpack the compressed archive file distribution to a directory of your choice to be used to compile and prepare the code, for example on Centos:

cd /DESTINATION_LOCATION
unzip CompleteGenomics_API.zip


Upon unpacking the distribution you will observe two source directories, src which contains the main source ll
code for an object code library, and examples, containing example software for exercising the File Access API's.


Within the source code directories you will find makefile file instances.
In order to successfully compile code provided by this distribution you will need to modify these makefile's to point at the installation locations resulting from steps 1-5 above.




The following list of libraries shows the external library dependencies for the File Access API and its associated examples :

libboost_iostreams-gcc41-mt.a
libboost_serialization-gcc41-mt.a
libboost_thread-gcc41-mt.a
libboost_wserialization-gcc41-mt.a
libxerces-depdom.a
libboost_regex-gcc41-mt.a
libboost_filesystem-gcc41-mt.a
libxerces-c.a




[root@ngsdev src]# make 

    make: Warning: File `makefile' has modification time 1.5e+02 s in the future
    g++ -Wall -g -c -I/usr/local/include/boost-1_39 -I. -I./common -I./libdnbcollection -I./libpipeline -I./libmapper -I/usr/local/apache/xerces-c-3.0.1/include -D__STDC_CONSTANT_MACROS -DCGI_MAX_DNB_BASE_COUNT=70 libdnbcollection/DnbCollection.cpp -o libdnbcollection/DnbCollection.o
    In file included from libdnbcollection/CollectionUtilities.hpp:40,
                     from libdnbcollection/DnbCollection.cpp:58:
    libdnbcollection/Collection.hxx:4775:42: error: xercesc/dom/DOMInputSource.hpp: No such file or directory



To build the main File Access API library you can change directory into the src directory and type "make".

Another alternative is to use the makefile within the root directory to compile all source code within the distribution.

The examples can also be compiled by changing to those directories, validating that the library locations are correct to link Xerces and boost and then using make. It can be seen that currently the library path is set to ../../libs. You should replace this with the locations of the installed libraries.
To run the example programs you will need to add an environment variable called CGI_HOME. This variable should point to your installation directory where you unpacked the CGI source distribution.



</entry>



<entry [Thurs May 21 23:44:09 EDT 2009] SANGER MAQ DATA WITH YRI AND CEU TRIOS>



#  1000 Genomes Project. MAQ alignment: ftp://ftp.sanger.ac.uk/pub/1000genomes
    
    Name  	Size  	Last Modified
    090407-test.bams 		4/7/2009 	4:44:00 PM
    File:ARG_10Trees.tgz 	128189 KB 	5/1/2009 	1:17:00 PM
    CEU43 		12/17/2008 	3:32:00 AM
    F3C-Trio-YRI 		11/18/2008 	12:00:00 AM
    June-CEU-trio 		11/16/2008 	12:00:00 AM
    LC29 		9/26/2008 	12:00:00 AM
    LC52 		10/25/2008 	12:00:00 AM
    LC52-extra 		10/21/2008 	12:00:00 AM
    NA12878 		5/11/2009 	11:42:00 AM
    REL-0902 		1/20/2009 	1:33:00 AM
    REL-0904 		4/21/2009 	12:51:00 PM
    goncalo 		4/30/2009 	10:40:00 AM
    lsq 		5/1/2009 	1:13:00 PM
    reference 		12/19/2008 	5:47:00 PM
    tk2 		5/11/2009 	11:42:00 AM





</entry>



<entry [Wed May 20 16:33:09 EDT 2009] qseq FORMAT HAS CHANGED TO ASCII='@'+10*log10(1/p) (where p = prob. base error) as of Pipeline 1.3.>



http://seqanswers.com/forums/showthread.php?t=1110

sparks
Hi Tony,
I've been given a couple of qseq.txt files to align for clients and the format looks pretty simple except for the quality values. I'm seeing a lot of B's in the quality string and it looks like this is the lowest quality value. In earlier _sequence.txt files quality values were in form log(p/(1-p)) + '@' and codes went as low as ';'
These qseq.txt files look like you may be using phred type log(p) + '@'. Any chance you could enlighten us.

Thanks, Colin

coxtonyj
Hi Colin

You have it spot on, they are now in Phred format. Just to state it fully for the benefit of others: ASCII='@'+10*log10(1/p), p being the estimated probability of the base being in error. This change was made as of Pipeline 1.3.

Cheers

Tony 





 kmcarr
Member

Instrument(s):
Illumina GAI-II Roche 454
 
Member #: 519
Join Date: May 2008
Location: USA, Midwest
Posts: 43
	
Default
Quote:
Originally Posted by coxtonyj View Post
Hi Colin

You have it spot on, they are now in Phred format. Just to state it fully for the benefit of others: ASCII='@'+10*log10(1/p), p being the estimated probability of the base being in error. This change was made as of Pipeline 1.3.

Cheers

Tony


Q kmcarr:

Out of curiosity why did you stick with ASCII(Q+64) instead of the standard ASCII(Q+33)? It results in the minor annoyance of having to remember to convert before use in programs which are expecting Sanger FASTQ. It also means that there are now three types of FASTQ files floating about; standard Sanger FASTQ with quality scores expressed as ASCII(Qphred+33), Solexa FASTQ with ASCII(Qsolexa+64) and Solexa FASTQ with ASCII(Qphred+64).

A coxtonyj:
That is a fair point. The need to convert has always been present of course. We did give this some thought at the time and as I recall the rationale was that any code (ours or others) that was expecting Qsolexa+64 would probably still work if given Qphred+64, but that the conversion to Qphred+33 was at least now just a simple subtraction. But perhaps we should have bitten the bullet and gone with Qphred+33.

Q fadista:

Default sol2sanger
Hi,

Just want to be sure here:

1 - Is the sol2sanger function of maq 0.7.1 not working for solexa pipeline 1.3?

2 - If not, how can I convert the scores that I already computed (sol2sanger of maq 0.7.1 with solexa pipeline 1.3) to the sanger phred score system?


Best regards,
João

</entry>



<entry [Wed May 20 16:33:09 EDT 2009] DOWNLOAD CASAVA>




https://icom.illumina.com/icom/login.ilmn
Username: syoung@med.miami.edu
Password: q$Rt&Qzu

DOWNLOADED CASAVA AND GA PIPELINE 1.4, PUT IN 04-comparison/casava




apfejes
Senior Member

Join Date: Feb 2008

I thought CASAVA was an Illumina product, as is Eland. I don't think you're missing anything - of course they want you to use their products end to end. (= On the other hand, even the WTSS SNP & Exon expression software I wrote handles more than one input format, so I think it's just Illumina trying to bring people back into the Eland fold.

Frankly, there are so many SNP callers out there, until I see some solid reason to switch to CASAVA (and back to Eland), its not even on my radar.


 coxtonyj
Junior Member

Join Date: Apr 2008
Location: Cambridge, UK
Posts: 8
	
Hi apfejes

Disclaimer: I work at Illumina and am one of the developers of CASAVA, but these are my personal opinions.

As I see it, the beauty of sequencing data is that once you've got it into As,Cs,Gs and Ts it becomes a 'commodity item' and I think trying to compete with the combined brainpower of the entire sequencing community by trying to 'lock users in' beyond that stage would be extremely tough, and it's not clear to me if we would gain much by doing so.

CASAVA is more meant to make it easier to process datasets on 'human genome resequencing' scales - a human genome at say 30x sequence coverage presents logistical issues beyond those associated with, say, a ChipSeq dataset of a couple of Gbases (and I in no way wish to trivialize those, I know this is already a dauntingly large dataset in many ways) and now we are not so far away from "1 run (from whatever platform) = 1 genome" we don't want these to stand in the way of the science. Ideally algorithm developers would be able concentrate on algorithms and not file formats and so forth.

The idea is that 'under the hood' CASAVA handles the necessary sorting, binning and filtering of reads. SNP callers and other downstream applications then access the alignment data they need by making function calls to a library.

The software evolved from the code we used for our Yoruba genome analysis and can be used as a standalone genome analysis tool. The currently released version only includes the SNP calling module but internally we have modules for e.g. short indel and structural variant detection that we are looking to move towards release. CASAVA is also used as a backend to provide input data for the Genome Studio software we are releasing.

I would actually be very happy if people were to use CASAVA to process MAQ and/or BowTie data and I imagine it would be quite straightforward to write a parser, lack of time is the only reason we haven't looked at this ourselves.

Cheers

Tony


</entry>



<entry [Wed May 20 16:57:56 EDT 2009] SHORT READ FORMAT>



http://srf.sf.net/

illumina2srf and srf2illumina utilities 
http://www.illumina.com/pagesnrn.ilmn?ID=84

Q1. What is SRF?
      A1. SRF (Single Read Format) is a generic format for DNA sequence data. Some public sequence databases, such as NCBI, require that you post data from published manuscripts and other sequencing projects using SRF. The format is defined at http://srf.sf.net.
Q2. What is the illumina2srf utility and what does it do?
      A2. The Illumina2srf utility converts analyses from Genome Analyzer Pipeline Analysis Software to SRF. It can create simple SRF archives containing only sequences and quality values. It is also capable of creating SRFs with raw intensity and noise values. If these values are stored, the SRF file is significantly larger (~8X larger), but this allows base calling to be rerun from the archived files. Note: Intensity and noise values are stored in SRF with one less significant digit than is contained in the original pipeline files.

      illumina2srf runs in Genome Analyzer Pipeline Analysis Software and produces SRF files containing sequences and quality values from the standard pipeline output files. Using Illumina2srf can be specified as part of the GERALD config file:

      SRF_ARCHIVE_REQUIRED yes

      Or from the command line:

      For Genome Analyzer Pipeline Analysis Software v1.3:

      ${PipelineDir}/bin/illumina2srf -o lane_${lane_no}.srf
      ${BustardDir}/s_${lane_no}_*_qseq.txt

      For Genome Analyzer Pipeline Analysis Software v1.0:

      ${BustardDir}/s_${lane_no}_*_seq.txt

      where ${PipelineDir} is the root location of the Genome Analyzer pipeline, ${BustardDir} is the bustard directory of the run to be archived, and ${lane_no} is the number of the lane to archive from this run.

      To include intensity and noise values in the archive, include the "-b" flag:

      ${PipelineDir}/bin/illumina2srf -b -o lane_${lane_no}.srf
      ${BustardDir}/s_${lane_no}_*_qseq.txt
Q3. What is the srf2illumina utility and what does it do?
      A3. The srf2illumina utility unpacks SRF files from Genome Analyzer Pipeline Analysis Software into multiple files. It can unpack these files into a single directory, or it can place files so as to reflect the distribution of files in a pipeline analysis directory tree.

      To unpack an SRF archive, enter:

      ${PipelineDir}/bin/srf2illumina file.srf

      To unpack an SRF archive into a pipeline directory tree, enter:

      ${PipelineDir}/bin/srf2illumina -b file.srf
Q4. How do I unpack my SRF files from public databases that were created from Illumina data?
      A4. You can unpack SRF files with the srf2illumina utility supplied with Genome Analyzer Pipeline Analysis Software.
Q5. What if I don't have the Illumina Pipeline at my disposal?
      A5. The io_lib package contains a variety of vendor-neutral SRF utilities. Download this utility from http://sourceforge.net/projects/staden/, and compile the code following the instructions provided with this distribution. To unpack the sequences and quality values from SRF file using this package, you can use the utility srf2fastq by entering the command:

      srf2fastq -c file.srf
Q6. What should I do if I get an error indicating that the program can't be found? For example:

-bash-3.1$ GAPipeline-1.3.2/bin/illumina2srf -o lane_1.srf / /Data/IPAR_1.3/Bustard1.3.2_01-03-2009/s_1_*_qseq.txt

-bash: /GAPipeline-1.3.2/bin/illumina2srf: No such file or directory
      A6. If you get this message, you should explicitly install the io_lib. To do this, run the following command from the Pipeline Install directory:

      /GAPipeline_1.3.2 make WITH_IO_LIB=1 install

      Then retry the command from Q2, above.





</entry>



<entry [Wed May 20 15:57:56 EDT 2009] MEETING WITH NICK ON PAPER>



Paper will test five aligners (criteria: correct read alignment, non-alignment for non-matching reads):

ELAND
MAQ
SOAP
Mosaik
SHRimP

(also Bowtie?)

At different coverages:

38X
30X
20X
10X
5X


On reads from these genomes:

NA18507 genome
X chromosome
other deep-coverage SRA genomes


Paper will then evaluate SNP callers:

MAQ             
CASSAVA         
SSAHASNP        http://www.sanger.ac.uk/Software/analysis/ssahaSNP/
PolyBayesShort  http://bioinformatics.bc.edu/marthlab/PbShort


Later:

Create an application for detecting large chromosomal rearrangments using different sets of reads (paired with varying insert, single)






</entry>



<entry [Tues May 19 16:40:56 EDT 2009] NA18507 SOLEXA AND SOLID DOWNLOADS + MAQ OUTPUTS>



NEXT GENERATION VIRTUAL ISSUE
http://www.oxfordjournals.org/our_journals/bioinformatics/nextgenerationsequencing.html

INFO FROM THIS Li Heng PAGE:
http://www.sccas.cn/~nbf/resources.htm




IN REPLY TO THE SEQANSWERS PAGE ON NEXTGEN ASSEMBLERS: http://seqanswers.com/forums/showthread.php?t=43

#  NA18507, by Illumina/Solexa:  ftp://ftp.ncbi.nih.gov/pub/TraceDB/ShortRead/SRA000271
#  NA18507, by AB SOLiD: ftp://ftp.ncbi.nih.gov/pub/TraceDB/ShortRead/SRA000272
#  1000 Genomes Project. MAQ alignment: ftp://ftp.sanger.ac.uk/pub/1000genomes
#  Latest release:  ftp://ftp-trace.ncbi.nih.gov/1000genomes/release/2009_04/

GET DOWN THE SOLID DATA FOR NA18507 ON pluto:

/nethome/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.ncbi.nih.gov/pub/TraceDB/ShortRead/SRA000272 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/SRA000272

    RUNNING Tue May 19 16:43:02 EDT 2009

SOME REFERENCE ASSEMBLERS

    * MAQ (Mapping and Assembly with Qualities). For Illumina and SOLiD only. My own software.
    * ELAND (Efficient Large-Scale Alignment of Nucleotide Databases), by Anthony J. Cox at Illumina. For Illumina data only. This is the software in GAPipeline (previously known as SolexaPipeline). It is incredibly fast. I learnt a lot from this masterpiece when I was mentally designing MAQ. The latest ELAND in GAPipeline-0.3.0 is able to find multiple hits. Other programs in the pipeline can calculate MAQ-like mapping qualities.
    * SOAP (Short Oligonucleotide Alignment Program), by Ruiqiang Li at the Beijing Genomics Institute. For Illumina data only. Published in Bioinformatics [PMID: 18227114]. So far as I know, this is the first peer-reviewed software that is specifically designed for short reads. SOAP is featured as gapped alignment. Apparently, it resembles SSAHA2 in its indexing the reference genome, resembles ELAND in its 4-segment seeding and resembles MAQ in its random mapping.
    * RMAP, by Andrew D. Smith and Zhenyu Xuan at CSHL. For Illumina data only. Published in BMC Bioinformatics [PMID: 18307793]. RMAP makes use of base qualities to improve the accuracy of alignments. The authors compared RMAP with MAQ and concluded that RMAP is much more accurate. However, they ignore MAQ's mapping qualities, which is unfair.
    * SSAHA2 (Sequence Search and Alignment by Hashing Algorithm), by Adam Spargo and Zemin Ning at the Sanger Institute. For Illumina, 454 and capillary data. This is one of the leading alignment programs at the age of capillary sequencing, and it still works elegantly with both short and long reads. However, being generic slows SSAHA down. Short read specific softwares like ELAND is faster.
    * Mosaik, by Michael Strömberg at Boston College. For Illumina, 454 and capillary data. This is the software used in a recent Nature Methods paper by LaDeana et al.
    * GMAP, by Thomas D Wu at the department of bioinformatics Genentech, Inc. For Illumina, 454 and capillary data. A great software from its paper, but I am not quite sure how it performs on Illumina/Solexa data. NCGR uses this software in its Alpheus commercial package.
    * SHRiMP (SHort Read Mapping Package), by Stephen Rumble and Michael Brudno at the University of Toronto. For Illumina and SOLiD only. SHRiMP uses q-gram filters to map reads. Aha, q-gram filtering was my second best choice when I was planning MAQ algorithm. A really promising candidate, but at the moment (2008-02-06), it seems that SHRiMP is not as fast as ELAND or MAQ.
    * Myrialign by Paul Harrison.
    * SRMA by Beifang Niu. For Illumina/SOLiD only.
    * xMAN by Wei Li et al. For oligonucleotide alignment. Published in BMC Genomics [PMID:18366610].
    * PatMaN by Kay Prüfer et al. For oligonucleotide alignment and short reads. Published in Bioinformatics [online].


MORE ASSEMBLERS ON SEQANSWERS:
http://seqanswers.com/forums/showthread.php?t=43

Euler-SR (Euler-Short Reads Assembly, http://euler-assembler.ucsd.edu/portal/) by Mark J. Chaisson and Pavel A. Pevzner from UCSD. (published in Genome Research)
RMAP (A program for mapping Solexa reads, http://rulai.cshl.edu/rmap/) by Andrew D. Smith and Zhenyu Xuan at CSHL. (published in BMC Bioinformatics)



 How are people making use of outputs from various tools?

For instance
soap has this one line format with its way of representing variation
shrimp seems even more complicated with a fasta line format not even mentioning where the substitutions / indels are ... even if you look at the prettyplot

Any views on visualizing the data on global scale .. giving an indication of depth of sequencing at various regions on the reference, % variation... etc?
bioinfosm is offline   	Reply With Quote


A FEJES
 To answer the part on visualization, I have several tools that create files that are viewable on the UCSC genome browser. or generate a text file showing the aligned reads against the canonical sequence. I now even have a tool for generating post script files of peaks (for Chip-Seq experiments) along entire chromosomes.

The question is really what you're looking for. It's easy to visualize this data, but very hard to create new views that give new insight.





</entry>



<entry [Mon May 18 16:05:56 EDT 2009] TO DO LIST FOR PAPER>




1. GENERATE NA18507 GENOME FROM HUMAN GENOME 36.3 AND SNP & INDEL FILES

    - USE ERROR RATE IN Harismendy PAPER EXTRAPOLATED BASED ON COVERAGE

    - EXCLUDE ALL SNPS BELOW ERROR RATE PERCENTILE IN QUALITY SCORE

    - CALCULATE THE 20th PERCENTILE SCORE FOR THE SNPs FILE

    - DISCARD ANY SNPS WITH QUALITY VALUES <= 81 (THIS SHOULD LEAVE US WITH A FILE CONTAINING 20% LESS SNPS.)

    - CALCULATE THE 5th PERCENTILE SCORE FOR THE INDELS FILE

    - DISCARD INDELS WITH QUALITY VALUES <= 23 
    
    - APPLY THESE SNPS TO HUMAN GENOME 36.3 TO GENERATE NA18507 DIPLOID GENOME



2. CONVERT GENOME INTO SEQUENCE-ONLY CHROMOSOME FILES

/nethome/syoung/base/bin/comparison/chromosomeSequences.pl \
--inputfile /mihg/data/NGS/syoung/base/pipeline/human-genome/genome.fa \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes
    
    Run time: 00:03:56
    Completed /nethome/syoung/base/bin/comparison/chromosomeSequences.pl
    1:01PM, 19 May 2009
    ****************************************



3. CONVERT snp AND indel FILES INTO CHROMOSOME-SPECIFIC FILES

/nethome/syoung/base/bin/utils/columnSplit.pl \
--inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-20pct-filtered.snp \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes \
--prefix chr \
--suffix snp \
--column 1

    Run time: 00:00:34
    Completed /nethome/syoung/base/bin/utils/columnSplit.pl
    1:17PM, 19 May 2009
    ****************************************

/nethome/syoung/base/bin/utils/columnSplit.pl \
--inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-5pct-filtered.indel \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes \
--prefix chr \
--suffix indel \
--column 1

    Run time: 00:00:02
    Completed /nethome/syoung/base/bin/utils/columnSplit.pl
    1:17PM, 19 May 2009
    ****************************************



4. MOVE THE NT_*** FILES TO chrNT DIRECTORY

rm -fr /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chrNT
mkdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chrNT
cd /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes
mv chrNT* chrNT


5. FOR EACH CHROMOSOME FILE, CONVERT USING snp AND indel FILES

mkdir -p /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507

/nethome/syoung/base/bin/comparison/convertChromosomes.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507

        ...
        /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chrY.fa
        
        Finished Genome::convert_indels()
        Printed output file:
        
        /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chrY.fa
        
        Run time: 00:00:03
        Completed /home/syoung/base/bin/comparison/convertChromosome.pl
        10:12AM, 19 May 2009
        ****************************************    
    
    Run time: 00:03:53
    Completed /nethome/syoung/base/bin/comparison/convertChromosomes.pl
    1:23PM, 19 May 2009
    ****************************************



6. ADD THE MITOCHONDRIAL GENOME

cd /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507

wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_MT/hs_ref_chrMT.fa.gz
gunzip hs_ref_chrMT.fa.gz
mv hs_ref_chrMT.fa chrMT.fa

    OK

    

7. FOR EACH CHROMOSOME FILE, SQUASH CHROMOSOME FILES

rm -fr /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed

/nethome/syoung/base/bin/comparison/squashChromosomes.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed

    Run time: 00:00:41
    Completed /nethome/syoung/base/bin/comparison/squashChromosomes.pl
    1:49PM, 19 May 2009
    ****************************************





8. GENERATE RANDOMLY SELECTED SET OF READS FROM MULTIPLE DIRECTORIES OF READ FILES

SEPARATE ILLUMINA NA18507 READS INTO THREE POOLS:

1) PAIRED END SHORT 200 BP INSERT

2) PAIRED END LONG 2000 BP INSERT

3) SINGLE READS (FIRST READS OF 1 AND 2 ABOVE)


    Insert  Accession	Spots	Bases
    200bp    SRX000600	1.5G	209.0G
    200bp   SRX000601	26.4M	3.9G
    200bp   SRX000602	121.7M	18.0G
    200bp   SRX000603	55.9M	9.2G
    2kb	    SRX001539	52.0M	7.5G  **** LONG
    2kb	    SRX001540	96.1M	13.8G **** LONG
    Total:      6		1.8G	261.3G



    1. CREATE INDEX FILES WITH NUMBERS OF READS AND READ POSITIONS IN BYTES
    
    2. SCAN ALL INDEX FILES TO GET CUMULATIVE COUNT OF LINES --> PUT IN MEMORY
    
    3. RANDOMLY SELECT ANY LINE --> SCAN MEMORY FOR INDEX FILE, SCAN INDEX FILE FOR READ
    
    4. EXTRACT READ AND PLACE IN OUTPUT FILE
    
    5. CONVERT READ FILE TO FASTA FORMAT FOR INPUT INTO eland.pl 


#### PROBLEM WITH CLUSTER...?

#####GENERATE READ .fasta FILES WITHOUT UNZIPPING .fastq.gz FILES:
#####
#####/nethome/syoung/base/bin/comparison/readsFasta.pl \
#####--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
#####--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
#####--compress gzip \
#####--cluster \
#####--queue "-q psmall" \
#####--dot 10 
#####
#####
#####WHICH RUNS clusterSubmit.pl:
#####
#####/home/syoung/base/bin/comparison/../utils/clusterSubmit.pl --queue "-q psmall" \
#####> --scriptfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/SRR002308_2.fastq.gz.sh \
#####> --outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
#####> --command "/home/syoung/base/bin/comparison/../nextgen/fastq2fasta.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/SRR002308_2.fastq.gz --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/SRR002308_2.fasta --dot 100000
#####
#####
#####WHICH RUNS fastq2fasta.pl ON THE CLUSTER:
#####
#####/nethome/syoung/base/bin/nextgen/fastq2fasta.pl \
#####--inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.fastq.gz \
#####--outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.fasta \
#####--dot 10000 \
#####--compress gzip
#####    
#####


SCRIPTFILE CREATED BY readsFasta.pl USING --cluster OPTION:
emacs /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/SRR004107_2.fastq.gz.sh
*****************************************************
#!/bin/sh                                                                                                                                                                         

HOST=`hostname`
echo $HOST

echo "/home/syoung/base/bin/comparison/../nextgen/fastq2fasta.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/SRR004107_2.fastq.gz --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/SRR004107_2.fasta --dot 100000 --compress gzip"
cd /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta;
echo `pwd`;

/home/syoung/base/bin/comparison/../nextgen/fastq2fasta.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/SRR004107_2.fastq.gz --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/SRR004107_2.fasta --dot 100000 --compress gzip

echo "Completed."
*****************************************************


COMMAND TO RUN readsFasta.pl ON CLUSTER:

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--compress gzip \
--cluster \
--queue "-q psmall" \
--dot 10 


*****************************************************



RUN readsFasta.pl ON MENDEL1, 0600:
----------------------------------

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--compress gzip \
--dot 10 &

    /nethome/syoung/base/bin/comparison/readsFasta.pl --inputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 --outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta --compress gzip --dot 10 &
    [3] 5138
    [syoung@mendel1 bin]$ executable: /mihg/users/syoung/base/bin/comparison/../nextgen/fastq2fasta.pl
    No. files: 374
    0
    /mihg/users/syoung/base/bin/comparison/../nextgen/fastq2fasta.pl --inputfile /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/SRR002272_1.fastq.gz --outputfile /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta/SRR002272_1.fasta --dot 100000 --compress gzip



RUN readsFasta.pl ON MENDEL2, 0603:
-----------------------------------

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603 \
--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603/fasta \
--compress gzip \
--dot 10 &

    Run time: 01:01:03
    Completed /nethome/syoung/base/bin/comparison/readsFasta.pl
    6:46AM, 22 May 2009
    ****************************************



RUN readsFasta.pl ON MENDEL3, 0601, 1540:
-----------------------------------------

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601 \
--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta \
--compress gzip \
--dot 10 &

    OK

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540 \
--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--compress gzip \
--dot 10 &

    Run time: 01:24:44
    Completed /nethome/syoung/base/bin/comparison/readsFasta.pl
    7:45AM, 22 May 2009
    ****************************************



RUN readsFasta.pl ON MENDEL4, 0602, 1539:
----------------------------------------


/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602 \
--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta \
--compress gzip \
--dot 10 &

    OK    

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539 \
--outputdir /data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta \
--compress gzip \
--dot 10 &

    OK



USING pack TO GENERATE INDEX FILES:

/nethome/syoung/base/bin/comparison/indexFasta.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.fasta.gz --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.index --dot 10000 --fixed

    /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.index
    Run time: 00:00:06
    Completed /nethome/syoung/base/bin/comparison/indexFasta.pl
    11:47AM, 23 May 2009
    ****************************************

ll /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.index
    -rw-rw----+ 1 syoung bioinfo 22M May 23 11:40 /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.index


    
    /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.index.text
    Run time: 00:00:04
    Completed /nethome/syoung/base/bin/comparison/indexFasta.pl
    12:19AM, 23 May 2009
    *************************************


ll /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.index.text
-rw-rw----+ 1 syoung bioinfo 22M May 23 12:12 /mihg/data/NGS/syoung/base/pipeline/SRA/test/test.index.text





REDO ALL FASTA WITH FIXED WIDTHS:
---------------------------------

SRX001540

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540/fasta \
--cluster \
--queue "-q psmall" \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 

    
KILL ALL JOBS
-------------

kill -9 `ps aux | grep syoung | cut -f 5  -d " "` 




SRX000600

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600/fasta \
--cluster \
--queue "-q psmall" \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 



SRX000601

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601/fasta \
--cluster \
--queue "-q psmall" \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 


SRX000602

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602/fasta \
--cluster \
--queue "-q psmall" \
--compress gzip \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 



SRX0000603

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX0000603 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX0000603/fasta \
--cluster \
--queue "-q psmall" \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 



SRX001539

/nethome/syoung/base/bin/comparison/readsFasta.pl \
--inputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539 \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539/fasta \
--cluster \
--queue "-q psmall" \
--fixed \
--id_length 21 \
--sequence_length 36 \
--dot 10 




9. GENERATE MAPPING POSITIONS FOR SELECTED READS

    1. RUN ELAND AGAINST GENOME WITH SOME READS

/nethome/syoung/base/bin/nextgen/elandChromosomes.pl \

/nethome/syoung/base/bin/nextgen/cluster-eland.pl \
--inputfile /data/NGS/syoung/base/pipeline/SRA/eland/reads1.fasta \
--outputfile /data/NGS/syoung/base/pipeline/SRA/eland/reads1-chr1.eland \
--refdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chr1/squashed \
--length 32 \
--multi


    WHICH RUNS ON EACH CHROMOSOME:

/nethome/syoung/base/bin/nextgen/cluster-eland.pl \
--inputfile /data/NGS/syoung/base/pipeline/SRA/eland/reads1.fasta \
--outputfile /data/NGS/syoung/base/pipeline/SRA/eland/reads1-chr1.eland \
--refdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chr1/squashed \
--length 32 \
--multi


    1. IDENTIFY UNIQUE MATCHES ACROSS WHOLE GENOME - LABEL 'U', STORE MATCH LOCATIONS IN FASTA ID

    2. IDENTIFY MULTIPLE MATCHES ACROSS WHOLE GENOME - LABEL 'M', STORE MATCH LOCATIONS IN FASTA ID
    
    3. DISCARD FIRST TWO BASES AND LAST TWO BASES OF UNMATCHED READS

    4. USE ELAND AND/OR BLAT ON UNMATCHED READS TO SEE HOW MANY MATCH UNIQUELY WITH 90% IDENTITY
        
        CHOP EDGES???

    5. LABEL UNIQUE 'SU' AND MULTIPLE 'SM' MATCHES, STORE MATCH LOCATIONS IN FASTA ID

    6. KEEP UNMAPPED READS - LABEL 'N'
    
    





</entry>



<entry [Fri May 8 14:17:56 EDT 2009] TO DO LIST FOR PAPER>



1. GENERATE NA18507 GENOME FROM HUMAN GENOME 36.3 AND SNP & INDEL FILES

    - USE ERROR RATE IN Harismendy PAPER EXTRAPOLATED BASED ON COVERAGE

        Figure 5 - 40X coverage corresponds to a simulated false positive rate of 0.2
                -   "   "           "       "  "     "     false negative rate of 0.02
                    (i.e., we'll miss 2% of all SNPs at 40X coverage)


    - EXCLUDE ALL SNPS BELOW ERROR RATE PERCENTILE IN QUALITY SCORE

        So, exclude all SNPs with quality scores in the 20th percentile or less
            

    - FIRST, CALCULATE THE 20th PERCENTILE SCORE FOR THE SNPs FILE
    
        NA18507.snp.gz
        ==============
        1	469	C	S	63	44	2.56	63	62	C	130	G
        1	18455	T	K	48	20	2.31	63	34	G	3	T
        1	18456	T	K	35	21	2.56	63	48	G	46	T
        1	45027	C	A	38	14	2.12	63	48	M	9	C
        1	45162	C	Y	128	76	1.44	63	62	T	47	C
        1	51305	A	G	75	16	2.38	63	62	N	81	N
        1	51325	T	W	145	62	1.62	63	62	A	27	T
        
        COLUMNS ARE AS FOLLOWS: 
            1. chromosome
            2. position
            3. reference base
            4. consensus base
            5. ***Phred-like consensus quality***
            6. read depth
            7. the average number of hits of reads covering this position
            8. the highest mapping quality of the reads covering the position
            9. the minimum consensus quality in the 3bp flanking regions at each side of the site (6bp in total)
            10. the second best call
            11. log likelihood ratio of the second best and the third best call
            12. the third best call.
        

        /nethome/syoung/base/bin/utils/columnPercentile.pl --column 5  --percentile 20  --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp.20pct.score
        
            /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp.20pct.score
            Run time: 00:00:32
            Completed /nethome/syoung/base/bin/utils/columnPercentile.pl
            10:11PM, 10 May 2009
            ****************************************
            
            
        cat /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp.20pct.score
            81
        
        lines /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp
            4192779
        
        SO 81 IS THE 20TH PERCENTILE QUALITY VALUE.

    - DISCARD ANY SNPS WITH QUALITY VALUES <= 81. THIS SHOULD LEAVE US WITH A FILE CONTAINING 20% LESS SNPS.


        /nethome/syoung/base/bin/utils/columnFilter.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-20pct-filtered.snp --column 5 --operator ">" --threshold 81

            /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-20pct-filtered.snp
            Run time: 00:00:32
            Completed /nethome/syoung/base/bin/utils/columnFilter.pl
            10:40PM, 10 May 2009
            ****************************************
                
        lines /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-20pct-filtered.snp
            3350169
        

        REDUCED FROM 4.2 MILLION SNPS TO 3.35 SNPS, WHICH IS THE CORRECT NUMBER OF SNPS LEFT (I.E., 20% HAVE BEEN REMOVED)


    - DO THE SAME FOR THE INDELS, USING 5th PERCENTILE CUTOFF

        Bentley et al. 2008 

        This genome from a Yoruba individual contains significantly more
        polymorphism than a genome of European descent. The autosomal
        heterozygosity (p) of NA18507 is 9.9431024 (1 SNP per 1,006 bp),
        higher than previous values for Caucasians (7.631024, ref. 12).
        Heterozygosity in the pseudoautosomal region 1 (PAR1) is substantially
        higher (1.9231023) than the autosomal value. PAR1 (2.7 Mb)
        at the tip of the short arm of chromosomes X and Y undergoes
        obligatory recombination in male meiosis, which is equivalent to
        203 the autosome average. This illustrates a clear correlation
        between recombination and nucleotide diversity. By contrast, the
        0.33-Mb PAR2 region has a much lower recombination rate than
        PAR1; we observed that heterozygosity in PAR2 is identical to that
        of the autosomes in NA18507. Heterozygosity in coding regions is
        lower (0.5431023) than the total autosome average, consistent with
        the model that some coding changes are deleterious and are lost as the
        result of natural selection22. Nevertheless, the 26,140 coding SNPs
        (Supplementary Fig. 15) include 5,361 non-conservative amino acid
        substitutions plus 153 premature termination codons
        (Supplementary Table 9), many of which are expected to affect protein
        function.
        We performed a genome-wide survey of structural variation in this
        individual and found excellent correlation with variants that had
        been reported in previous studies, as well as detecting many new
        variants.
        
        ******
        We found 0.4 million short indels (1–16 bp;
        Supplementary Fig. 16), most of which are length polymorphisms
        in homopolymeric tracts of A or T. Half of these events are corroborated
        by entries in dbSNP, and 95 of 100 examined were present in
        amplicons sequenced from this individual in ENCODE regions, confirming
        the high specificity of this method of short indel detection.
        ******
    
        NA18507.indel.gz
        ================
        1       709353  */+ATAAT        16
        1       741363  */+AT   45
        1       757983  */-TTG  13
        1       768166  +CT/+CT 373
        1       770921  -C/*    723
        1       776933  */-AG   114
        1       780560  +AT/+AT 879
        1       780622  */-TA   437
        1       783192  */+T    175
        1       783277  */+AT   196
        
        COLUMNS ARE AS FOLLOWS:
        
        1. chromosome
        2. position
        3. genotype
        4. score. The higher the score the more reliable the call.
            
        /nethome/syoung/base/bin/utils/columnPercentile.pl --column 4  --percentile 5  --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel.5pct.score
            
            /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel.5pct.score
            Run time: 00:00:03
            Completed /nethome/syoung/base/bin/utils/columnPercentile.pl
            9:25PM, 11 May 2009
            ****************************************
        
            cat /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel.5pct.score
            
                23
                # /nethome/syoung/base/bin/utils/columnPercentile.pl --column 4 --percentile 5 --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel.5pct.score    
        
            SO THE SCORE CUTOFF FOR THE 5TH PERCENTILE IS 23

        /nethome/syoung/base/bin/utils/columnFilter.pl --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-5pct-filtered.indel --column 4 --operator ">" --threshold 23

            /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-5pct-filtered.indel
            Run time: 00:00:03
            Completed /nethome/syoung/base/bin/utils/columnFilter.pl
            9:30PM, 11 May 2009
            ****************************************

        lines /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-5pct-filtered.indel
            473588
        lines /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.indel
            499208

        REDUCED FROM 499,000 TO 473,000 - I.E., 5% HAVE BEEN REMOVED
    
    - APPLY THESE SNPS TO HUMAN GENOME 36.3 TO GENERATE NA18507 DIPLOID GENOME

        NUCLEOTIDE SYMBOLS
        http://www.mun.ca/biochem/courses/3107/symbols.html

        * = FOUND IN NA18507.snp FILE

        A		A	adenine
        C		C	cytosine
        G		G	guanine
        T		T	thymine
        U		U	uracil
                    
        *R		A or G	purine
        *Y		C or T (U)	pyrimidine
        *M		A or C	amino
        *K		G or T (U)	keto
        *S		C or G	strong (3 H bonds)
        *W		A or T (U)	weak (2 H bonds)
        B		C or G or T (U)	not A
        D		A or G or T (U)	not C
        H		A or C or T (U)	not G
        V		A or C or G	not T (U)
        N		A or C or G or T (U)	any nucleotide


        GET UNIQUE VALUES FOR CONSENSUS BASE
        
        /nethome/syoung/base/bin/utils/columnUniqueValues.pl --column 4  --inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp --outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp.unique-consensus
        
            /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp.unique-consensus
            Run time: 00:00:30
            Completed /nethome/syoung/base/bin/utils/columnUniqueValues.pl
            11:13PM, 10 May 2009
            ****************************************
            
            cat /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507.snp.unique-consensus

            W       196469  A or T weak (2 H bonds)
            K       227208  G or T keto
            M       227829  A or C amino
            S       228517  C or G strong (3 H bonds)
            A       352022
            T       352103
            G       401777  
            C       401833
            R       902400  A or G	purine
            Y       902621  C or T  pyrimidine
        

        CONVERT HUMAN GENOME 36.3 TO NA18507 GENOME USING SNPs
        
/nethome/syoung/base/bin/comparison/convertGenome.pl \
--inputfile /mihg/data/NGS/syoung/base/pipeline/human-genome/genome.fa \
--outputdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/genome \
--snpfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-20pct-filtered.snp \
--indelfile /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-5pct-filtered.indel

	...
	Run time: 22:00:04
	Completed /nethome/syoung/base/bin/comparison/convertGenome.pl
	10:05PM, 14 May 2009
	****************************************



    ...    
    Sequence length: 247249719
    INDEL file found: /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/genome/chr1.indel
    Left +GG != -G Right
    Left +A != +AA Right
    Left -G != -GG Right
    Left -GG != -G Right
    Left +A != -AAA Right
    Left -T != -TT Right
    Left -GTGT != -GT Right
    Left -TT != -T Right
    Left +A != +AA Right
    Left +C != -C Right
    Left -T != -TT Right
    Left +AT != +ATAT Right
    Left +ACACA != +A Right
    Left -A != -AA Right
    Left -TT != -TTT Right
    Left +CC != +C Right
    Left +T != +TT Right
    Left +C != +CC Right
    Left -T != -TT Right
    Left +TT != -T Right
    Left +AA != +A Right
    Left -T != -TT Right
    Left -T != +T Right
    Left -A != -AA Right
    Left +C != +TC Right
    Left -A != -AA Right
    Left -TT != -T Right
    Left -CCCCCCCC != -CC Right
    Left -T != +T Right
    Left -T != -TT Right
    Left -TTTTTTTT != -TTTTTTTTT Right
    Left -A != -AA Right
    Left +A != -A Right
    Left +T != +TT Right
    Left -A != +AA Right
    Left -T != +TT Right
    ...
    



        NOTE: SOME ISSUES WITH THE 'INDELS':
        
            1. MANY INDELS RESULT IN NO CHANGE, E.G.:
                1 6490831 +GGG/+GGG

                THESE ARE IGNORED.

            2. MANY INDELS HAVE REFERENCE BASES THAT DON'T CORRESPOND TO THE 36.3 GENOME SEQUENCE
                        
                THESE ARE USED - THE CONSENSUS BASES ARE SUBSTITUTED INTO THE CHROMOSOME SEQUENCE.
                RATIONALE: MAY BE SOME DIFFERENCES BETWEEN 

                


                SOLUTION: The March 2006 human reference sequence (NCBI Build 36.1) was used (p.44 of Bentley
                et al. Supplementary).
                
                http://www.ncbi.nlm.nih.gov/genome/guide/human/release_notes.html
                http://www.ncbi.nlm.nih.gov/mapview/stats/BuildStats.cgi?taxid=9606&build=36&ver=1
                
                DOWNLOAD NCBI 36.1
                ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/README

                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_01/hs_ref_chr1.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_02/hs_ref_chr2.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_03/hs_ref_chr3.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_04/hs_ref_chr4.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_05/hs_ref_chr5.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_06/hs_ref_chr6.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_07/hs_ref_chr7.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_08/hs_ref_chr8.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_09/hs_ref_chr9.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_10/hs_ref_chr10.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_11/hs_ref_chr11.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_12/hs_ref_chr12.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_13/hs_ref_chr13.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_14/hs_ref_chr14.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_15/hs_ref_chr15.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_16/hs_ref_chr16.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_17/hs_ref_chr17.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_18/hs_ref_chr18.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_19/hs_ref_chr19.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_20/hs_ref_chr20.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_21/hs_ref_chr21.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_22/hs_ref_chr22.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_X/hs_ref_chrX.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_Y/hs_ref_chrY.fa.gz
                wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/ARCHIVE/BUILD.36.1/CHR_MT/hs_ref_chrMT.fa.gz
                
                head hs_ref_chr11.fa
                >gi|51493057|ref|NT_035113.6|Hs11_35275 Homo sapiens chromosome 11 genomic contig, reference assembly
                
                CHANGE ALL HEADERS TO JUST CHROMOSOME NAME >chr11
                
                BUT FOUND THAT EACH CHROMOSOME FILE CONTAINED MULTIPLE FASTA ENTRIES, SO JUNKED THIS DATA DIR AS '36.1-old'
                
                THEN FOUND THAT BUILDS 36.1 AND 36.3 ARE IDENTICAL ASSEMBLIES...

                http://www.ncbi.nlm.nih.gov/genome/guide/human/release_notes.html#36.3assembly


        CHECK IF THESE CAN BE USED IN AN ELAND

        mkdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/squashed
        /mihg/analysis/GAPipeline-1.3.2/bin/squashGenome /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/squashed /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-genome.fa
        

PROBLEM:

USING SEQUENCE STRING IN MEMORY WAS EXTREMELY SLOW
USING Tie::File ON INDIVIDUAL CHROMOSOMES RAN OUT OF MEMORY

SOLUTION:

seek AND read THROUGH FASTA FILE - FAST AND LOW MEMORY


1. CONVERT GENOME INTO SEQUENCE-ONLY CHROMOSOME FILES

[syoung@mendel1 comparison]$
/nethome/syoung/base/bin/comparison/chromosomeSequences.pl \
--inputfile /data/NGS/syoung/base/pipeline/human-genome/genome.fa \
--outputdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes

    Printing chromosomes to sequence-only files (no fasta header)...
    chromosome: chr1
    chromosome: chr2
    ...
    chromosome: chr22
    chromosome: chrX
    chromosome: chrY
    
    Run time: 00:03:12
    Completed /nethome/syoung/base/bin/comparison/chromosomeSequences.pl
    2:59AM, 15 May 2009
    ****************************************

2. CONVERT snp AND indel FILES INTO CHROMOSOME-SPECIFIC FILES

[syoung@mendel1 comparison]$

/nethome/syoung/base/bin/utils/columnSplit.pl \
--inputfile /data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-20pct-filtered.snp \
--outputdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes \
--prefix chr \
--suffix snp \
--column 1

    Using default separator: whitespace
    Printing files with unique values in column 1...
    outfile: /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr1.snp
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr1.snp
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr2.snp
    ...
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chrNT_113877.snp
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chrNT_113899.snp
    done.
    
    Run time: 00:00:25
    Completed /nethome/syoung/base/bin/utils/columnSplit.pl
    3:29AM, 15 May 2009
    ****************************************



[syoung@mendel1 comparison]$

/nethome/syoung/base/bin/utils/columnSplit.pl \
--inputfile /data/NGS/syoung/base/pipeline/SRA/SRA000271/NA18507-5pct-filtered.indel \
--outputdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes \
--prefix chr \
--suffix indel \
--column 1

    Using default separator: whitespace
    Printing files with unique values in column 1...
    outfile: /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr1.indel
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr1.indel
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr2.indel
    ...
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chrNT_113888.indel
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chrNT_113899.indel
    done.
    
    Run time: 00:00:02
    Completed /nethome/syoung/base/bin/utils/columnSplit.pl
    3:32AM, 15 May 2009
    ****************************************


3. FOR EACH CHROMOSOME FILE, CONVERT USING snp AND indel FILES


mkdir -p /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507

/nethome/syoung/base/bin/comparison/convertChromosome.pl \
--inputfile /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr1.fa \
--snpfile /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr1.snp \
--indelfile /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/chr1.indel \
--outputfile /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chr1.fa

    
    Run time: 00:00:11
    Completed /nethome/syoung/base/bin/comparison/convertChromosome.pl
    1:26AM, 18 May 2009
    ****************************************



4. SQUASH CHROMOSOME FILES

mkdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed
/mihg/analysis/GAPipeline-1.3.2/bin/squashGenome /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chr1.fa

    User: 0s System: 0s Actual: 8e-06s Efficiency: 0%
    Full file path: /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chr1.fa
    Extracted file name:chr1.fa
    /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.2bpb /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.vld
    squash: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chr1.fa of size 247237623 bytes.
    finished file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/chr1.fa
    247237617 bases
    225018350 valid bases (91.013%)
    28553 valid regions
    User: 1.43209s System: 1.22008s Actual: 4.15057s Efficiency: 63.8988%



            NB: SQUASH DOES NOT RECOGNIZE NON-AGTC BASE SYMBOLS

            mkdir -p /data/NGS/syoung/base/pipeline/SRA/eland/test/squashed
            emacs /data/NGS/syoung/base/pipeline/SRA/eland/test/nonAGTC.fa
            >nonAGTC
            AAAAAAAAAAAAAAAAMMMMMMMMYYYYYYYYRRRRRRRRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGgggggggggggggggggggggggggggggggggggggggTtttttttttttttttttttttttttttttttttCCcccccccccccccccccccccccccccccccccccccccccccccccc
            
            NB: AGTC BASES
            
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGgggggggggggggggggggggggggggggggggggggggTtttttttttttttttttttttttttttttttttCCcccccccccccccccccccccccccccccccccccccccccccccccc
            
            /mihg/analysis/GAPipeline-1.3.2/bin/squashGenome /data/NGS/syoung/base/pipeline/SRA/eland/test/squashed /data/NGS/syoung/base/pipeline/SRA/eland/test/nonAGTC.fa
            


5. CONVERT READ FILE TO FASTA FORMAT FOR INPUT INTO eland.pl 

/nethome/syoung/base/bin/nextgen/fastq2fasta.pl \
--inputfile /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fastq \
--outputfile /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fast
--dot 100000
    
    ...
    /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta
    
    Run time: 00:05:37
    Completed /nethome/syoung/base/bin/nextgen/fastq2fasta.pl
    1:38AM, 18 May 2009
    ****************************************
    

head /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta

    >SRR002271.1 
    GTGATTAGTGAAACATAAAATAGTTTCATGTTGAAA
    ...
    

            NB: CONVERSION TO SANGER FASTQ IS MUCH SLOWER:
            
            cd /nethome/syoung/base/bin/nextgen
            ./solexa2fastq.pl \
            -i /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fastq \
            -o /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.sanger.fastq
            
                22250000
                22251000
                Output file printed:
                
                /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta
                
                Run time: 00:27:11
                Completed ./fastq2fasta.pl
                11:25PM, 17 May 2009
                ****************************************


6. RUN ELAND AGAINST GENOME WITH SOME READS

/nethome/syoung/base/bin/nextgen/eland.pl \
--inputfile /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta \
--outputfile /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.NA18507.eland \
--refdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed \
--length 32 \
--multi


    ELAND: Efficient Local Alignment of Nucleotide Data
    Copyright (c) 2003-2006 Solexa Limited. All rights reserved.
    Author: Anthony J. Cox
    
    Publications incorporating data generated by the use of
    this software or modified versions thereof should cite:
    Anthony J. Cox.
    Ultra high throughput alignment of short sequence tags.
    In preparation.
    
    WARNING: this software is compiled to process oligos of length 32.
    To change this value, edit OLIGO_LENGTH and recompile.
    
    Will use at most 25 bits in hash table
    Can process at most 2147483647 oligos per batch
    Will find all matches having 2 errors or less
    getOligoSourceFile: detected fasta format oligo file
    WARNING: first sequence of /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta contains 36 bases, but only the first 32 bases will be used in the alignment.
    To change this value, edit OLIGO_LENGTH and recompile.
    
    Starting run! Time now: Mon May 18 01:46:56 2009
    Will read oligos from file /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta
    Built MatchTableMulti: will store at most 10,10,10 0,1,2 error matches per read
    Trying to open directory /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed ...
    Sorting chromosome names
    made hash table, pointer table sizes = 0, 0
    About to build hash tables for pass 0: User: 0.004001s System: 0s Actual: 0.011576s Efficiency: 34.5629%
    partition hash table will run in split prefix mode, split is 25/7
    Setting partition hash table size to 25 bits
    partition hash table will run in split prefix mode, split is 25/7
    Setting partition hash table size to 25 bits
    counting oligos
    read 22251361 oligos from source
    Will hash 22232382 oligos
    converting count values to pointer arrays
    will place 44360077 entries in table
    will place 44360077 entries in table
    44360077 entries reduced to 44360077 entries
    44360077 entries reduced to 44360077 entries
    successful table build
    Built hash tables: User: 93.0298s System: 3.62823s Actual: 96.6708s Efficiency: 99.9868%
    Scanning file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa: User: 0s System: 0s Actual: 0.000115s Efficiency: 0%
    Starting block: 1
    FileReader: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.2bpb of size 61809408 bytes.
    squash: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.vld of size 228430 bytes.
    Comment: >chr1
    finished making FileReader
    
    
    Finishing block: 16
    ... done User: 991.202s System: 2.90418s Actual: 994.666s Efficiency: 99.9437%
    FileReader: unmapping 61809408 bytes of memory
    FileReader: unmapping 228430 bytes of memory
    made hash table, pointer table sizes = 33554434, 33554434
    About to build hash tables for pass 1: User: 0s System: 0.020002s Actual: 0.018388s Efficiency: 108.777%
    partition hash table will run in split prefix mode, split is 25/7
    Setting partition hash table size to 25 bits
    partition hash table will run in split prefix mode, split is 25/7
    Setting partition hash table size to 25 bits
    counting oligos
    read 22251361 oligos from source
    Will hash 20972632 oligos
    converting count values to pointer arrays
    will place 41873233 entries in table
    will place 41808615 entries in table
    41873233 entries reduced to 41873233 entries
    41808615 entries reduced to 41808615 entries
    successful table build
    Built hash tables: User: 93.2738s System: 2.14013s Actual: 95.4173s Efficiency: 99.9965%
    Scanning file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa: User: 0s System: 0s Actual: 8.7e-05s Efficiency: 0%
    Starting block: 1
    FileReader: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.2bpb of size 61809408 bytes.
    squash: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.vld of size 228430 bytes.
    Comment: >chr1
    finished making FileReader
    Finishing block: 16
    ... done User: 273.677s System: 0.504032s Actual: 274.174s Efficiency: 100.002%
    FileReader: unmapping 61809408 bytes of memory
    FileReader: unmapping 228430 bytes of memory
    made hash table, pointer table sizes = 33554434, 33554434
    About to build hash tables for pass 2: User: 0s System: 0.020001s Actual: 0.018373s Efficiency: 108.861%
    partition hash table will run in split prefix mode, split is 25/7
    Setting partition hash table size to 25 bits
    partition hash table will run in split prefix mode, split is 25/7
    Setting partition hash table size to 25 bits
    counting oligos
    read 22251361 oligos from source
    Will hash 20972632 oligos
    converting count values to pointer arrays
    will place 41842226 entries in table
    will place 41842226 entries in table
    41842226 entries reduced to 41842226 entries
    41842226 entries reduced to 41842226 entries
    successful table build
    Built hash tables: User: 89.4576s System: 2.16013s Actual: 91.6695s Efficiency: 99.9435%
    Scanning file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa: User: 0s System: 0s Actual: 0.000105s Efficiency: 0%
    Starting block: 1
    FileReader: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.2bpb of size 61809408 bytes.
    squash: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.vld of size 228430 bytes.
    Comment: >chr1
    finished making FileReader
    Finishing block: 16
    ... done User: 253.496s System: 0.428027s Actual: 253.932s Efficiency: 99.9967%
    FileReader: unmapping 61809408 bytes of memory
    FileReader: unmapping 228430 bytes of memory
    Will look for index file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.idx
    ... not found, will not index
    Outputting results: User: 0s System: 0.028002s Actual: 0.0218s Efficiency: 128.45%
    Info: 52061314 matches were stored
    Info: 208245256 bytes of temp storage used for oligo numbers
    Info: 208245256 bytes of temp storage used for match positions
    ... done User: 47.515s System: 5.17232s Actual: 52.9902s Efficiency: 99.4283%
    Run complete! Time now: Mon May 18 02:17:55 2009
    
    Run time: 00:31:30
    Completed /nethome/syoung/base/bin/nextgen/eland.pl
    2:18AM, 18 May 2009
    ****************************************


6. (ALTERNATIVE) SPLIT INPUT FILE INTO TWO PARTS AND THEN RUN ELAND ON KRONOS


/nethome/syoung/base/bin/nextgen/elandfasta.pl \
-i/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta
-m 12000000

    /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta.1
    /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta.2
        
    Run time: 00:00:31
    Completed /nethome/syoung/base/bin/nextgen/elandfasta.pl
    2:04AM, 18 May 2009
    ****************************************


ON KRONOS:

emacs /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.1.NA18507.eland.sh
#!/bin/sh

/nethome/syoung/base/bin/nextgen/eland.pl \
--inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta.1 \
--outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.1.NA18507.eland \
--refdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed \
--length 32 \
--multi


emacs /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.2.NA18507.eland.sh
#!/bin/sh

/nethome/syoung/base/bin/nextgen/eland.pl \
--inputfile /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.fasta.2 \
--outputfile /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.2.NA18507.eland \
--refdir /mihg/data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed \
--length 32 \
--multi

cd /mihg/data/NGS/syoung/base/pipeline/SRA/eland
chmod 755 *sh

qsub -q psmall /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.1.NA18507.eland.sh
qsub -q psmall /mihg/data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.2.NA18507.eland.sh

    [syoung@kronos eland]$ mshow
    
    active jobs------------------------
    JOBID              USERNAME      STATE PROCS   REMAINING            STARTTIME
    
    29133               tozgokm    Running    88    19:09:57  Sun May 17 21:33:49
    27188               abarman    Running    16  1:12:56:12  Tue May 12 15:20:04
    29070               wcooper    Running     8  2:00:21:00  Sat May 16 18:44:52
    27788              sschurer    Running    32  3:14:01:21  Thu May 14 16:25:13
    27176                 ezeng    Running     1  4:16:32:59  Sat May 16 12:56:51
    29232              famelung    Running     1  4:23:50:40  Mon May 18 02:14:31
    29233              famelung    Running     1  4:23:51:40  Mon May 18 02:15:31
    29234              famelung    Running     1  4:23:55:55  Mon May 18 02:19:46
    29237                syoung    Running     1  4:23:59:53  Mon May 18 02:23:44
    29238                syoung    Running     1  4:23:59:57  Mon May 18 02:23:48
    
    10 active jobs          150 of 232 processors in use by local jobs (64.66%)
                              19 of 29 nodes active      (65.52%)
    


lines /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.NA18507.eland
    22251361

grep -c NM /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.NA18507.eland
    16985221

head /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1.NA18507.eland
    >SRR002271.1    GTGATTAGTGAAACATAAAATAGTTTCATGTTGAAA    NM
    >SRR002271.2    GTGGGAAAAACTGAAATACATTGCTTATGGATTCAT    NM
    >SRR002271.3    TTTTCTTGATTTCATTTTAGCACAATCATTAATTAC    NM
    >SRR002271.4    TTCCATTCCATTCCATTCCATTCCAGTTGATTCCAT    0:0:2   chr1.fa:716781R2,222255279R2
    >SRR002271.5    GGAAAGGAATGGAATGGAATGGAATGGAATGGAATG    0:63:56
    >SRR002271.6    GTGGTGAACAAAGTAGGCTGCTTGGAACTGGGAAGT    NM
    >SRR002271.7    GATGGATGCTAGAGTTTGAGAAACACTGTATTGTAT    0:1:0   chr1.fa:59543580R1
    >SRR002271.8    GCTATTAGTTGATTTTTATTTTTACATAGATACACC    NM
    >SRR002271.9    TATATTCATCTGCATGTTTTAGCACTGAGATGCATG    NM
    >SRR002271.10   TGTAAGCCACTGTGCCCAGCTATAGTTGTTAACATT    NM





            NB: THE FASTA HEADER MUST ONLY HAVE ONE \S+ ENTRY, OTHERWISE ELAND WILL THINK THE REMAINING PARTS OF THE HEADER ARE THE SEQUENCE
            
            emacs  /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.fastq
            
            >SRR002271.1 
            GTGATTAGTGAAACATAAAATAGTTTCATGTTGAAA
            >SRR002271.2 
            GTGGGAAAAACTGAAATACATTGCTTATGGATTCAT
            >SRR002271.3 
            TTTTCTTGATTTCATTTTAGCACAATCATTAATTAC
            >SRR002271.4 
            TTCCATTCCATTCCATTCCATTCCAGTTGATTCCAT
            >SRR002271.5 
            GGAAAGGAATGGAATGGAATGGAATGGAATGGAATG
            >SRR002271.6 
            GTGGTGAACAAAGTAGGCTGCTTGGAACTGGGAAGT
            >SRR002271.7 
            GATGGATGCTAGAGTTTGAGAAACACTGTATTGTAT
            >SRR002271.8 
            GCTATTAGTTGATTTTTATTTTTACATAGATACACC
            >SRR002271.9 
            TATATTCATCTGCATGTTTTAGCACTGAGATGCATG
            >SRR002271.10 
            TGTAAGCCACTGTGCCCAGCTATAGTTGTTAACATT
            
            
            cd /nethome/syoung/base/bin/nextgen
            ./eland.pl \
            --inputfile /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.fastq \
            --outputfile /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.NA18507.eland \
            --refdir /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed \
            --length 30
            
                Eland: /mihg/analysis/GAPipeline-1.3.2/bin
                Eland: /mihg/analysis/GAPipeline-1.3.2/bin/eland_30
                Output directory: /data/NGS/syoung/base/pipeline/SRA/eland
                /mihg/analysis/GAPipeline-1.3.2/bin/eland_30 /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.fastq /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.NA18507.eland 
                ELAND: Efficient Local Alignment of Nucleotide Data
                Copyright (c) 2003-2006 Solexa Limited. All rights reserved.
                Author: Anthony J. Cox
                
                Publications incorporating data generated by the use of
                this software or modified versions thereof should cite:
                Anthony J. Cox.
                Ultra high throughput alignment of short sequence tags.
                In preparation.
                
                WARNING: this software is compiled to process oligos of length 30.
                To change this value, edit OLIGO_LENGTH and recompile.
                
                Will use at most 25 bits in hash table
                Can process at most 2147483647 oligos per batch
                Will find all matches having 2 errors or less
                getOligoSourceFile: detected fasta format oligo file
                WARNING: first sequence of /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.fastq contains 36 bases, but only the first 30 bases will be used in the alignment.
                To change this value, edit OLIGO_LENGTH and recompile.
                
                Starting run! Time now: Sun May 17 23:55:37 2009
                Will read oligos from file /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.fastq
                Will output assembly format match details to file /data/NGS/syoung/base/pipeline/SRA/eland/SRR002271_1-10.NA18507.eland
                Trying to open directory /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed ...
                Sorting chromosome names
                made hash table, pointer table sizes = 0, 0
                About to build hash tables for pass 0: User: 0.004s System: 0s Actual: 0.065178s Efficiency: 6.13704%
                partition hash table will run in split prefix mode, split is 25/5
                Setting partition hash table size to 25 bits
                partition hash table will run in split prefix mode, split is 25/5
                Setting partition hash table size to 25 bits
                counting oligos
                read 10 oligos from source
                Will hash 10 oligos
                converting count values to pointer arrays
                will place 20 entries in table
                will place 20 entries in table
                20 entries reduced to 20 entries
                20 entries reduced to 20 entries
                successful table build
                Built hash tables: User: 1.03207s System: 0.272017s Actual: 1.31339s Efficiency: 99.2911%
                Scanning file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa: User: 0s System: 0s Actual: 0.00069s Efficiency: 0%
                Starting block: 1
                FileReader: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.2bpb of size 61809408 bytes.
                squash: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.vld of size 1400926 bytes.
                Comment: >chr1
                finished making FileReader
                Finishing block: 16
                ... done User: 30.3459s System: 0.300018s Actual: 31.9236s Efficiency: 95.9978%
                FileReader: unmapping 61809408 bytes of memory
                FileReader: unmapping 1400926 bytes of memory
                made hash table, pointer table sizes = 33554434, 33554434
                About to build hash tables for pass 1: User: 0s System: 0.020002s Actual: 0.01821s Efficiency: 109.841%
                partition hash table will run in split prefix mode, split is 25/5
                Setting partition hash table size to 25 bits
                partition hash table will run in split prefix mode, split is 25/5
                Setting partition hash table size to 25 bits
                counting oligos
                read 10 oligos from source
                Will hash 10 oligos
                converting count values to pointer arrays
                will place 20 entries in table
                will place 20 entries in table
                20 entries reduced to 20 entries
                20 entries reduced to 20 entries
                successful table build
                Built hash tables: User: 1.04807s System: 0s Actual: 1.05057s Efficiency: 99.7617%
                Scanning file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa: User: 0s System: 0s Actual: 0.0001s Efficiency: 0%
                Starting block: 1
                FileReader: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.2bpb of size 61809408 bytes.
                squash: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.vld of size 1400926 bytes.
                Comment: >chr1
                finished making FileReader
                Finishing block: 16
                ... done User: 39.9025s System: 0.112007s Actual: 40.0204s Efficiency: 99.9852%
                FileReader: unmapping 61809408 bytes of memory
                FileReader: unmapping 1400926 bytes of memory
                made hash table, pointer table sizes = 33554434, 33554434
                About to build hash tables for pass 2: User: 0s System: 0.020001s Actual: 0.019247s Efficiency: 103.917%
                partition hash table will run in split prefix mode, split is 25/7
                Setting partition hash table size to 25 bits
                partition hash table will run in split prefix mode, split is 25/3
                Setting partition hash table size to 25 bits
                counting oligos
                read 10 oligos from source
                Will hash 10 oligos
                converting count values to pointer arrays
                will place 20 entries in table
                will place 20 entries in table
                20 entries reduced to 20 entries
                20 entries reduced to 20 entries
                successful table build
                Built hash tables: User: 1.05207s System: 0s Actual: 1.05216s Efficiency: 99.9909%
                Scanning file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa: User: 0s System: 0s Actual: 0.000584s Efficiency: 0%
                Starting block: 1
                FileReader: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.2bpb of size 61809408 bytes.
                squash: opened file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.vld of size 1400926 bytes.
                Comment: >chr1
                finished making FileReader
                Finishing block: 16
                ... done User: 39.8625s System: 0.108007s Actual: 39.9831s Efficiency: 99.9684%
                FileReader: unmapping 61809408 bytes of memory
                FileReader: unmapping 1400926 bytes of memory
                Will look for index file /data/NGS/syoung/base/pipeline/SRA/SRA000271/chromosomes/NA18507/squashed/chr1.fa.idx
                ... not found, will not index
                Outputting results: User: 0s System: 0.020001s Actual: 0.020918s Efficiency: 95.6162%
                ... done User: 0s System: 0s Actual: 0.000819s Efficiency: 0%
                Run complete! Time now: Sun May 17 23:57:33 2009
                
                Run time: 00:01:56
                Completed ./eland.pl
                11:57PM, 17 May 2009
                ****************************************
            





USE BLAT TO:

1) CHARACTERISE MIHG HUMAN NUCLEAR READS THAT DIDN'T MATCH THE 36.3 REFERENCE 

2) CHARACTERISE THE ERRORS IN THE NA18507 SEQUENCE RELATIVE TO GENERATED

    -   FLANKING REGION (GC)
    -   START POINT (ATGC)
 
 
 
</entry>



<entry [Fri May 8 14:17:56 EDT 2009] CONVERT BLAT OUTPUT TO GFF>



[syoung@solexa01 apps]$ locate blat
/store/home/syoung/base/apps/gff2aplot/bin/blat2gff.pl
/store/home/syoung/base/apps/gff2aplot/src/blat2gff.pl
/store/home/syoung/base/apps/sam/bioperl/bioperl-1.4/t/data/blat.psLayout3
/store/home/syoung/base/dev/dev/plmods/Bio-Pipeline/bioperl-pipeline/t/data/blat_dna.fa
/store/home/syoung/base/dev/dev/plmods/Bio-Pipeline/bioperl-run/t/data/blat_dna.fa
/usr/local/bin/blat2gff.pl
[syoung@solexa01 apps]$ 



</entry>



<entry [Fri May 8 11:04:56 EDT 2009] INSTALL BLAT FOR CHECKING WHICH READS MATCH REFERENCE WITH VARYING DEGREES OF IDENTITY>



REASONS FOR USING BLAT - FAST, SHORT MATCHES (WILL USE DEFAULT 11BP FRAGMENT SIZE)

1. FIGURE OUT WHAT THESE NON-ELAND HIT READS ARE UP TO

    FOR THESE SAMPLES:
    
    1) HUMAN NEUROLOGICAL DISEASE SAMPLE FROM MIHG SOLEXA (RUN 1, RUN 2)
    
    2) SRA DOWNLOADED SAMPLES FROM DIFFERENT LABS
    
    METHOD
    
    ELAND MISMATCHES --> BLAT : 1. GET PERCENTAGE WITH MORE THAN 2 ERRORS (3, 4, 5, ETC.)
                                2. GET POSITIONS OF ERRORS, ANY BIAS (5' OR 3'?)
                                3. GET GC/AT CONTENT OF MISMATCHES COMPARED TO ELAND MATCHES
                                
2. GET ERROR PROFILE FOR NA18507 READS AGAINST NA18507 CONSENSUS* TO USE IN TESTING SIMULATED READ GENERATORS LIKE metasim

* GENERATE NA18507 CONSENSUS USING DOWNLOADED SNP AND INDELS SUBSTITUTED INTO REFERENCE 36.3 HUMAN GENOME

DOWNLOAD BLAT

mkdir /nethome/syoung/base/apps/blat
cd /nethome/syoung/base/apps/blat
wget http://users.soe.ucsc.edu/~kent/src/blatSrc34.zip
unzip blatSrc34.zip
mv blatSrc v34
ls blat  gfClient  gfServer  hg  inc  jkOwnLib  lib  makefile  README  utils  webBlat

INSTALL 

1. echo $MACHTYPE
    x86_64-redhat-linux-gnu

2. Make the directory ~/bin/$MACHTYPE which is where the (non-web) executables will go.
   
   mkdir -p /nethome/syoung/base/apps/blat/v34/bin/x86_64-redhat-linux-gnu

3. Add this directory to your path.

    export PATH=/nethome/syoung/base/apps/blat/v34/bin/x86_64-redhat-linux-gnu:$PATH

4. Go to the lib directory.  If it doesn't already exist do a mkdir $MACHTYPE.

   mkdir -p /nethome/syoung/base/apps/blat/v34/lib/x86_64-redhat-linux-gnu


6. At the blatSrc directory type 'make'

make




[syoung@kronos v34]$ cat makefile 
all:
        cd lib && ${MAKE}
        cd jkOwnLib && ${MAKE}
        cd blat && $(MAKE)
        cd gfClient && $(MAKE)
        cd gfServer && $(MAKE)
        cd hg/pslPretty && $(MAKE)
        cd hg/pslReps && $(MAKE)
        cd hg/pslSort && $(MAKE)
        cd utils/nibFrag && $(MAKE)
        cd utils/faToNib && $(MAKE)
        cd utils/faToTwoBit && $(MAKE)
        cd utils/twoBitToFa && $(MAKE)
        cd utils/twoBitInfo && $(MAKE)
        cd webBlat && $(MAKE)

clean:
        rm -f */*.o */*/*.o


BLAT README

1. Unzip this to create a blatSrc directory.
2. Check that the environment variable MACHTYPE
   exists on your system.  It should on Unix.
   (And making this on non-Unix systems is beyond
   the scope of this README).  For a Linux
   system MACHTYPE will probably be 'i386', for
   and Alpha it will be 'alpha', for a Sun
   probably 'sparc'.  If necessary set up
   this environment variable.  Do this under the
   bash shell as so:
       MACHTYPE=something
       export MACHTYPE
   or under tcsh as so:
       setenv MACHTYPE something
3. Make the directory ~/bin/$MACHTYPE which is
   where the (non-web) executables will go.
   Add this directory to your path.
4. Go to the lib directory.  If it doesn't
   already exist do a mkdir $MACHTYPE.
5. If you're on an alpha system do a:
     setenv SOCKETLIB -lxnet
   on Solaris do
     setenv SOCKETLIB "-lsocket -lnsl"
   on SunOS do
     setenv SOCKETLIB "-lsocket -lnsl -lresolv"
   on Linux you can skip this step.
6. At the blatSrc directory type 'make'




</entry>



<entry [Fri May 8 11:04:56 EDT 2009] SYNTHETIC READS - ERROR FUNCTIONS>



Myers 1999 A dataset generator for whole genome shotgun sequencing
http://www.aaai.org/Papers/ISMB/1999/ISMB99-024.pdf



Evaluation of next generation sequencing platforms for population targeted sequencing studies
Harismendy et al 2009
http://genomebiology.com/2009/10/3/R32

Abstract

Background

Next generation sequencing (NGS) platforms are currently being utilized for targeted sequencing of candidate genes or genomic intervals to perform sequence-based association studies. To evaluate these platforms for this application, we analyzed human sequence generated by the Roche 454, Illumina GA, and the ABI SOLiD technologies for the same 260 kb in four individuals.
Results

Local sequence characteristics contribute to systematic variability in sequence coverage (>100-fold difference in per-base coverage), resulting in patterns for each NGS technology that are highly correlated between samples. A comparison of the base calls to 88 kb of overlapping ABI 3730xL Sanger sequence generated for the same samples showed that the NGS platforms all have high sensitivity, identifying >95% of variant sites. At high coverage, depth base calling errors are systematic, resulting from local sequence contexts; as the coverage is lowered additional 'random sampling' errors in base calling occur.
Conclusions

Our study provides important insights into systematic biases and data variability that need to be considered when utilizing NGS platforms for population targeted sequencing studies.


Background

The Sanger method [1] of sequencing by capillary electrophoresis using the ABI 3730xL platform has been employed in many historically significant large-scale sequencing projects and is considered the 'gold standard' in terms of both read length and sequencing accuracy [2]. Several next generation sequencing (NGS) technologies have recently emerged, including Roche 454, Illumina GA, and ABI SOLiD, which are able to generate three to four orders of magnitude more sequence and are considerably less expensive than the Sanger method on the ABI 3730xL platform (hereafter referred to as ABI Sanger) [2-4]. To date these new technologies have been successfully applied toward ChIP-sequencing to identify binding sites of DNA-associated proteins [5,6], RNA-sequencing to profile the mammalian transcriptome [7,8], as well as whole human genome sequencing [9-11]. Currently there is much interest in applying NGS platforms for targeted sequencing of specific candidate genes, intervals identified through single nucleotide polymorphism (SNP)-based association studies, or the entire human exome [12-15] in large numbers of individuals.

As population targeted sequencing studies are initiated, it is important to determine the issues that will be encountered in generating and analyzing data produced by NGS platforms for this application. Here, we generate 260 kb of targeted sequence in four samples using the manufacturer recommended and/or supplied sample library preparation methods, sequence generation, alignment tools, and base calling algorithms for the Roche 454, Illumina GA, and ABI SOLiD platforms (Figure 1). For each NGS technology we generated a saturating level of redundant sequence coverage, meaning that increased coverage is likely to have minimal, if any, effect on data quality and variant calling accuracies. We analyzed the sequences produced by each platform for per-base sequence coverage and for systematic biases giving rise to low coverage. We show that each NGS platform generates its own unique pattern of biased sequence coverage that is consistent between samples.

* For the short-read platforms, low coverage intervals tend to be in AT-rich repetitive sequences.

* We also performed a comparative analysis with sequence generated by the well-established ABI Sanger platform (Figure 1) to determine base calling accuracies and how average fold sequence coverage impacts base calling errors. Although the three NGS technologies correctly identify >95% of variant alleles, the average sequence coverage required to achieve this performance is greater than the targeted levels of most current studies.



maq
---


Simulation Related

    fakemut 	maq fakemut [-r mutrate] [-R indelfrac] in.ref.fasta > out.fakeref.fasta 2> out.fake.snp

    Randomly introduce substitutions and indels to the reference. Substitutions and sinlge base-pair indels can be added.

    OPTIONS:
    -r FLOAT 	Mutation rate [0.001]
    -R FLOAT 	Fraction of mutations to be indels [0.1]
    simutrain 	maq simutrain out.simupars.dat in.read.fastq

    Estimate/train parameters for read simulation.
    simulate 	maq simulate [-d insize] [-s stdev] [-N nReads] [-1 readLen1] [-2 readLen2] [-r mutRate] [-R indelFrac] [-h] out.read1.fastq out.read2.fastq in.ref.fasta in.simupars.dat

    Simulate paired end reads. File in.simupars.dat determines the read lengths and quality distribution. It is generated from simutrain, or can be downloaded from Maq website. In the output read files, a read name consists of the reference sequence name and the outer coordinates of the pair of simulated reads. By default, simulate assumes reads come from a diploid sequence which is generated by adding two different sets of mutations, including one base-pair indels, to in.ref.fasta.

    OPTIONS:
    -d INT 	mean of the outer distance of insert sizes [170]
    -s INT 	standard deviation of insert sizes [20]
    -N INT 	number of pairs of reads to be generated [1000000]
    -1 INT 	length of the first read [set by in.simupars.dat]
    -2 INT 	length of the second read [set by in.simupars.dat]
    -r FLOAT 	mutation rate [0.001]
    -R FLOAT 	fraction of 1bp indels [0.1]
    -h 	add all mutations to in.ref.fasta and generate reads from the single mutated sequence (haploid mode)

    NOTE:
    * 	Reads generated from this command are independent, which deviates from the truth. Whereas alignment evaluation is less affected by this, evaluation on SNP calling should be performed with caution. Error dependency may be one of the major causes of wrong SNP calls.
    simustat 	maq simustat in.simu-aln.map > out.simustat

    Evaluate mapping qualities from simulated reads.
    
    



random selection
----------------




EXAMPLE OF USE OF RANDOMLY SELECTED READS:

High-throughput sequence alignment using Graphics Processing
Units
Michael C Schatz*†1,2, Cole Trapnell†1,2, Arthur L Delcher1,2 and
Amitabh Varshney2
Published: 10 December 2007

The first test scenario was to align synthetically constructed
reads to a bacterial genome. We used synthetic
reads in order to explore MUMmerGPU's performance in
the absence of errors and over a wider variety of query
lengths then are available with genuine reads. The synthetic
test reads consisted of 50-, 100-, 200-, 400-, and
800-character substrings (uniformly randomly) sampled
from the Bacillus anthracis genome (GenBank ID:
NC_003997.3). Thus, each read exactly aligns to the
genome end-to-end at least once, and possibly more
depending on the repeat content of the genome. When
aligning each of the five sets of reads, we used l equal to
the read size for the set. Each set contained exactly
250,000,000 base pairs of query sequence divided evenly
among all the reads in the set.



metasim
-------
produces simulated metagenome reads from input genomes

RELATED TO:

genfrag.pl
http://www.mirrorservice.org/sites/download.sourceforge.net/pub/sourceforge/t/ti/tigr-closure/

celsim
OLD PROGRAM FROM 1994, UNSOPHISTICATED ERROR PROFILE?


Simulation of reads with empirical models

Using empirical data, MetaSim provides an error model for the
short reads of the Illumina technology.

As an additional feature, MetaSim includes an empirical error
model that allows the incorporation of user-defined error statistics.
The probability of an occurrence of a sequencing error often
depends on the position of the erroneous base and its surrounding
bases. The program GenFrag [35] originally developed an error

model which incorporates different error types (deletion, insertion,
substitution) at certain positions with empirical error probabilities.
MetaSim adopts this general approach. The error model is
based on mappings (error curves) that assign error rates to specific
base positions. Each mapping has three parameters (the last two
are optional):

    N type of error,
    N base at the position where the error occurs and
    N base preceding the position where the error occurs.

In this way, 48 independent mappings can be individually
determined. In addition, in case of a substitution error the user can
specify the probability of integrating a particular base depending
on the type of the base at the error position and the preceding
base.


MetaSim—A Sequencing Simulator for Genomics and Metagenomics
Daniel C. Richter1*, Felix Ott1, Alexander F. Auch1, Ramona Schmid2, Daniel H. Huson1
1 ZBIT- Center for Bioinformatics Tübingen, University of Tübingen, Tübingen, Germany, 2 Boehringer Ingelheim Pharma GmbH & Co. KG, Biberach, Germany


Finally, for the construction of a realistic read data set, MetaSim includes a versatile read sequencing simulator. The user is able to choose from different (adaptable) error models of current sequencing technologies (e.g. Sanger [28], [29], Roche's 454 [7] and Illumina (former Solexa) [30]).


Abstract 
Background
The new research field of metagenomics is providing exciting insights into various, previously unclassified ecological systems. Next-generation sequencing technologies are producing a rapid increase of environmental data in public databases. There is great need for specialized software solutions and statistical methods for dealing with complex metagenome data sets.

Methodology/Principal Findings
To facilitate the development and improvement of metagenomic tools and the planning of metagenomic projects, we introduce a sequencing simulator called MetaSim. Our software can be used to generate collections of synthetic reads that reflect the diverse taxonomical composition of typical metagenome data sets. Based on a database of given genomes, the program allows the user to design a metagenome by specifying the number of genomes present at different levels of the NCBI taxonomy, and then to collect reads from the metagenome using a simulation of a number of different sequencing technologies. A population sampler optionally produces evolved sequences based on source genomes and a given evolutionary tree.

Conclusions/Significance
MetaSim allows the user to simulate individual read datasets that can be used as standardized test scenarios for planning sequencing projects or for benchmarking metagenomic software.



Dohm 2008
Substantial biases in ultra-short read data sets from high-throughput DNA sequencing

Novel sequencing technologies permit the rapid production of large sequence data sets. These technologies are likely to revolutionize genetics and biomedical research, but a thorough characterization of the ultra-short read output is necessary. We generated and analyzed two Illumina 1G ultra-short read data sets, i.e. 2.8 million 27mer reads from a Beta vulgaris genomic clone and 12.3 million 36mers from the Helicobacter acinonychis genome. We found that error rates range from 0.3% at the beginning of reads to 3.8% at the end of reads. Wrong base calls are frequently preceded by base G. Base substitution error frequencies vary by 10- to 11-fold, with A > C transversion being among the most frequent and C > G transversions among the least frequent substitution errors. Insertions and deletions of single bases occur at very low rates. When simulating re-sequencing we found a 20-fold sequencing coverage to be sufficient to compensate errors by correct reads. The read coverage of the sequenced regions is biased; the highest read density was found in intervals with elevated GC content. High Solexa quality scores are over-optimistic and low scores underestimate the data quality. Our results show different types of biases and ways to detect them. Such biases have implications on the use and interpretation of Solexa data, for de novo sequencing, re-sequencing, the identification of single nucleotide polymorphisms and DNA methylation sites, as well as for transcriptome analysis.

Perl scripts:

    - Generated 12.288 million 36-mer reads from Helicobacter acinonychis on an Illumina 1G sequencing device
        - The Helicobacter genome is 1.55 Mbp in size and has a GC content of 38%.
        - A high-quality reference sequence for Helicobacter is available (GenBank NC_008229 [GenBank])
        - ELAND software selected the 8.389 million 32-mer reads to be uniquely matched against the Helicobacter reference sequence with zero, one or two mismatches (labeled U0, U1 or U2, respectively, see Figure 1b).
        
        - Additionally, generated a 27-mer read data set for the sugar beet (Beta vulgaris) bacterial artificial chromosome (BAC) clone ZR-47B15.
        - The data set consists of 2.788 million reads, 2.156 million of which were labeled U0, U1 or U2 in the ELAND output (Figure 1a).
        
        - The Sanger reference sequence in finished quality of this BAC insert consists of 10 9563 bases with 34.85% GC (Dohm et al., manuscript submitted for publication). For all uniquely matched reads, ELAND reports the match position in the reference sequence as well as the error position(s) in the read.

        - Sequence characteristics and total number of reads starting in a sliding window of 1 kbp in width. Found a correlation of read coverage and GC content in both data sets. In regions of elevated GC content the number of reads was increased. For instance, windows with a GC content of 40% contain almost twice as many reads as windows with 30% GC in the Beta data set
    
        - Tested whether the distributions shown in Figure 3 are compatible with a uniform distribution of reads across the target sequences. We have applied a {chi}2-test (goodness of fit) to reject the hypothesis that reads have the same probability to fall into equally sized regions of the target sequence (P < 1e–10 even when dividing target sequences in only five regions).
        
    
   - extract and process information from ELAND output files
   - find positions of reads that can be aligned more than once to the reference sequence without mismatches (the positions of those reads are not reported by ELAND)
    - detection of deletions and insertions of single nucleotides in otherwise error-free reads
    - analysis of quality values per base call



method ???
International Journal of Bioinformatics Research and Applications
 	 Issue: 	 Volume 5, Number 2 / 2009
 	 Pages: 	 224 - 237
 	URL: 	Linking Options
Correcting short reads with high error rates for improved sequencing result

Thomas K.F. Wong A1, T.W. Lam A2, P.Y. Chan A3, S.M. Yiu A4

A1 Faculty of Engineering, Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong.
A2 Faculty of Engineering, Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong.
A3 Faculty of Engineering, Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong.
A4 Faculty of Engineering, Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong
Abstract:

In the sequencing process, reads of the sequence are generated, then assembled to form contigs. New technologies can produce reads faster with lower cost and higher coverage. However, these reads are shorter. With errors, short reads make the assembly step more difficult. Chaisson et al. (2004) proposed an algorithm to correct the reads prior to the assembly step. The result is not satisfactory when the error rate is high (e.g., ?3%). We improve their approach to handle reads of higher error rates. Experimental results show that our approach is much more effective in correcting errors, producing contigs of higher quality.





</entry>



<entry [Sun Apr 19 22:10:56 EDT 2009] SELECT HUMAN SAMPLES FROM SHORT READ ARCHIVE>




******************
TEST DATA CRITERIA
******************

1. Pedigree (Hapmap, 1000 genomes)
2. SRA, all platforms - 454, Solexa, Solid (and Sanger?)
3. Papers


1) Amplicons of 6 human genes (Harismendy et al 2009)
=====================================================

1. Pedigree - none

2. SRA - ??? email sent to kfrazer@scripps.edu

3. Papers - Harismendy et al 2009, Evaluation of next generation sequencing platforms for population targeted sequencing studies

Sample
------

NextGen
*******
Twenty-eight LR-PCR reactions were performed to amplify six genomic intervals spanning a total of 266 kb in each of four DNA samples (NA17275, NA17460, NA17156, and NA17773) obtained from the Coriell Institute [32] (Additional data file 2).

Following LR-PCR, the 28 amplicons generated using a single DNA sample template, ranging in size from 3,088 bp to 14,477 bp, were quantified, combined in equimolar amounts, and used to create libraries for Roche 454, Illumina GA and ABI SOLiD sequencing.

NB: ADJUST FOR BIAS TOWARDS LESS REPEATS AND MORE CODING SEQUENCE IN SAMPLE - SEE FIGURE 1: "The 260 kb examined in this study is representative of human sequences containing 38% repeats and 4% coding sequence compared with 47% and 1%, respectively, genome-wide."


Sanger
******
We used an existing data set deposited by JCVI and performed under the auspices of the National Heart, Lung and Blood Re-sequencing and Genotyping program [34]. The data set included 88 kb of non-contiguous sequence encompassing the exons and the intronic sequence conserved with mouse and rat in the K+/Na+ channel proteins produced by employing 273 short-range PCR reactions generating amplicons averaging 418 bp in length.


Alignment
---------

454 - Newbler
The Roche 454 laboratory methods and protocols used were as described by Rothberg and coworkers [23]. The reads produced by the Roche 454 FLX platform were mapped to the reference sequence using the algorithm Newbler version 1.1.03.19 (provided by Roche), unless stated otherwise

Solexa - MAQ
The Illumina GA libraries were prepared according to the manufacturer's instructions from the 28 equimolar pooled PCR products except for the fragmentation step (Additional data file 2). The Illumina GA reads were aligned with MAQ 0.6.2 [33], unless stated otherwise.

SOLiD - Corona-Lite
Long mate pair (LMP) libraries DNA libraries were generated from the four 28 equimolar pooled amplicon samples and end sequenced using standard ABI SOLiD protocols at Applied Biosystems in Beverly, MA. For each sample, ABI aligned the sequence reads to the reference sequence and mate-pairing information was not employed in this project. The aligned reads and the number of calls per base for each position were used for data analysis (Additional data file 2).


SNPs
----

Calling genotypes in the NGS sequence data

We define the alternate allele as the most commonly called base (which is not the reference base) for a given position in the reference sequence. Then, the AARF is the fraction of reads corresponding to the alternate allele.

Positions called as reference homozygote by ABI Sanger have AARFs close to 0% by the NGS technologies (Supplemental Figure 2 in Additional data file 3). Also, positions called as alternate homozygous by ABI Sanger have AARFs near or at 100% by the NGS technologies. The AARFs for heterozygous calls by ABI Sanger is centered at 50% for Roche 454 and Illumina GA; for ABI SOLiD it is centered at 42% (Additional data file 2). Upon independent inspection of the three technologies, most ABI Sanger-called heterozygotes fell in the range 20-80%. Thus, for the NGS technologies, utilizing only high quality bases we call positions with AARFs between 20% and 80% as heterozygous, positions with AARFs >80% as homozygous alternate, and positions with AARFs <20% as homozygous reference (Additional data file 2).


Performance
-----------

Definitions of performance metrics

In order to assess the performance of the sequencing technologies, we define several metrics.

Comparing a genotyping microarray to a sequencing technology
Genotype accuracy

We genotyped the four samples on the Illumina Hap550 microarray according to specifications of the manufacturer. We compared the genotype calls of the SNPs on the Hap550 microarray with the genotypes observed from sequencing (Supplemental Table 8 in Additional data file 1). Genotype accuracy is defined as: (Number of genotypes matching exactly between Illumina Hap550 and a sequencing technology)/(Number of compared positions).


Metrics for comparing a NGS sequencing technology with ABI Sanger

We initially assumed the ABI Sanger sequence data are correct because it is an established method with the longest history [2]. Upon further analysis, we found that this assumption was not always true; there were some positions incorrectly called by ABI Sanger, but correctly called by the NGS technologies (see Results). We refer to Table 1 annotations to clarify these definitions.

    Table 1. Annotations of the genotypes differences to illustrate the definition of the metrics used to compare ABI Sanger and NGS Technologies
    Sequencing accuracy

This is defined as the number of concordant calls between ABI Sanger and a NGS technology. Following the diagram above, this is calculated as (A1 + B2 + C3)/Total, where Total is defined as the number of positions with genotype calls by both technologies, or (A1 + A2 + A3 + B1 + B2 + B3 + C1 + C2 + C3). Because the sequencing accuracy metric is dominated by the concordance of a large number of homozygous reference calls (A1), this metric tends to be very near 1.
Variant accuracy

Because 'sequencing accuracy' tends to be dominated by the large number of homozygous reference calls, we define another metric called 'variant accuracy'. Variant accuracy is restricted to the variant positions called by ABI Sanger and is defined as: (B2 + C3)/(A2 +A3 + B2 + B3 + C2 + C3).
False positive rate of variants (false positive rate)

We define a false positive when the NGS technology calls a variant where ABI Sanger calls a homozygous reference. The false positive rate is calculated as (B1 + C1)/(B1 + B2 + B3 + C1 + C2+ C3).
False negative rate of variants (false negative rate)

We define a false negative when ABI Sanger detects a variant, but the NGS method calls this locus as a homozygous reference. The false negative rate is calculated as (A2 + A3)/(A2 + A3 + B2 + B3 + C2 + C3).
Variant discrepancy rate

We define the variant discrepancy rate as (B3 + C2)/(B2 + B3 + C2 + C3). This metric reflects ABI Sanger variant positions that are also detected by the NGS technology, but where the genotype calls disagree.
Coverage rate

The fraction of positions with genotype calls is defined as 1-(D1 + D2 + D3)/(A1 + A2 + A3 + B1 + B2 + B3 + C1 + C2 + C3 + D1 + D2 + D3).
ABI Sanger false positive rate

We define a ABI Sanger false positive when ABI Sanger calls a variant but all three NGS technologies call the locus as homozygous reference. We assume the NGS technologies to be correct, and this was confirmed by re-inspection of the ABI Sanger traces. The ABI Sanger false positive rate is calculated as follows. The numerator is the number of loci that are called as homozygous reference by all three NGS technologies, but as a variant in ABI Sanger. In the denominator, we consider all positions that were called as variant by Sanger and also had a genotype call by all three NGS technologies.
ABI Sanger false negative rate

We define a ABI Sanger false negative as a locus where the initial call by ABI Sanger is homozygous reference but all three NGS technologies detect a variant at this locus. In the numerator of the ABI Sanger false negative rate, we count the number of variant loci that are identified by all three NGS technologies but called as homozygous reference by ABI Sanger. We note that zygosity may not agree among the three NGS technologies, but if all three technologies identify a variant at the position, the locus is included (Supplemental Table 12 in Additional data file 1). The denominator represents the number of loci called as variant by all three NGS technologies (although the zygosity may differ).


Simulations
-----------

Simulations were performed in order to assess performance of each NGS platform at lower coverage depths. For each simulation, we randomly sampled a subset of the reads and recalled genotypes. The size of the subset was determined by the desired coverage depth.
Inferring coverage at various error rate degradations

To obtain the coverage depths in Figure 5, we first examined the error rate at the maximal simulated coverage. For 50% error rate degradation, we multiplied the error rate at the maximal coverage by 1.5 to get the desired error rate. For 10% error rate degradation, we multiplied the error rate at the maximal coverage by 1.1 to get the desired error rate. We then examined the error rates from the simulations at different coverage depths, and interpolated what coverage depth corresponds to the desired error rate. For example, the false positive error rate for Illumina GA at 140× from the simulations is 0.073. At 50% error rate degradation, the false positive rate is 0.110. The false positive rates at coverage depths of 60× and 80× are 0.118 and 0.099, respectively, so we know that a coverage depth within the range of 60× to 80× will give a false positive rate of 0.110. Using linear interpolation, we deduce that a coverage depth of 68× gives a false positive rate of 0.110, and this is reported in Figure 5.

The error rates for Illumina GA and ABI SOLiD at maximum simulated coverage are slightly higher than what was experimentally observed. The additional errors observed in the simulations are largely associated with low coverage regions and are different between iterations, whereas the systematic errors present in the experimental data set at full coverage are shared between iterations. This shows that the simulation produces random sampling errors, directly associated with low coverage regions.



2) NA18507 (YRI family Y009)
============================


1. Pedigree - yes

African Human Genome Data Summary

NA18507 father
NA18506 child ****** NOT YET AVAILABLE!!
NA18508 mother

2. Short read archive - available except child

http://0-www.ncbi.nlm.nih.gov.millennium.unicatt.it/Traces/sra/sra.cgi?cmd=table&f=sample&m=data&s=sample

3. Paper - Bentley, 2008. Accurate whole human genome sequencing using reversible terminator chemistry


38x coverage of NA18507 (achieved in 8 weeks)
All paired and mate pair reads; 35-50 bases, 0.2 & 2kb gap sizes
Data submitted to NCBI (SRA000271)
17x coverage of other members of trio for public release

SRP000239  Human genome sequencing of an African male individual (HapMap: NA18507) using the Illumina Genome Analyzer
http://www.dtd.nlm.nih.gov/Traces/sra/sra.cgi?study=SRP000239

Study Type: Whole Genome Sequencing
Submission: SRA000271 by ILLUMINA on 2008-11-05T22:22:00Z
Abstract: We have generated paired-end sequence data covering the genome of an African male individual to a sequence depth of more than 40-fold using the Illumina Genome Analyzer. This individual is a member of the population samples described in the PhaseI and PhaseII HapMap Projects and is from the Yoruba in Ibadan, Nigeria (abbreviation: YRI). The DNA identifier for this individual is NA18507
Description: We obtained the DNA sample NA18507 from The Coriell Institute for Medical Research. We generated two sequencing libraries. The first had a median insert size of 200 bp and was produced following random fragmentation and gel fractionation of the genomic DNA. This library was used for generating most of the data (38x coverage). The second library provided longer range paired-read information. For this library fragments of 2 kb were produced by random fragmentation and gel fractionation. These fragments were circularised and fragmented and the junction fragments were recovered. Paired-end sequencing of the two libraries was carried out using the Illumina Genome Analyzer. We carried out purity-filtering (PF) to remove mixed reads, where two or more different template molecules are close enough on the surface of the flow-cell to form a mixed or overlapping cluster. No other filtering of the data has been carried out prior to submission. The data contain 3.77 billion PF reads from the short-insert library and 296 million PF reads from the long-insert library


INSDC Project id: 29429
External Links: NA18507

RUNs for each experiment

Insert  Accession	Spots	Bases
200bp    SRX000600	1.5G	209.0G
200bp   SRX000601	26.4M	3.9G
200bp   SRX000602	121.7M	18.0G
200bp   SRX000603	55.9M	9.2G
2kb	    SRX001539	52.0M	7.5G  **** LONG
2kb	    SRX001540	96.1M	13.8G **** LONG
Total:      6		1.8G	261.3G


DOWNLOAD THE RUNS

FTP directory

ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600
ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000601
ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000602
ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000603
ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX001539
ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX001540


deepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/SRA000271

    ...
    SRR006561_2.fastq.gz
    SRR006562_1.fastq.gz
    SRR006562_2.fastq.gz
    Files found: 374
    Downloading...   
    wget ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600/SRR002271_1.fastq.gz
    --16:47:51--  ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600/SRR002271_1.fastq.gz
               => `SRR002271_1.fastq.gz'
    Resolving ftp.ncbi.nlm.nih.gov... 130.14.29.30
    Connecting to ftp.ncbi.nlm.nih.gov|130.14.29.30|:21... connected.
    Logging in as anonymous ... Logged in!
    ==> SYST ... done.    ==> PWD ... done.
    ==> TYPE I ... done.  ==> CWD /sra/Studies/SRP000/SRP000239/SRX000600 ... done.
    ==> SIZE SRR002271_1.fastq.gz ... 1132261985
    ==> PASV ... done.    ==> RETR SRR002271_1.fastq.gz ... done.
    Length: 1132261985 (1.1G)
    
    100%[===========================================================>] 1,132,261,985 6.16M/s   in 3m 57s 
    ...
    
    
ls -alh

    total 4.1G
    drwxrwx---+ 3 syoung  1072   68 May  6 16:55 .
    drwxr-x---+ 4 syoung  1072   35 May  6 16:38 ..
    -rw-rw----+ 1 syoung users 3.8G May  6 16:52 SRR002271_1.fastq
    -rw-rw----+ 1 syoung users 281M May  6 16:53 SRR002271_2.fastq.gz
    drwxrwx---+ 2 syoung  1072  16K May  6 16:40 temp



screen -S deepvac-SRX000600

mkdir SRX000600
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000600




ON PLUTO:

screen -S deepvac-SRX000601

cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
mkdir SRX000601
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000601 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000601

    Run time: 00:46:09
    Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
    9:39PM, 7 May 2009
    ****************************************


cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
mkdir SRX000602
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000602 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000602

    Run time: 01:57:08
    Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
    11:17PM, 6 May 2009
    ****************************************


cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
mkdir SRX000603
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000603 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX000603

    Run time: 00:39:20
    Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
    0:12AM, 7 May 2009
    ****************************************

cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
mkdir SRX001539
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX001539 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX001539

    Length: 882826406 (842M)
    100%[=============================================================>] 882,826,406 2.88M/s   in 5m 59s    
    00:00:28 (2.34 MB/s) - `SRR005719_2.fastq.gz' saved [882826406]
    
    Run time: 00:26:15
    Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
    0:00AM, 7 May 2009
    ****************************************


cd /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507
mkdir SRX001540
/store/Data01/NGS/syoung/base/bin/utils/deepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX001540 --outputdir /store/Data01/NGS/syoung/base/pipeline/SRA/NA18507/SRX001540

    Run time: 00:28:34
    Completed /store/Data01/NGS/syoung/base/bin/utils/deepvac.pl
    0:04AM, 7 May 2009
    ****************************************


DOWNLOADED SNPS FOR NA18507:

http://www.ncbi.nlm.nih.gov/SNP/snp_viewBatch.cgi?sbid=857037&all=1&batch=ILLUMINA-UK|ILLUMINA_WTSI:NA18507_c1&task=download&sortOrder=chr_rs_ss&go=go
http://www.ncbi.nlm.nih.gov/SNP/snp_viewTable.cgi?type=contact&handle=ILLUMINA-UK

WHICH I ARRIVED AT THROUGH:

Illumina Human Genome Sequencing Data
http://www.illumina.com/HumanGenome

First Yoruban human genome NA18507 
Described in Bentley DR, Balasubramanian S, Swerdlow HP, Smith GP, Milton J, et al. (2008) Accurate whole human genome sequencing using reversible terminator chemistry. Nature 456: 53-59. 



DOWNLOADED SNPS AND INDELS FOR NA18507 FROM SANGER:

ftp://ftp.sanger.ac.uk/pub/rd/NA18507/NA18507.indel.gz

ftp://ftp.sanger.ac.uk/pub/rd/NA18507/NA18507.snp.gz

Sanger README:
ftp://ftp.sanger.ac.uk/pub/rd/NA18507/00README.txt

NA18507.snp.gz
==============

Each line consists of chromosome, position, reference base, consensus
base, Phred-like consensus quality, read depth, the average number of
hits of reads covering this position, the highest mapping quality of the
reads covering the position, the minimum consensus quality in the 3bp
flanking regions at each side of the site (6bp in total), the second
best call, log likelihood ratio of the second best and the third best
call, and the third best call.

NA18507.indel.gz
================

Each line consists of chromosome, position, genotype and the score. The
higher the score the more reliable the call.

NB: AT THE BOTTOM OF THE FILE, NT_113898 IS THE CHROMOSOME ENTRY

Contig	 :	 NT_113898		
Homo sapiens chromosome 6 genomic contig, reference assembly.
http://howdy.jst.go.jp/HOWDYCL//HOWDY.pl?Cls=Contig&Key=UKEY&Val=nt_113898



3) Human X chromosome NA07340 


1. Pedigree - CEPH/Utah resident with ancestry from northern and western Europe. 

2. Sequences accessible - ftp://ftp.era.ebi.ac.uk/ERA000035/

3. Paper - Bentley D, et al.also describes sequence of the X chromosomes from the female sample NA07340 (CEPH/Utah resident with ancestry from northern and western Europe). 


X chromosome data are freely available from ERA,
accession ERA000035








TRIED DOWNLOADING WITH CLUSTERDEEPVAC BUT DID NOT RUN BECAUSE THE HEAD NODE IS THE BOTTLENECK, SO USED deepvac.pl ON pluto INSTEAD.

clusterDeepvac.pl --url ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600 --outputdir /mihg/data/NGS/syoung/SRA/SRA000271 --qsub "qsub -q psmall"

    Doing get(ftp://ftp.ncbi.nlm.nih.gov/sra/Studies/SRP000/SRP000239/SRX000600)
    Moving to output directory: /mihg/data/NGS/syoung/SRA/SRA000271
    Files found: 374
    Downloading...   
    qsub -q psmall wget-SRR002271_1.fastq.gz.sh.kronos.ccs.miami.edu
    qsub -q psmall wget-SRR002271_2.fastq.gz.sh
    ...
    qsub -q psmall wget-SRR006562_2.fastq.gz.sh
    24604.kronos.ccs.miami.edu
    
    Run time: 00:13:38
    Completed /nethome/syoung/base/bin/utils/clusterDeepvac.pl
    0:35AM, 6 May 2009
    ****************************************
    






ALTERNATE DOWNLOAD URLs:

ftp://ftp.1000genomes.ebi.ac.uk/    ### not working

ftp://ftp-trace.ncbi.nih.gov/1000genomes/


********** ftp://ftp-trace.ncbi.nih.gov/1000genomes/README.ftp_structure

The 1000genomes project has two mirrored ftp sites:
ftp://ftp.1000genomes.ebi.ac.uk and ftp://ftp-trace.ncbi.nih.gov/1000genomes/ 

These follow this basic structure.

At the top level there are 3 directories:

data
release
technical
changelog_details

==== data ====:
 contains a subdirectory per individual of the project. Each individual directory
contains series of subdirectories for different data sets like sequence reads, sequence alignments etc.

e.g  ftp://ftp.1000genomes.ebi.ac.uk/data/NA12878/sequence_reads/SRR003082.recal_1.fastq.gz 
or   ftp://ftp-trace.ncbi.nih.gov/1000genomes/data/NA12878/sequence_reads/SRR003082.recal_1.fastq.gz

==== release ==== 
 contains dated directories which contain analysis results sets released on
that date plus readmes explaining how those data sets were produced.

e.g ftp://ftp.1000genomes.ebi.ac.uk/release/2008_12/
or  ftp://ftp-trace.ncbi.nih.gov/1000genomes/release/2008_12/

==== technical ==== 
 contains subdirectories for other data sets like simulations or files for
method development interm data sets etc.

e.g ftp://ftp.1000genomes.ebi.ac.uk/technical/simulations
or  ftp://ftp-trace.ncbi.nih.gov/1000genomes/technical/simulations

=== changelog_details ===

In order to make the main root-level CHANGELOG human-readable, and scrollable, when changes are made
involving lareg moves or renames of files, these are referenced in the CHANGELOG and placed in this
changelog_details directory. Wherever possible (in all cases so far) these will be in programmatically 
parseable format. Thus far they are all have column 1: old file location, column 2: new file location,
which will also allow for renaming.


=== Index ===

The volume of data generated by 1000genomes project is unprecedented. Therefore in order 
to find and easily download the sequence_read files you need an index file is provided: 
ftp://ftp.1000genomes.ebi.ac.uk/sequence.index or
ftp://ftp-trace.ncbi.nih.gov/1000genomes/sequence.index 

This is a tab-separated file whose format is documented here: 
ftp://ftp.1000genomes.ebi.ac.uk/README.sequence.index  or
ftp://ftp-trace.ncbi.nih.gov/1000genomes/README.sequence.index

This file should provide you with sufficient data to download subsets of files by 
individual, pilot, technology etc. This index also contains the md5s for the fastq 
files


mother NA18508
--------------

http://www.dtd.nlm.nih.gov/Traces/sra/sra.cgi?study=SRX003971


SHORT READ ftp DOWNLOAD

ftp://ftp.ncbi.nih.gov/pub/TraceDB/ShortRead



DOWNLOAD FASTQ FROM HERE
ftp://ftp.ncbi.nih.gov/pub/TraceDB/ShortRead/SRA000271/fastq/ 

    Index of /pub/TraceDB/ShortRead/SRA000271/fastq/
    
    Name	Size	Date Modified
    [parent directory]		
    200x36x36-071113_EAS56_0053-s_1_1.fastq.gz	167.5 MB	5/20/08 8:00:00 PM
    200x36x36-071113_EAS56_0053-s_1_2.fastq.gz	180.5 MB	5/20/08 8:00:00 PM
    200x36x36-071113_EAS56_0053-s_2_1.fastq.gz	183 MB	5/20/08 8:00:00 PM
    200x36x36-071113_EAS56_0053-s_2_2.fastq.gz	193.8 MB	5/20/08 8:00:00 PM
    200x36x36-071113_EAS56_0053-s_3_1.fastq.gz	190.2 MB	5/20/08 8:00:00 PM
    200x36x36-071113_EAS56_0053-s_3_2.fastq.gz	199.2 MB	5/20/08 8:00:00 PM
    ...

mkdir -p /mihg/data/NGS/syoung/SRA/SRA000271
cd /mihg/data/NGS/syoung/SRA/SRA000271
deepvac.pl --url ftp://ftp.ncbi.nih.gov/pub/TraceDB/ShortRead/SRA000271/fastq/ --outputdir /mihg/data/NGS/syoung/SRA/SRA000271


CHECKED FASTQ FILE:

head 200x36x36-071113_EAS56_0053-s_1_1.fastq 
    @071113_EAS56_0053:1:1:756:463
    GTGATTAGTGAAACATAAAATAGTTTCATGTTGAAA
    +
    IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIGIAI
    @071113_EAS56_0053:1:1:813:752
    GTGGGAAAAACTGAAATACATTGCTTATGGATTCAT
    +
    IIIIIIIIIIIIIIIIIIIIIIIIIIIIIA?II/%I
    @071113_EAS56_0053:1:1:556:366
    TTTTCTTGATTTCATTTTAGCACAATCATTAATTAC

records 200x36x36-071113_EAS56_0053-s_1_1.fastq "@"
5840389

lines 200x36x36-071113_EAS56_0053-s_1_1.fastq 
17020968



Bentley et al 2008. Accurate whole human genome sequencing using reversible terminator chemistry

DNA samples (NA07340 and NA18507) and cell line (GM07340) were obtained from Coriell Repositories. DNA samples were genotyped on the HM550 array and the results compared to publicly available data to confirm their identity before use. Methods for DNA manipulation, including sample preparation, formation of single-molecule arrays, cluster growth and sequencing were all developed during this study and formed the basis for the standard protocols now available from Illumina, Inc. All sequencing was performed on Illumina GA1s equipped with a one-megapixel camera. All purity filtered read data are available for download from the Short Read Archive at NCBI or from the European Short Read Archive (ERA) at the EBI.












</entry>



<entry [Sun Apr 19 22:10:56 EDT 2009] HOW DIFFERENT ALIGNERS TREAT PAIRED ENDS>




http://seqanswers.com/forums/showthread.php?t=1600


Actually there are a lot to say about paired-end mapping. This is where the accuracy of different aligners differs. The algorithms can be classified into four groups.

a) Eland-like strategy. Eland finds up to 10 equally best hits first and then check which pair (10x10 in total) is consistent. SSAHA2 uses a similar strategy, but seeing more top hits.

b) SOAP-like strategy. SOAP finds almost all the hits and then pair them. I do not know whether it may map a read to a suboptimal position if its mate is hanging around. I am sure SOAP-2.0.1 and BWA do this if necessary. You can say a) and b) are essentially the same, but only b) is useful to anchor reads in repeats.

c) MAQ-like strategy. MAQ does not find all the single-end hits first. It pairs the reads while doing the alignment. For programs indexing reads, this strategy is more effective and efficient than collecting all the single-end hits first.

d) We can map one end first and then do local alignment around the region pointed by the mapped reads. This strategy is usually combined with the previous. I believe NovoAlign/MAQ/BWA use this strategy as a complement to other strategies.

For short reads, proper pairing increases the coverage of the genome and substantially reduce false alignments.


</entry>



<entry [Sun Apr 19 22:10:56 EDT 2009] Unbiased Comparisons of Short-Read Aligners>




In summary, there are a number of competing tools for short read alignment, each with its own set of strengths, weaknesses, and caveats. It’s hard to trust any benchmarking comparison on tools like these because usually, it’s the developers of one of the tools that publish them. Here’s an idea: what if NHGRI, Illumina, or another group put together a short-read-aligning contest? They generate a few short-read data sets: real, simulated, with/without errors, with/without SNPs and indels, etc. Then, the developers of each aligner are invited to throw their best efforts at it. Every group submits the results to a DCC, which analyzes the results in a simple, unbiased way: # of reads placed correctly/incorrectly. # of SNPs/indels detected, missed, or false-positives. The results are published on a web site or in the literature for all to see. Yeah, I know, there are hurdles, like the fact that most proprietary tool developers would probably chicken out of an unbiased head-to-head comparison, given the stakes. But wouldn’t it be nice to know the results? Unless that happens, however, I think Heng’s analysis is about as unbiased as can be.



</entry>



<entry [Sun Apr 19 12:51:56 EDT 2009] MAQ Simulation Related and CHECK SYSTEMATIC ERROR OF SEQUENCER>



USAGE:

fakemut maq fakemut [-r mutrate] [-R indelfrac] in.ref.fasta > out.fakeref.fasta 2> out.fake.snp

Randomly introduce substitutions and indels to the reference. Substitutions and sinlge basepair
indels can be added.
OPTIONS:
-r FLOAT Mutation rate [0.001]
-R FLOAT Fraction of mutations to be indels [0.1]



simutrain maq simutrain out.simupars.dat in.read.fastq

Estimate/train parameters for read simulation.



simulate maq simulate [-d insize] [-s stdev] [-N nReads] [-1 readLen1] [-2 readLen2] [-r mutRate]

[-R indelFrac] [-h] out.read1.fastq out.read2.fastq in.ref.fasta in.simupars.dat

Simulate paired end reads. File in.simupars.dat determines the read lengths and quality distribution.
It is generated from simutrain, or can be downloaded from Maq website. In the output
read ?les, a read name consists of the reference sequence name and the outer coordinates
of the pair of simulated reads. By default, simulate assumes reads come from a diploid
sequence which is generated by adding two different sets of mutations, including one basepair
indels, to in.ref.fasta.
    OPTIONS:
    -d INT mean of the outer distance of insert sizes [170]
    -s INT standard deviation of insert sizes [20]
    -N INT number of pairs of reads to be generated [1000000]
    -1 INT length of the first read [set by in.simupars.dat]
    -2 INT length of the second read [set by in.simupars.dat]
    -r FLOAT mutation rate [0.001]
    -R FLOAT

fraction of 1bp indels [0.1]
-h add all mutations to in.ref.fasta and generate reads from the single mutated
sequence (haploid mode)

NOTE:
* Reads generated from this command are independent, which deviates from the truth.

Whereas alignment evaluation is less affected by this, evaluation on SNP calling should be
performed with caution. Error dependency may be one of the major causes of wrong SNP
calls.


simustat maq simustat in.simu-aln.map > out.simustat

Evaluate mapping qualities from simulated reads.





ALGORITHM:

SEE IN version 0.71

C:\DATA\00.archive\02-ng.assembly\maq\download\maq-0.7.1\maq-0.7.1\simulate.c




Li 2008
Mapping short DNA sequencing reads and calling variants using mapping quality scores

Methods

Simulating diploid genomes and short reads
MAQ also generates in silico mutated diploid sequences by adding random mutations to the known reference sequence. The human reference genome does not contain heterozygotes, but when we resequence a human sample and map reads to the reference genome, we will see both homozygous and heterozygous variants in comparison to the reference. If the sample and the reference come from the same population and at a potential polymorphic site the allele frequency is f, the probability of observing a heterozygote is

2f(1 - f)

and of observing a homozygous variant is

f(1 - f) (= f2(1 - f) + f(1 - f)2).

Consequently, on the condition that a site is different from the reference, the probability of a heterozygote is always 2/3, regardless of the allele frequency f, assuming the sample comes from the same population as the reference.

Based on this observation, we can simulate a diploid genome as follows.

We first used the reference genome as the two preprocessed haplotypes.

We then generated a set of polymorphic sites, randomly selected two thirds of them as heterozygotes, and took the rest as homozygotes.

At a heterozygous site, we randomly selected one haplotype and mutated the base into another one; on a homozygous site, we mutated both haplotypes.

Both substitutions and indels can be simulated in this way.

This simulation ignores linkage disequilibrium between variants.

Although coalescent-based simulation (Hudson 2002) gives a more accurate long-range picture, the procedure described here is sufficient for the evaluation of the variant calling method for a single individual.

!PAIRED END!

From a known sequence, paired-end reads can be simulated with insert sizes drawn from a normal distribution and with base qualities drawn from the empirical distribution estimated from real sequence data.

Sequencing errors are introduced based on the base quality.

With sufficiently large data, we are able to estimate the position-specific distributions of base qualities and the correlation between adjacent qualities as well.

An order-one Markov chain is constructed, based on these statistics, to capture the fact that low-quality bases tend to appear at the 3--end of a read and to appear successively along a read.





mapcheck 	maq mapcheck [-s] [-m maxmis] [-q minQ] in.ref.bfa in.aln.map > out.mapcheck

Read quality check. The mapcheck first reports the composition and the depth of the reference. After that there is a form. The first column indicates the position on a read. Following four columns which show the nucleotide composition, substitution rates between the reference and reads will be given. These rates and the numbers in the following columns are scaled to 999 and rounded to nearest integer. The next group of columns show the distribution of base qualities along the reads at a quality interval of 10. A decay in quality can usually be observed, which means bases at the end of read are less accurate. The last group of columns present the fraction of substitutions for read bases at a quality interval. This measures the accuracy of base quality estimation. Idealy, we expect to see 1 in the 3? column, 10 in the 2? column and 100 in the 1? column.

OPTIONS:
-s 	Take single end mapping quality as the final mapping quality
-m INT 	Maximum number of mismatahces allowed for a read to be counted [4]
-q INT 	Minimum mapping quality allowed for a read to be counted [30]





</entry>



<entry [Tues Mar 31 23:12:24 EDT 2008] REVIEWS OF ELAND>




SEE ALSO (DETAILED)
http://analysis.yellowcouch.org/dsf/ga0.3/Whole%20genome%20alignments%20using%20ELAND.html


Thursday, January 17, 2008
Aligning DNA - Eland
http://www.fejes.ca/2008/01/aligning-dna-eland.html


Continuing in my series of blog articles on short-read sequencing, it's time for a little bit of a discussion on the first short-sequence aligner that I'd ever met: Eland. The problem with writing anything about Eland, is that 90% of the information I have on it can't be confirmed independently. In fact, the majority of what I know comes from the header of the ELAND.cpp file. I'll admit, while I've gone through the source code a couple of times, I haven't spent much time getting to know it's well - I've processed billions of lines of Eland files, but have yet to run it, myself...

Anyhow, here's what I can tell you: Eland stands for "Efficient Local Alignment of Nucleotide Data" and was written by Anthony J. Cox for Solexa Ltd. Of course, Solexa has since been bought out by Illumina, so I assume the copyright has been transferred along with the technology during that transaction.

What makes Eland so fascinating to me is that it's a direct departure from the dynamic programming based algorithms (like the venerable Smith-Waterman alignment), making it somewhat interesting as a computational program.

The basic algorithm works along these lines: Given a sequence of length N, it can be divided into four subsequences (A, B, C, and D), which are of equal (or nearly equal length). Assuming there are no more than 2 errors, at least two of these subsequences will be "error free", so that the two error free sequences can then be searched for in a database containing all possible subsequences in the genome of interest. Thus, you can search your database for the subsequence AB and CD. Of course, you don't know which subsequences are the error free ones, so you need to try all possible combination.

What Eland does to speed things up is to combine these subsequences into sets of two. Thus, rather than searching for 4 independent entries in their database, they simply have to search for 2 sets of two, and as long as one set matches, you can use looser matching criteria on the other two, ie, allowing for mismatches. That is to say, if you make two sequences out of the 4 subsequences {AB and CD}, you can search for an exact match for AB, and test all the possible results for mismatches in the {CD} portion of the sequence. This has the effect of significantly reducing the search space. (Only sequences containing the exact match to {AB}.)

Searching for the {AB and CD} subsequences would only work if the first half of your sequence has no errors. What if B and C had the errors? The simple answer is to shuffle your subsequences to make other combinations: ({AB and CD}, {AC and BD}, {AD and CD}, {BA and CD}, etc.) This still provides you with a relatively small search space for each sequence, as there are only 4! possible combinations (which is 4x3x2x1 = 24 possible sequences) to search for.

Fortunately, you can bound this even further. You always know that you want sequences in which the first pair and second pair are in the correct order, (ie {AB and CD} and {AC and BD} are ok, but {CA and DB} and {BA and DC} would give you an incorrect result) limiting you to only six possible combinations, which still allows you to find any correct match where at least two of the four subsequences are error free.

That, in general is how it works.. with a few nifty shortcuts. ie, they only need to pass over the genome search space 3 times to find all possible matches with up to two errors, because they can search for subsequence combinations simultaneously and efficiently. In other words, you get a very quick alignment.

On the other hand, the way in which ELAND was implemented is very important. The Eland aligner has some severe restrictions, some of which are algorithm specific, some of which are implementation specific:

   1. The Eland aligner can only align sequences up to 32 base pairs long. (Implementation specific: they use four integers to represent the subsequences {A,B,C and D}, which reduces the memory requirements.)

   2. The Eland aligner can only align sequences with up to two mismatches. (Algorithm specific: at least two of the keys must match, although the algorithm could be expanded to use more subsequences, at the expense of expanding the sequence space.)

   3. The Eland aligner only returns sequences that match to one unique location in the genome (Implementation specific: Eland already tells you when a sequence matches to more than one location, it just doesn't tell you what those locations are.)

   4. The Eland aligner can do mismatches in the sequence, but can not handle insertions or deletions (i.e, gapped alignments). (Algorithm specific: The algorithm for matching the keys could be expanded to include this, but it would be very costly in time/memory.)

   5. The code is not freely available. (Implementation specific: I don't know of anywhere you can go to get the code... or documentation!)

   6. Changing the length of the alignment sequence (I called it N, above), requires a recompile. (Implementation, obviously. Why this isn't a command line parameter, I don't know.)



I'm sure I could go on and list other disadvantages, but I'd like to point out the main advantage: It's FAST. Blazing fast, compared to the other aligners. From my own personal experience, Eland may only be able to map 60-70% of your sequences to the genome (compared to 70-80% for other aligners with which I have less experience), but it does so in a few hours, compared to several days or weeks for most other aligners (or years, compared to Blast). (Comparisons are for a single processor, matching 1 million+ reads to a mamalian size genome.) The only other aligner that can come close to this speed is, to the best of my knowledge, SXOligoSearch, produced by Synamatix, though that beast will cost upwards of $225,000CAD to license.

Anyhow, to close this discussion, it's worth mentioning that rumours of a new version of Eland have been circulating since March 2007. Beta versions, capable of performing searches on sequences larger than 32 base pairs in length and able to perform multi-matches, were supposed to be released in September 2007. Unfortunately, the new betas appear to be vapourware, which has prompted us to look into several other aligners, which I'll discuss in future posts.

(2008-01-28 Update: I stand corrected: I've heard that the new betas have finally arrived! I haven't seen what they can do yet, but at least we know my prediction that they're vapourware is wrong.)

Labels: Aligners, DNA, Sequencing, Solexa/Illumina

posted by Anthony Fejes at 8:51 PM
5 Comments:

OpenID stajich said...

    You may want to take a look at SHRiMP which was developed for both colorspace matching from SOLiD and for short-read technology.

    http://compbio.cs.toronto.edu/shrimp/
    2:05 PM   
Anonymous SolexaSufferer said...

    Apparently the SOAP program deals with the shortcomings of ELAND fantastically. It handles repeat hits (and can report them all, none or one random). And it can align with in-dels up to 3bp. Tried it just now. All works.

    http://soap.genomics.org.cn/ and
    http://www.ncbi.nlm.nih.gov/pubmed/18227114
    7:07 PM   
Blogger Malarky said...

    Hello
    I found your blog whilst searching for details about the way that Eland actually works.
    I understand your description of the algorithm but what interests me is the data structure that is used to hold the reads (in RAM) and which the algorithm searches over (or in SOAPs case the reference). Do you know how this is done?
    5:21 AM   
Blogger Anthony said...

    Hi Malarky,

    I don't know how happy Illumina/Solexa or Anthony Cox would be if I gave out all of the details of their implementation, so I'm going to refrain from giving too much detail. Though the algorithm is relatively involved, using look up tables and such, they appear to be using a suffix tree to hold the oligos.

    I hope that helps.

    Anthony
    9:40 AM   
Blogger Malarky said...

    Hi
    Thats good enough. Thanks




The Eland Short Read Aligner
http://attractivechaos.wordpress.com/2008/08/24/eland-short-read-aligner

Eland is a computer program that aligns short oligonucleotides against a reference genome. It is written by Anthony Cox from the Illumina company. The source codes are freely available to machine buyers. Eland is the first program for short read alignment and it profoundly influences most of its successors.

Algorithm

Eland guarantees full sensitivity for hits with up to two mismatches. To achieve this, Eland divides a read into four parts with approximately equal lengths. Six noncontiguous seed templates can be constructed with each template covering two parts. Eland applies each seed templates on reads and indexes the sequences that pass the template. After indexing it scans the reference genome sequence base by base and then looks up each K-mer in the index to find hits. As any two mismatches can only occur to at most two of the four parts, the seeding strategy used by Eland guarantees to find all 2-mismatch hits.

Eland might be the first widely used program that achieves full sensitivity given a threshold. Most of Eland successors learn from this point, and some software, such as Maq and SeqMap, even use the same seeding strategy. SOLiD read mapping software and ZOOM further extend the idea of using noncontiguous seed templates to achieve full sensitivity with fewer templates.

Efficiency

Eland is so fast that it effectively sets a goal for all its successors. Although several software are claimed to achieve so, they cannot retain the same useful information as Eland. For example, frequently a program only gives the unique best hit without couting the occurrences of a read. Counting greatly helps to reduce false alignment in some cases, but implementing this is non-trivial. Comparing Eland to a program without counting is unfair.

Limitations

Eland is not perfect, though. Natively, it does not support reads longer than 32bp, paired end mapping nor gapped alignment. Eland provides several scripts to overcome these limitations, but the power is reduced. In particular, even with the help of the additional scripts, Eland will miss a read alignment if the first 32bp of the read is nonunique or if the read has more than 10 identical hits in the reference genome. These limitations give the room for other short read aligners.





</entry>



<entry [Wed Mar 25 13:12:24 EDT 2008] MESSAGE Jennifer RE: ALIGNMENT TOOL FOR NEXT GEN RNA VS DNA DATA>



Hi Jennifer,

I'll try to answer your questions though it's just my 2 cents worth :)

1) what's the difference between an alignment tool and an assembly tool?

Generally speaking, they're understood to mean (though they're often used interchangeably):

Alignment = align against a reference
Assembly = align de novo with no reference


2) Is there any way to tell whether an alignment/assembly tool is solely for short seq DNA as opposed to short seq DNA and/or RNA? I'm having trouble distinguishing tools that may be useful for transcriptome data vs. genome data.

I think a major requirement for a NextGen transcriptome alignment/assembly tool is that it can cope with intron/exon boundaries but you could discriminate between different tools in terms of errors or capabilities:

RNA alignment against DNA reference (transcriptome data)

 - how does the algorithm deal with RNA artefact/bias (5' prime vs 3' prime degradation, surfeit of ribosomal RNAs, etc)?
 - how does it cope with alternate splice sites?
 - how does it deal with systemic errors in the read sequence predictions?

DNA alignment against DNA reference (genome data)

 - how does the algorithm deal with systemic errors in the read sequence predictions?
 - can it use the whole genome as a reference?
 - how does it deal with multiply-mapped reads?

Some more generic criteria:

 - how does the algorithm deal with multiply-mapped reads?
 - how many differences can it allow between read and reference (substitutions, indels)
 - number of reads incorporated into assembly


Cheers,

Stuart.



</entry>



<entry [Fri Mar 06 21:09:24 EDT 2008] Nick CHAT RE: CHALLENGE GRANT>



1. CHECK WHERE UNMAPPED READS (AGAINST EXOME) MAP TO ON GENOME

    IF DON'T MAP TO GENOME WITH LESS THAN 3, 4 (?) ERRORS THEN IT CAN BE COUNTED AS A TRUE SEQUENCING ERROR

    OTHERWISE, IT'S A LIMITATION OF ELAND (ONLY 2 ERRORS)

2. CHECK TO SEE IF THERE ARE ANY PATTERNS (G/C, 2D STRUCTURE) OF UNMAPPED READS DIFFERENT TO MAPPED READS


3. DO SYNTHETIC READS AGAINST ALL TOOLS

    - DIFFICULT REGIONS OF DNA
    
    - RANDOM SELECTION OF DNA OR RNA
    
    - RNA WITH MANY REPEATS



4. CHECK FOR CONTAMINATIONS

    viral gene insertion
    
    fusion genes


</entry>



<entry [Sun Jan 04 21:09:24 EDT 2008] Short reads not aligned by assemblers - USE NOVOALIGN>



SEE Notes-apps-novoalign.txt
Sun Jan 04 23:16:01 EST 2009
RUN NOVOALIGN


http://seqanswers.com/forums/archive/index.php?t-256.html

08-06-2008, 09:09 AM
Reads that aren't matched by Eland are interesting because we would suppose that they're not repeats because Eland reports the matches with multiple locations. 
I would say that gaps in a read would probably be missed by Eland, so use a short read aligner that can find gaps on these reads. I've been using novoalign (www.novocraft.com) and it can find up to 7/8 gaps in a 36bp read matching to a reference sequence, and fast on large ones. I've even tested it on simulated data with mutation rates in excess of 15% and it still finds them. Use a very high threshold e.g. -t 200 to find potentially all permutations for your read.
I'd be interested to know how much more you may be able to match out of your Eland NM reads.






</entry>



<entry [Sun Jan 04 21:09:24 EDT 2008] SUMMARY OF COMPARISON STATS>




1.1.1 ELAND ALIGNMENT AGAINST cDNA REFERENCE:
=============================================

*** ROUGHLY 10% OF READS ALIGNED TO cDNA REFERENCE ***

1.1.1.2 ELAND ALIGNMENT STATS
-----------------------------
                Number reads       %
ALIGNED           479,065        10.07
NOT ALIGNED     4,277,155        89.93
TOTAL           4,756,220       100.00


1.1.2 ELAND '--multi' ALIGNMENT AGAINST cDNA REFERENCE:
=======================================================

*** ROUGHLY 23% OF human 1 READS HAD AN ELAND HIT (UNIQUE OR NOT, PERFECT OR NOT) AGAINST THE cDNA REFERENCE ***

            READS       %
ALIGNED     1116229     23.469
NON-ALIGNED 3639991     76.531
TOTAL       4756220     100.000

1.2.1.2 VELVET ALIGNMENT STATS
------------------------------
GET NUMBER OF READS INCORPORATED INTO DENOVO CONTIGS FROM .ace FILE

                Number reads       %
ALIGNED           961,245        20.210
TOTAL           4,756,220       100.00



*** 3,821 VELVET CONTIG HITS AGAINST cDNA, OF THEM AGAINST UNIQUE cDNAs ***


1.2.1.4 FILTER NUCMER OUTPUT TO GET ONLY UNIQUE HITS, THEN DO THE COORDS FILE 
------------------------------------------------------------------------------

*** 1,469 UNIQUE RECIPROCAL HITS BETWEEN VELVET CONTIGS AND cDNA (REDUCED TO 1,443 AFTER EXLUDING Chr6 VARIANT REGION cDNAs)***






1.2.1.8 GET UNIQUE TARGETS FROM *.coords FILE
---------------------------------------------

*** FOR BEST VELVET-cDNA UNIQUE HITS, 1,105 UNIQUE cDNAs WERE HIT BY VELVET CONTIGS (1,486 HITS IN TOTAL) ***

*** FOR ALL VELVET HITS, 2,493 UNIQUE cDNAs WERE HIT BY VELVET CONTIGS (4,244 HITS IN TOTAL) ***




1.3.1 COMPARE READS IN .ace FILES OF ELAND AND VELVET ASSEMBLIES
----------------------------------------------------------------

lines eland-only.txt
    324025
lines eland-velvet.both.txt
    155040
lines velvet-only.txt
    806205





</entry>



<entry [Fri Dec 26 10:09:24 EDT 2008] Lander-Waterman READ COVERAGE STATISTIC>



Lander-Waterman Statistics

Given: N reads of length L from a genome of size G
P(? covered by read) = 1 – (1 – L/G)N 
		?1 – e-c, where c = N L / G is coverage
P(? covered by read) ?1 – e-c





</entry>



<entry [Fri Dec 26 10:09:24 EDT 2008] SLIDER ASSEMBLER USES SOLEXA QUALITY VALUES>



Friday, December 26, 2008 10:09 AM
To: 	
Young, Stuart
Cc: 	
Hedges, Dale; Zuchner, Stephan; Huang, Jia; Dittman, David; Nunez, Eduardo
Attachments: 	
Slider_alignment_tool.pdf? (152 KB?)[Open as Web Page]

Hi Stuart,

I just came across this new aligner on pubmed.

Thanks,

Josh

http://bioinformatics.oxfordjournals.org/cgi/content/full/25/1/6

</entry>



<entry [Tues Dec 09 23:37:58 EDT 2008] THE POSTER DEALS WITH TWO ISSUES: 1) DIFFERENT ASSEMBLY OVERLAPS ON A REFERENCE SEQUENCE, 2) ASSEMBLY CONSENSUS DIFFERENCES IN OVERLAPPING REGIONS>




(1) HUMAN 1 (LANE 3) ASSEMBLY OVERLAPS AGAINST cDNA (EMBL) - Eland versus Velvet
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

1.1 ELAND
=========

LOCATION:

cd /home/syoung/base/pipeline/human1-eland/assembly


1.1.1 ELAND ALIGNMENT AGAINST cDNA REFERENCE:
=============================================

1.1.1.1 DO ELAND ALIGNMENT
--------------------------
./eland.pl -i /home/syoung/base/pipeline/human-eland/data/human1.fasta \
            -r /home/syoung/base/pipeline/human-eland/data \
            -o /home/syoung/base/pipeline/human-eland/assembly/human1-cdna_embl-eland.txt \
            > /home/syoung/base/pipeline/human-eland/assembly/human1-cdna_embl-eland.log



*** ROUGHLY 10% OF READS ALIGNED TO cDNA REFERENCE ***

1.1.1.2 ELAND ALIGNMENT STATS
-----------------------------
                Number reads       %
ALIGNED           479,065        10.07
NOT ALIGNED     4,277,155        89.93
TOTAL           4,756,220       100.00


STATS OBTAINED AS FOLLOWS:

CONCENTRATE HITS INTO ONE FILE:

cd /home/syoung/base/pipeline/human1-eland/assembly
cat human1-cdna_embl-eland.txt | grep NCBI36 > human1-cdna_embl-eland.hits

lines human1-cdna_embl-eland.hits
479065

lines human1-cdna_embl-eland.txt
4756220


1.1.1.3 CONVERT 'hits' FILE INTO GFF SORTED BY START POSITION:
--------------------------------------------------------------

./eland2gff.pl \
    --inputfile /home/syoung/base/pipeline/human1-eland/assembly/human1-cdna_embl-eland.txt \
    --chromofile /home/syoung/base/pipeline/human-genome/chromosome_positions.txt \
    --cdnadir /home/syoung/base/pipeline/human-cdna-embl/gff \
    --outputdir /home/syoung/base/pipeline/human1-eland/assembly/gff \
    --readlength 34

    Run time: 00:00:34
    Completed ./eland2gff.pl
    0:10AM, 17 December 2008
    # EXECUTED FULL COMMAND:
    # ./eland2gff.pl --inputfile /home/syoung/base/pipeline/human1-eland/assembly/human1-cdna_embl-eland.txt --chromofile /home/syoung/base/pipeline/human-genome/chromosome_positions.txt --cdnadir /home/syoung/base/pipeline/human-cdna-embl/gff --outputdir /home/syoung/base/pipeline/human1-eland/assembly/gff --readlength 34
    ****************************************




1.1.2 ELAND '--multi' ALIGNMENT AGAINST cDNA REFERENCE:
=======================================================

1.1.2.1 DO ELAND MULTI ALIGNMENT
--------------------------------

cd /home/syoung/base/pipeline/human1-eland/assembly-multi

    Run time: 00:04:41
    Completed ./eland.pl
    11:55PM, 15 December 2008
    # EXECUTED FULL COMMAND:
    # ./eland.pl -i /home/syoung/base/pipeline/human1-eland/data/human1.fasta -r /home/syoung/base/pipeline/human1-eland/data -o /home/syoung/base/pipeline/human1-eland/assembly/human1-cdna_embl-eland.txt
    ****************************************

1.1.2.2 CONDENSE cDNA HITS INTO 'hits' FILE AND DO ALIGNMENT STATS:
-------------------------------------------------------------------

cd /home/syoung/base/pipeline/human1-eland/assembly-multi
cat human1-cdna_embl-eland_multi.txt | grep NCBI36 > human1-cdna_embl-eland_multi.hits
lines *hits
    1116229

lines *txt
    4756220

*** ROUGHLY 23% OF human 1 READS HAD AN ELAND HIT (UNIQUE OR NOT, PERFECT OR NOT) AGAINST THE cDNA REFERENCE ***

            READS       %
ALIGNED     1116229     23.469
NON-ALIGNED 3639991     76.531
TOTAL       4756220     100.000


1.1.2.3 CONVERT 'hits' FILE INTO GFF SORTED BY START POSITION:
--------------------------------------------------------------

./eland2gff.pl \
    --inputfile /home/syoung/base/pipeline/human1-eland/assembly-multi/human1-cdna_embl-eland_multi.hits \
    --chromofile /home/syoung/base/pipeline/human-genome/chromosome_positions.txt \
    --cdnadir /home/syoung/base/pipeline/human-cdna-embl/gff \
    --outputdir /home/syoung/base/pipeline/human1-eland/assembly-multi/gff \
    --multi \
    --readlength 34

    Run time: 00:01:47
    Completed ./eland2gff.pl
    0:02AM, 17 December 2008
    # EXECUTED FULL COMMAND:
    # ./eland2gff.pl --inputfile /home/syoung/base/pipeline/human1-eland/assembly-multi/human1-cdna_embl-eland_multi.hits --chromofile /home/syoung/base/pipeline/human-genome/chromosome_positions.txt --cdnadir /home/syoung/base/pipeline/human-cdna-embl/gff --outputdir /home/syoung/base/pipeline/human1-eland/assembly-multi/gff --multi --readlength 34
    ****************************************

CHECK CHROMOSOME 3 LINES:

cd /home/syoung/base/pipeline/human1-eland/assembly-multi/gff/
lines  human-cdna-embl-chr3.eland.sorted.gff
132244


1.1.2.4 GENERATE .ace FILE 
--------------------------

eland2ace.pl --inputfile /home/syoung/base/pipeline/run2lane6-test/eland/s_6_1_sorted.txt \
--referencefile /home/syoung/base/pipeline/run2-human-mitochondria/data/human-mtDNA-AC_000021.fasta






1.2 VELVET
==========

1.2.1 VELVET DENOVO ALIGNMENT 
=============================

cd /home/syoung/base/pipeline/human1-velvet/assembly

1.2.1.1 DO VELVET ALIGNMENT 
---------------------------
Notes-project02-ng_assembly.txt, P.178
    
./velvet.pl -i /home/syoung/base/pipeline/human1-velvet/data/human1_sequence_in.solexa.fasta -l 21 
    
    Run time: 00:08:09
    Completed ./velvet.pl
    4:08PM, 14 August 2008
    ****************************************

VELVET GENERATED 4532 CONTIGS:

    records /home/syoung/base/pipeline/human1-velvet/assembly/contigs.fa
    Records: 4532

1.2.1.2 VELVET ALIGNMENT STATS
------------------------------
GET NUMBER OF READS INCORPORATED INTO DENOVO CONTIGS FROM .ace FILE

                Number reads       %
ALIGNED           961,245        20.210
TOTAL           4,756,220       100.00


CREATE .ace FILE: http://zion.ccs.miami.edu:8080/display/NextGen/Convert+.afg+to+.ace

    cd /home/syoung/base/pipeline/human1-velvet/data
    cp human1_sequence_in.solexa.fasta human1_sequence_in.seq
    cp human1_sequence_in.solexa.fasta.qual human1_sequence_in.seq.qual
    tarchive2amos -o human1_sequence_in human1_sequence_in.seq human1_sequence_in.seq.qual
    amos2ace human1_sequence_in.afg ../assembly/velvet_assy.afg

    TOOK 28 MINS

    ... RUNNING IN screen Fri Dec 12 13:30:36 EST 2008

    ll
    -rw-r--r-- 1 syoung users  297884535 Dec 12 13:58 human1_sequence_in.ace
    -rw-r--r-- 1 syoung users 2107663479 Dec 10 15:18 human1_sequence_in.afg
    -rw-r--r-- 1 syoung users  354253372 Dec 10 13:57 human1_sequence_in.seq
    -rw-r--r-- 1 syoung users  669133428 Dec 10 13:57 human1_sequence_in.seq.qual
    -rw-r--r-- 1 syoung users  354253372 Jul 20 21:13 human1_sequence_in.solexa.fasta
    -rw-r--r-- 1 syoung users  669133428 Jul 20 21:14 human1_sequence_in.solexa.fasta.qual
    -rw-r--r-- 1 syoung users          0 Dec 10 14:51 tarchive2amos.log
    -rw-r--r-- 1 syoung users 1569316864 Dec 10 14:18 tmp.18274.red

head human1_sequence_in.ace

    AS 4531 961245
    
    CO 1 146 100 60 U
    CATGAGAGTGGTGTTAATTATCCTCCCTCCAAGTTTGCAAATAAAGAGGT
    TGATACATATAAAGATTATAACTTGCCTAGATGGATTTGCAGAAAGATTT
    ATTACTAGCAATTTGTTATATTATTTTGCATCTCTTTTATTGTTTA
    
    BQ
     19 17 36 23 17 23 17 23 36 23 23 36 23 36 36 17 17 36 36 17 36 19 19 36 19 19 19 36 19 19 17 17 23 36 36 36 23 19 17 17 17 36 17 17 17 23 17 23 23 36
     36 23 17 36 17 19 17 36 17 36 17 17 17 23 17 36 36 17 36 17 17 19 36 36 23 19 19 36 17 23 17 36 23 23 17 36 36 36 23 19 17 23 17 17 17 23 17 36 36 36


RECOUNT THE NUMBER OF LINES WITH 'AF '

cd /home/syoung/base/pipeline/human1-velvet/data
grep -n "AF " human1_sequence_in.ace

961245

SAME AS IN .ace HEADER LINE SO OKAY.

    
***********************************************************************
*** NB: TRIED TO GET NUMBER FROM .afg FILE BUT NOT STRAIGHTFORWARD: ***
cd /home/syoung/base/pipeline/human1-velvet
grep -c iid: assembly/velvet_assy.afg
    4760751
cd /home/syoung/base/pipeline/human1-velvet
records data/human1_sequence_in.solexa.fasta
    4756221

ALIGNED     4760751
UNALIGNED      4530
TOTAL       4756221

LOOKS FISHY - iid DOES NOT REPRESENT JUST ALIGNED READS, RATHER ALL READS
***********************************************************************


1.2.1.3 DO NUCMER ALIGNMENT AGAINST cDNA
----------------------------------------

INPUTFILE IS VELVET CONTIGS: /home/syoung/base/pipeline/human1-velvet/assembly/contigs.fa

./nucmer.pl --inputfile /home/syoung/base/pipeline/human1-velvet/assembly/contigs.fa \
	--referencefile /home/syoung/base/pipeline/human-cdna-embl/Homo_sapiens.NCBI36.49.cdna.known.fas \
	--outputdir /home/syoung/base/pipeline/human1-velvet/nucmer-cdna


cd /home/syoung/base/pipeline/human1-velvet/nucmer-cdna
ll

    -rw-rw-rw-  1 syoung users 495K Dec 17 11:08 out.cluster
    -rw-rw-rw-  1 syoung users 328K Dec 17 11:08 out.delta


*** 3,821 VELVET CONTIG HITS AGAINST cDNA, OF THEM AGAINST UNIQUE cDNAs ***

records out.cluster 
    3821

head out.cluster
    /home/syoung/base/pipeline/human1-velvet/assembly/contigs.fa /home/syoung/base/pipeline/human-cdna-embl/Homo_sapiens.NCBI36.49.cdna.known.fas
    NUCMER
    >NODE_3812_length_271_cov_32.929890 ENST00000361390 291 957
     1  1
          67        1    225     -      -
    >NODE_1559_length_209_cov_15.354067 ENST00000361390 229 957
     1 -1
          16      957     75     -      -
          92      881    138     1      1

out.cluster FILE FORMAT:

    -   First line: the two original input files separated by a space.
    -   Second line: the type of alignment data - either "NUCMER" or "PROMER". 

Each match cluster contains a five column match list:

    1. the start of the match in the reference
    2. the start of the match in the query
    3. the length of the match
    4. the gap between this match and the previous match in the reference
    5. the gap between this match and the previous match in the query respectively.

    NB:
    
    All coordinates reference the forward strand of each sequence, regardless of match direction, and are always measured in DNA bases regardless of alignment type (DNA or amino acid). Therefore, when running PROmer, all the numbers in the length and gaps columns must be multiples of three.
    
    In addition, because the matches reference the forward DNA strand forward match clusters will be sorted in ascending fashion while reverse match clusters will be sorted in descending fashion.
    
    Each individual cluster has a header formed from two digits in the set [-1, -2, -3, 1, 2, 3]. These two digits represent the direction of the cluster (negative for reverse and positive for forward) and the frame of the cluster in the reference and query sequences respectively (note that matches within the same cluster must have a consistent reading frame).
    
    For NUCmer output, the header will always show a "1" for the reference and a "-1" or "1" for the query, since only the query can be reverse complemented. However, for PROmer output all 36 combinations of these two digits are valid headers. For instance, " -2 3" would represent a cluster on the 2nd reading frame of the reversed reference sequence and on the 3rd reading frame of the forward query sequence.


1.2.1.4 FILTER NUCMER OUTPUT TO GET ONLY UNIQUE HITS, THEN DO THE COORDS FILE 
------------------------------------------------------------------------------


1. CREATE delta.filter FILE (A one-to-one local mapping of reference to query sequences)

./nucmer-deltafilter.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/out.delta

*** 1,469 UNIQUE RECIPROCAL HITS BETWEEN VELVET CONTIGS AND cDNA (REDUCED TO 1,443 AFTER EXLUDING Chr6 VARIANT REGION cDNAs)***

cd /home/syoung/base/pipeline/human1-velvet/nucmer-cdna
records delta.filter 
1469



2. GENERATE COORDINATES FOR HITS WITHIN delta.filter FILE

./nucmer-showcoords.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/delta.filter

cd /home/syoung/base/pipeline/human1-velvet/nucmer-cdna
lines delta.filter.coords
    1491

cd /home/syoung/base/pipeline/human1-velvet/nucmer-cdna
head delta.filter.coords

    /home/syoung/base/pipeline/human1-velvet/assembly/contigs.fa /home/syoung/base/pipeline/human-cdna-embl/Homo_sapiens.NCBI36.49.cdna.known.fas
    NUCMER
    
        [S1]     [E1]  |     [S2]     [E2]  |  [LEN 1]  [LEN 2]  |  [% IDY]  |  [COV R]  [COV Q]  | [TAGS]
    ==========================================================================================================
           1      235  |     1792     1558  |      235      235  |   100.00  |    98.74     4.21  | NODE_3019_length_218_cov_5.032110       ENST00000006951
           1      497  |       25      521  |      497      497  |   100.00  |    98.81    95.39  | NODE_3183_length_483_cov_9.049689       ENST00000009589
           1      146  |      570      715  |      146      146  |   100.00  |   100.00    10.56  | NODE_5331_length_126_cov_5.142857       ENST00000022615
           1      134  |     1236     1369  |      134      134  |   100.00  |   100.00     9.70  | NODE_6976_length_114_cov_5.561403       ENST00000022615
           1      246  |     4280     4525  |      246      246  |   100.00  |   100.00     3.39  | NODE_3896_length_226_cov_8.252213       ENST00000031135


1.2.1.5 GENERATE GENOME-RELATIVE GFF FILE FOR UNIQUE HITS IN delta.filter.coords FILE
-------------------------------------------------------------------------------------

CREATE cdna_chromosomes.txt FILE FOR EMBL cDNAs:

1. GENERATE 'pre' FILE FROM FASTA HEADERS IN 'raw' FILE

./parsecolumns.pl --inputfile /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.raw.txt \
    --outputfile /home/syoung/base/pipeline/human-cdna-embl/cdna_chromosomes.pre.txt \
    --regex "^.+?>(\S+)\s+[^:]+:[^:]+:[^:]*?:([^:]+):(\d+):(\d+):(\S+)\s+gene:(\S+)$" \
    --headings "id:start:stop:orientation:chromosome:gene" \
    --order "1:3:4:5:2:6"


head /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.pre.txt

    id      start   stop    orientation     chromosome      gene
    ENST00000391556 7373    8827    -1      NT_113908       ENSG00000212867
    ENST00000361390 3308    4264    1       MT      ENSG00000198888
    ENST00000391565 3308    5514    1       MT      ENSG00000212876
    ENST00000361453 4471    5512    1       MT      ENSG00000198763
    ENST00000391564 5585    7515    1       MT      ENSG00000212875
    ENST00000361624 5905    7446    1       MT      ENSG00000198804
    ENST00000361739 7587    8270    1       MT      ENSG00000198712

2. GENERATE GENOME-RELATIVE cDNA POSITIONS FILE WITH 'pre' FILE AND chromosome_positions.txt FILE

./cdna-positions.pl --inputfile /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.pre.txt \
--chromofile /home/syoung/base/pipeline/human-genome/chromosome_positions.txt \
--outputfile /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.final.txt


ll /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.final.txt
    -rw-rw-rw- 1 syoung users 1.8M Dec 19 21:13 /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.final.txt

head /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.final.txt
    ENST00000298232 2836447089      2836531783      84695
    ENST00000342420 2836447089      2836531783      84695
    ENST00000359693 2836447089      2836512601      65513
    ENST00000361285 2836447089      2836531783      84695
    ENST00000400230 2836447620      2836531761      84142
    ENST00000356832 2836561721      2836639576      77856
    ENST00000335369 2836588426      2836639616      51191
    ENST00000400589 2839855984      2839865210      9227
    ENST00000305570 2839909529      2839926349      16821
    ENST00000332473 2840162467      2840163848      1382


3. GENERATE GENOME-RELATIVE VELVET CONTIG HITS AGAINST cDNA USING *coords FILE AND cdna_positions.final.txt FILE
(NB: EXCLUDED ALL cDNAS BELONGING TO CHROMOSOME 6 VARIANTS AND THEREFORE NOT IN chromosome_positions.txt FILE, E.G., Chromosome c6_COX)
./coords2gff.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/delta.filter.coords --chromofile /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.final.txt --source velvet --algorithm nucmer

    /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/delta.filter.coords.gff
    
    Run time: 00:00:00
    Completed ./coords2gff.pl
    10:15PM, 19 December 2008
    ****************************************

lines /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/delta.filter.coords.gff

    1443
    
head /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/delta.filter.coords.gff

    #seqname        source  feature start   end     score   strand  frame   attributes      comments
    NODE_3019       velvet  contig  2542202175      2542202422      .       +       .       Target: ENST00000006951; Coverage: 5.032110; Length: 248; Query hit start/stop: 1..235; Alignment algorithm: nucmer
    NODE_3183       velvet  contig  1476534352      1476534864      .       +       .       Target: ENST00000009589; Coverage: 9.049689; Length: 513; Query hit start/stop: 1..497; Alignment algorithm: nucmer
    NODE_5331       velvet  contig  1461755275      1461755430      .       +       .       Target: ENST00000022615; Coverage: 5.142857; Length: 156; Query hit start/stop: 1..146; Alignment algorithm: nucmer
    NODE_6976       velvet  contig  1461755941      1461756084      .       +       .       Target: ENST00000022615; Coverage: 5.561403; Length: 144; Query hit start/stop: 1..134; Alignment algorithm: nucmer
    NODE_3896       velvet  contig  1219694283      1219694538      .       +       .       Target: ENST00000031135; Coverage: 8.252213; Length: 256; Query hit start/stop: 1..246; Alignment algorithm: nucmer
    NODE_4753       velvet  contig  1219694281      1219694462      .       +       .       Target: ENST00000031135; Coverage: 5.203948; Length: 182; Query hit start/stop: 1..169; Alignment algorithm: nucmer
    NODE_6483       velvet  contig  716681770       716681924       .       +       .       Target: ENST00000040738; Coverage: 7.352000; Length: 155; Query hit start/stop: 1..145; Alignment algorithm: nucmer
    NODE_6915       velvet  contig  2423427209      2423427298      .       +       .       Target: ENST00000044462; Coverage: 5.116667; Length: 90; Query hit start/stop: 1..79; Alignment algorithm: nucmer
    NODE_193        velvet  contig  688137475       688137825       .       +       .       Target: ENST00000169298; Coverage: 11.632399; Length: 351; Query hit start/stop: 1..341; Alignment algorithm: nucmer



1.2.1.6 FILTER NUCMER OUTPUT TO GET ONLY UNIQUE HITS, THEN DO THE COORDS FILE 
------------------------------------------------------------------------------

1. COPY nucmer-cdna TO nucmer-cdna-all

cd /home/syoung/base/pipeline/human1-velvet
cp -r nucmer-cdna nucmer-cdna-all

2. CREATE delta.filter FILE (A one-to-one local mapping of reference to query sequences)

./nucmer-deltafilter.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/out.delta --parameters " "

cd /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all
records delta.filter 
    3821
records ../nucmer-cdna/delta.filter
    1469

*** delta-filter RETAINED ALL 3,821 VELVET CONTIG HITS AGAINST cDNA ***


2. GENERATE COORDINATES FOR HITS WITHIN delta.filter FILE

./nucmer-showcoords.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/delta.filter

cd /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all
lines delta.filter.coords
    4249

cd /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all
head delta.filter.coords

    /home/syoung/base/pipeline/human1-velvet/assembly/contigs.fa /home/syoung/base/pipeline/human-cdna-embl/Homo_sapiens.NCBI36.49.cdna.known.fas
    NUCMER
    
        [S1]     [E1]  |     [S2]     [E2]  |  [LEN 1]  [LEN 2]  |  [% IDY]  |  [COV R]  [COV Q]  | [TAGS]
    ==========================================================================================================
           1      235  |     1792     1558  |      235      235  |   100.00  |    98.74     4.21  | NODE_3019_length_218_cov_5.032110       ENST00000006951
           1      118  |      584      467  |      118      118  |   100.00  |   100.00    13.10  | NODE_866_length_98_cov_7.540816 ENST00000008180
           1      497  |       25      521  |      497      497  |   100.00  |    98.81    95.39  | NODE_3183_length_483_cov_9.049689       ENST00000009589
          31      235  |      641      845  |      205      205  |   100.00  |    87.23    11.60  | NODE_4311_length_215_cov_5.865116       ENST00000010338
           1      420  |      833     1252  |      420      420  |    99.76  |   100.00    23.77  | NODE_875_length_400_cov_7.725000        ENST00000010338



1.2.1.7 GENERATE GENOME-RELATIVE GFF FILE FOR UNIQUE HITS IN delta.filter.coords FILE
-------------------------------------------------------------------------------------

CREATE cdna_chromosomes.txt FILE FOR EMBL cDNAs:

1. GENERATE 'pre' FILE FROM FASTA HEADERS IN 'raw' FILE

SEE ABOVE.

2. GENERATE GENOME-RELATIVE cDNA POSITIONS FILE WITH 'pre' FILE AND chromosome_positions.txt FILE

SEE ABOVE.


3. GENERATE GENOME-RELATIVE VELVET CONTIG HITS AGAINST cDNA USING *coords FILE AND cdna_positions.final.txt FILE
(NB: EXCLUDED ALL cDNAS BELONGING TO CHROMOSOME 6 VARIANTS AND THEREFORE NOT IN chromosome_positions.txt FILE, E.G., Chromosome c6_COX)

./coords2gff.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/delta.filter.coords --chromofile /home/syoung/base/pipeline/human-cdna-embl/cdna_positions.final.txt --source velvet --algorithm nucmer

    /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/delta.filter.coords.gff
    
    Run time: 00:00:00
    Completed ./coords2gff.pl
    10:36PM, 19 December 2008
    ****************************************

lines /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/delta.filter.coords.gff

    3970

COMPARED TO UNIQUE HITS:

lines /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/delta.filter.coords.gff

    1443
    
head /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/delta.filter.coords.gff

    #seqname        source  feature start   end     score   strand  frame   attributes      comments
    NODE_3019       velvet  contig  2542202175      2542202422      .       +       .       Target: ENST00000006951; Coverage: 5.032110; Length: 248; Query hit start/stop: 1..235; Alignment algorithm: nucmer
    NODE_866        velvet  contig  2452209115      2452209242      .       +       .       Target: ENST00000008180; Coverage: 7.540816; Length: 128; Query hit start/stop: 1..118; Alignment algorithm: nucmer
    NODE_3183       velvet  contig  1476534352      1476534864      .       +       .       Target: ENST00000009589; Coverage: 9.049689; Length: 513; Query hit start/stop: 1..497; Alignment algorithm: nucmer
    NODE_4311       velvet  contig  208000619       208000863       .       +       .       Target: ENST00000010338; Coverage: 5.865116; Length: 245; Query hit start/stop: 31..235; Alignment algorithm: nucmer
    NODE_875        velvet  contig  208000841       208001270       .       +       .       Target: ENST00000010338; Coverage: 7.725000; Length: 430; Query hit start/stop: 1..420; Alignment algorithm: nucmer
    NODE_5331       velvet  contig  1461755275      1461755430      .       +       .       Target: ENST00000022615; Coverage: 5.142857; Length: 156; Query hit start/stop: 1..146; Alignment algorithm: nucmer
    NODE_6976       velvet  contig  1461755941      1461756084      .       +       .       Target: ENST00000022615; Coverage: 5.561403; Length: 144; Query hit start/stop: 1..134; Alignment algorithm: nucmer
    NODE_3896       velvet  contig  1219694283      1219694538      .       +       .       Target: ENST00000031135; Coverage: 8.252213; Length: 256; Query hit start/stop: 1..246; Alignment algorithm: nucmer
    NODE_4753       velvet  contig  1219694281      1219694462      .       +       .       Target: ENST00000031135; Coverage: 5.203948; Length: 182; Query hit start/stop: 1..169; Alignment algorithm: nucmer





1.2.1.8 GET UNIQUE TARGETS FROM *.coords FILE
---------------------------------------------

*** FOR BEST VELVET-cDNA UNIQUE HITS, 1,105 UNIQUE cDNAs WERE HIT BY VELVET CONTIGS (1,486 HITS IN TOTAL) ***

./nucmer-uniquetargets.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/delta.filter.coords --outputfile out.targets 

    No. unique targets: 1105
    No. lines: 1486
    Output file printed:
    
    /home/syoung/base/pipeline/human1-velvet/nucmer-cdna/out.targets
    Run time: 00:00:00
    Completed ./nucmer-uniquetargets.pl
    11:09PM, 19 December 2008
    ****************************************


*** FOR ALL VELVET HITS, 2,493 UNIQUE cDNAs WERE HIT BY VELVET CONTIGS (4,244 HITS IN TOTAL) ***

./nucmer-uniquetargets.pl --inputfile /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/delta.filter.coords --outputfile out.targets 

    Inputfile: /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/delta.filter.coords
    Output directory: /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all
    No. unique targets: 2493
    No. lines: 4244
    Output file printed:
    
    /home/syoung/base/pipeline/human1-velvet/nucmer-cdna-all/out.targets
    Run time: 00:00:00
    Completed ./nucmer-uniquetargets.pl
    11:11PM, 19 December 2008
    ****************************************



1.3.1 COMPARE READS IN .ace FILES OF ELAND AND VELVET ASSEMBLIES
----------------------------------------------------------------

1. EXTRACT READS FROM VELVET .ace FILE:
/home/syoung/base/pipeline/human1-velvet/data/human1_sequence_in.ace

cd /home/syoung/base/pipeline/human1-velvet/data
cat human1_sequence_in.ace | grep "AF " > human1-velvet-assembled-reads.pre.txt

head human1-velvet-assembled-reads.txt 
    AF HWI-EAS185_1_JIA_cDNA_JH:3:1:237:251 U 69
    AF HWI-EAS185_1_JIA_cDNA_JH:3:14:154:894 U 73
    AF HWI-EAS185_1_JIA_cDNA_JH:3:27:247:920 U 105
    AF HWI-EAS185_1_JIA_cDNA_JH:3:29:166:899 U 70
    AF HWI-EAS185_1_JIA_cDNA_JH:3:31:834:294 U 48
    AF HWI-EAS185_1_JIA_cDNA_JH:3:33:293:287 U 73
    AF HWI-EAS185_1_JIA_cDNA_JH:3:47:755:370 U 86
    AF HWI-EAS185_1_JIA_cDNA_JH:3:59:267:42 U 105
    AF HWI-EAS185_1_JIA_cDNA_JH:3:63:94:532 U 95
    AF HWI-EAS185_1_JIA_cDNA_JH:3:69:119:133 U 89

cut -d " " -f 2 human1-velvet-assembled-reads.pre.txt > human1-velvet-assembled-reads.txt
head /home/syoung/base/pipeline/human1-velvet/data/human1-velvet-assembled-reads.txt
    HWI-EAS185_1_JIA_cDNA_JH:3:1:237:251
    HWI-EAS185_1_JIA_cDNA_JH:3:14:154:894
    HWI-EAS185_1_JIA_cDNA_JH:3:27:247:920
    HWI-EAS185_1_JIA_cDNA_JH:3:29:166:899
    HWI-EAS185_1_JIA_cDNA_JH:3:31:834:294
    HWI-EAS185_1_JIA_cDNA_JH:3:33:293:287
    HWI-EAS185_1_JIA_cDNA_JH:3:47:755:370
    HWI-EAS185_1_JIA_cDNA_JH:3:59:267:42
    HWI-EAS185_1_JIA_cDNA_JH:3:63:94:532
    HWI-EAS185_1_JIA_cDNA_JH:3:69:119:133


2. EXTRACT READS FROM ELAND .txt FILE:

ELAND .txt FILE:

cd /home/syoung/base/pipeline/human1-eland/assembly
head human1-cdna_embl-eland.txt

cut -f 1 human1-cdna_embl-eland.txt > human1-eland-assembled-reads.pre.txt
cut -d ">" -f 2 human1-eland-assembled-reads.pre.txt > human1-eland-assembled-reads.txt

head /home/syoung/base/pipeline/human1-eland/assembly/human1-eland-assembled-reads.txt 
    HWI-EAS185_1_JIA_cDNA_JH:3:1:129:540
    HWI-EAS185_1_JIA_cDNA_JH:3:1:113:576
    HWI-EAS185_1_JIA_cDNA_JH:3:1:212:252
    HWI-EAS185_1_JIA_cDNA_JH:3:1:118:571
    HWI-EAS185_1_JIA_cDNA_JH:3:1:207:277
    HWI-EAS185_1_JIA_cDNA_JH:3:1:103:565
    HWI-EAS185_1_JIA_cDNA_JH:3:1:211:297
    HWI-EAS185_1_JIA_cDNA_JH:3:1:114:511
    HWI-EAS185_1_JIA_cDNA_JH:3:1:217:361
    HWI-EAS185_1_JIA_cDNA_JH:3:1:728:353


3. FIND THE INTERSECTION OF THE VELVET AND ELAND MATCHES

./compare-reads.pl --firstfile /home/syoung/base/pipeline/human1-eland/assembly/human1-eland-assembled-reads.txt --secondfile /home/syoung/base/pipeline/human1-velvet/data/human1-velvet-assembled-reads.txt --assemblynames eland,velvet --outputdir /home/syoung/base/pipeline/human-eland-velvet

    First: eland, second: velvet
    Loading first file into hash: /home/syoung/base/pipeline/human1-eland/assembly/human1-eland-assembled-reads.txt ...
    Checking through second file for matching reads in first file...
    First only file printed: /home/syoung/base/pipeline/human-eland-velvet/eland-only.txt
    Second only file printed: /home/syoung/base/pipeline/human-eland-velvet/velvet-only.txt
    Both file printed: /home/syoung/base/pipeline/human-eland-velvet/eland-velvet.both.txt
    
    Run time: 00:00:04
    Completed ./compare-reads.pl
    2:40AM, 21 December 2008
    ****************************************


ll /home/syoung/base/pipeline/human-eland-velvet

    -rw-rw-rw-  1 syoung users  12M Dec 21 02:40 eland-only.txt
    -rw-rw-rw-  1 syoung users 5.7M Dec 21 02:40 eland-velvet.both.txt
    -rw-rw-rw-  1 syoung users  30M Dec 21 02:40 velvet-only.txt


cd /home/syoung/base/pipeline/human-eland-velvet
lines eland-only.txt
    324025
lines eland-velvet.both.txt
    155040
lines velvet-only.txt
    806205


GOOD IF VELVET IS GOOD ASSEMBLY...    


CREATE ONE OR MORE SEQUENCE FILES (FILENAME = SEQUENCE ID, CONTENT = SEQUENCE ONLY) FROM SINGLE FASTA FILE

./sequence-files.pl --fastafile /home/syoung/base/pipeline/human-cdna-embl/Homo_sapiens.NCBI36.49.cdna.known.fas \
--outputdir /home/syoung/base/pipeline/human-eland-velvet/sequences

OKAY:
40,000+ 'ENST00000401097' ETC. SEQUENCE FILES PRINTED TO DIRECTORY /home/syoung/base/pipeline/human-eland-velvet/sequences

E.G.:
head  /home/syoung/base/pipeline/human-eland-velvet/sequences/ENST00000401096

GET READ ALIGNMENT ACCURACIES BY COMPARING THE CONSENSUS SEQUENCE IN AN .ace FILE TO THE ACTUAL SEQUENCE:

./ace-read-accuracy.pl --inputfile /home/syoung/base/pipeline/human1-velvet/data/human1_sequence_in.ace \
--sequencedir /home/syoung/base/pipeline/human-eland-velvet/sequences


GET READ ALIGNMENT ACCURACIES FOR:

    1) ELAND ONLY READS

    2) VELVET ONLY READS

    3) READS INCORPORATED IN BOTH ELAND AND VELVET









(2) HUMAN 2 (LANES 1-3,5-8) ASSEMBLY OVERLAPS AGAINST cDNA (EMBL) - Eland versus Velvet
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

ELAND
=====

LOCATION:

cd /home/syoung/base/pipeline/human2-eland/assembly


RUN ELAND MULTI:

DO 1 OF 2: 

./eland.pl -i /home/syoung/base/pipeline/human2-eland/data/human2-1of2.fasta  -r /home/syoung/base/pipeline/human2-eland/data -o /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland-1of2.txt > /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland-1of2.log
    
    Eland: /usr/local/Pipeline/Eland/eland
    Output directory: /home/syoung/base/pipeline/human2-eland/assembly
    /usr/local/Pipeline/Eland/eland /home/syoung/base/pipeline/human2-eland/data/human2-1of2.fasta /home/syoung/base/pipeline/human2-eland/data /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland-1of2.txt --multi
    
    Run time: 00:12:51
    Completed ./eland.pl
    0:07AM, 16 December 2008
    # EXECUTED FULL COMMAND:
    # ./eland.pl -i /home/syoung/base/pipeline/human2-eland/data/human2-1of2.fasta -r /home/syoung/base/pipeline/human2-eland/data -o /home/syoung/base/pipeline/human2-eland/assembl\
    y/human2-cdna_embl-eland-1of2.txt
    ****************************************

    ELAND OUTPUT:

    ...
    Parsed offset=119327430, name=/ENST00000315492
    Parsed offset=119328819, name=/ENST00000366471
    Parsed offset=119330529, name=/ENST00000391820
    Parsed offset=119330987, name=/ENST00000329291
    Parsed offset=119332960, name=/ENST00000355360
    Outputting results: User: 0.367944s System: 1.84372s Actual: 3.48364s Efficiency: 63.4871%
    Info: 17915531 matches were stored
    Info: 71662124 bytes of temp storage used for oligo numbers
    Info: 71662124 bytes of temp storage used for match positions
    ... done User: 47.4918s System: 11.0143s Actual: 59.0701s Efficiency: 99.0452%
    Run complete! Time now: Tue Dec 16 00:07:42 2008


DO 2 OF 2:

./eland.pl \
    -i /home/syoung/base/pipeline/human2-eland/data/human2-2of2.fasta \
    -r /home/syoung/base/pipeline/human2-eland/data \
    -o /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland-2of2.txt \
    &> /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland-2of2.log


tail /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland-2of2.log

    Run time: 00:12:44
    Completed ./eland.pl
    0:09AM, 16 December 2008
    # EXECUTED FULL COMMAND:
    # ./eland.pl -i /home/syoung/base/pipeline/human2-eland/data/human2-2of2.fasta -r /home/syoung/base/pipeline/human2-eland/data -o /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland-2of2.txt
    ****************************************



./eland.pl -i /home/syoung/base/pipeline/human2-eland/data/human2_sequence_in.fasta \
            -r /home/syoung/base/pipeline/human2-eland/data \
            -o /home/syoung/base/pipeline/human-eland/assembly/human2-cdna_embl-eland.txt

*** ROUGHLY 10% OF READS HAVE UNIQUE HITS AGAINST THE cDNA REFERENCE ***

                Number reads       %
ALIGNED          3,209,719      10.049
NOT ALIGNED     28,729,599      89.951
TOTAL           31,939,318     100.000



LScd /home/syoung/base/pipeline/human2-eland/assembly
cat human2-cdna_embl-eland-contigs.solexa.fasta.1 human2-cdna_embl-eland-contigs.solexa.fasta.2 > human2-cdna_embl-eland.txt
cat human2-cdna_embl-eland.txt | grep NCBI36 > human2-cdna_embl-eland.hits
lines human2-cdna_embl-eland.hits
    3,209,719
lines human2-cdna_embl-eland.txt
    31,939,318




VELVET
======

LOCATION:

/home/syoung/base/pipeline/human1-velvet/assembly

RUN:

Notes-project02-ng_assembly.txt, P.178



1. GENERATE ELAND ALIGNMENT CONTIGS .gff FILE:

CONCENTRATE ALL HITS IN ONE FILE:

/home/syoung/base/pipeline/human2-eland/assembly

cat human2-cdna_embl-eland-contigs.solexa.fasta.1 human2-cdna_embl-eland-contigs.solexa.fasta.2 | grep NCBI36 > human2-cdna_embl-eland.txt





./eland2gff.pl \
    --inputfile /home/syoung/base/pipeline/human2-eland/assembly/human2-cdna_embl-eland.hits \
    --outputdir /home/syoung/base/pipeline/human2-eland/assembly/gff \
    --cdnadir /home/syoung/base/pipeline/human-cdna-embl/gff \
    --chromofile /home/syoung/base/pipeline/human-genome/chromosome_positions.txt \
    --readlength 34


SORT THE ELAND GFF FILE JUST IN CASE THE cDNAs WERE NOT IN THE RIGHT ORDER:

./sortgff.pl -i /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.gff \
            -o /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.sorted.gff

    Run time: 00:00:03
    Completed ./sortgff.pl
    10:39PM, 15 December 2008
    ****************************************

lines /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.gff
lines /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.sorted.gff

diff /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.gff /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.sorted.gff


head /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.sorted.gff

./elandgff2contig.pl  --inputdir /home/syoung/base/pipeline/human2-eland/assembly/gff \
                      --outputdir /home/syoung/base/pipeline/human2-eland/assembly/contig



2. COMPARE OVERLAPPING CONTIGS ALIGNED TO EACH CHROMOSOME


./comparegff.pl \
    --firstfile /home/syoung/base/pipeline/human-cdna-embl/gff/human-cdna-embl-chr2.gff  \
    --secondfile /home/syoung/base/pipeline/human2-eland/assembly/gff/human-cdna-embl-chr2.eland.sorted.gff  \
    --assemblynames cdna,eland \
    --outputdir /home/syoung/base/pipeline/human2-eland/assembly/compare 




3. CHECK COVERAGE DIFFERENCES BETWEEN OVERLAPPING AND NON-OVERLAPPING REGIONS







(2) ASSEMBLY CONSENSUS DIFFERENCES IN OVERLAPPING REGIONS (RESIDUES AND READS)








</entry>



<entry [Thu Sep 11 23:37:58 EDT 2008] USE dnadiff TO COMPARE ASSEMBLIES>



Genome assembly forensics: finding the elusive mis-assembly
Reviewed by Adam M Phillippy,1 Michael C Schatz,1 and Mihai Popcorresponding author1
Published online 2008 March 14

The Phrap assemblies were aligned against the reference sequences using the MUMmer utility dnadiff to collect regions of mis-assembly. dnadiff performs a whole-genome alignment and compactly summarizes the location and characteristics of differences between two contig sets (http://mummer.sourceforge.net).

TAKEN FROM:

To supplement the anecdotal results presented above, we have performed a systematic evaluation of assemblies using amosvalidate. Sequencing data for 16 bacterial genomes were collected and assembled with Phrap v0.990329 using the phrap.manyreads program with default parameters. Phrap was chosen because of its popularity, simplicity, and tendency to mis-assemble repetitive genomes. Similar experiments were attempted with Celera Assembler, but not enough mis-assemblies were produced to allow adequate validation. In larger genomes, Celera Assembler, and virtually all other assemblers, produce many errors; however, there are not enough fully finished eukaryotic genomes to allow comprehensive testing of our methods. For extensive and objective testing, bacteria were chosen as the assembly targets because many complete, finished genomes are available, thus providing a proper reference that can be used to identify true mis-assemblies.

The Phrap assemblies were aligned against the reference sequences using the MUMmer utility dnadiff to collect regions of mis-assembly. dnadiff performs a whole-genome alignment and compactly summarizes the location and characteristics of differences between two contig sets [45]. 

For aligning contigs to a reference genome, this process is identical to the read mapping discussed in the 'Read breakpoint analysis' section. Using the same algorithm, the contig set is mapped to the reference genome using nucmer, and the optimal mapping for each contig is identified. The alignment information is then parsed, and all alignment breakpoints are identified. By default, nucmer creates a contiguous alignment as long as the average nucleotide identity is greater than 70% for a 200 bp window; therefore, any stretch of greater than approximately 60 mis-matches will force the alignment to break. After alignment, the breakpoints are classified as insertions, deletions, rearrangements, or inversions based on their surrounding context. For example, a breakpoint between a forward-strand and negative-strand alignment on the same contig is classified as an inversion. For the Phrap contigs, only alignment differences that produced a breakpoint were considered as mis-assemblies. Small differences such as consensus SNPs, short indels (less than approximately 60 bp), and breakpoints occurring within the first 10 bp of a contig were ignored. All contigs less than 5,000 bp were also ignored because of their generally low quality.

amosvalidate was then run on all 16 Phrap assemblies to determine if the mis-assembled regions were correctly identified by our methods. Additional data file 1 lists the NCBI Taxonomy and RefSeq identifiers for the 16 reference genomes. Table 1 gives a summary of the Phrap induced mis-assemblies, along with statistics detailing the performance of amosvalidate. Table 2 gives specific details on the types of mis-assemblies introduced by Phrap, and the size characteristics of the amosvalidate features. Mis-joins (rearrangements) were the most prevalent type of mis-assembly reported by dnadiff.


</entry>



<entry [Fri Aug 15 02:45 EDT 2008] CREATED compare-gff-reference.pl TO COUNT EXONS IN COMMON BETWEEN TWO ASSEMBLIES ON A REFERENCE BACKBONE>



COMPARED: eland, velvet (run 1 - HUMAN 7 LANES)

REFERENCE: HUMAN cDNA GFF FILES

./compare-reference.pl -f /home/syoung/base/pipeline/human-eland/assembly/gff/human-cdna-embl-chr1.eland.gff -s /home/syoung/base/pipeline/human2-velvet/nucmer.whole-human/chromosome-gff/human-velvet-nucmer.chr1.gff -p eland,velvet -r /home/syoung/base/pipeline/human-cdna-embl/gff/human-cdna-embl-chr1.gff -o /home/syoung/base/pipeline/human-eland-velvet/comparison-eland-velvet



OUTPUT

    1. SET 1 - NO. OF HITS IN BOTH ASSEMBLY 1 AND ASSEMBLY 2
    2. SET 2 - NO. OF HITS IN ASSEMBLY 1 AND NOT IN ASSEMBLY 2
    3. SET 3 - NO. OF HITS IN ASSEMBLY 2 AND NOT IN ASSEMBLY 1
    4. SET 4 - NO. OF HITS IN EITHER ASSEMBLY 1 OR ASSEMBLY 2







</entry>



<entry [http://massgenomics.wordpress.com/2008/05/14/short-read-aligners-maq-eland-and-others/] HENG LI COMPARISON OF MAQ WITH ELAND, RMAP, SOAP AND SHRiMP>



COMMENTS
========

Sparks (Colin, Novocraft):

MAQ randomly chooses one alignment from a set of equal scoring alignments, which introduces some FP and some extra (random) TP.

ac:
We generally get around this by providing only uniquely aligned reads from Eland as input to MAQ. The obvious drawback to this is that you may be losing some reads. However, I haven’t seen any drop in depth beyond 1X unless it is a highly repetitive region. Fortunately we did see some FPs go away with this approach but does anyone see any drawbacks?

#  Justin Says:
May 18, 2008 at 9:26 pm

I am under the impression that the random assignment protocol in MAQ for repeats results in a lower mapping quality score for such assigned reads.

Can anyone here point me in a direction to understand how SNP calling is conditioned on mapping quality score for MAQ?

I couldn’t find it on the MAQ page.

ARTICLE
=======

Short Read Aligners: Maq, Eland, and Others

This month I’ve come across some interesting statistics on the performance of Maq, Eland, and other short-read alignment tools as applied to Illumina/Solexa data. I took note because these programs are finally being evaluated against appropriate data sets, as opposed to simulated reads or tiny genomes. First the disclaimers: all of these numbers came from people other than myself (see Credits, below), so please forgive any inaccuracies. Also, this entry reflects my personal second-hand impressions of the different alignment tools, and should not be considered an endorsement or criticism of the different alignment tools by the WashU GC.

Short-Read Data Sets at the WashU Genome Center

One of our data sets includes 100+ Solexa runs (non-paired) from the genomic DNA of a single individual. We’ve applied a number of alignment tools to these data: Eland (part of the Illumina suite), Maq (free/open source), SX Oligo Search (proprietary), SlimSearch (proprietary), and even BLAT. Our group (Medical Genomics) is currently leaning toward Maq for read mapping and SNP discovery purposes. There’s recently been a new release of Maq (0.6.5) which seems to run substantially faster:
Metric 	Maq 0.6.3 	Maq 0.6.5
Average alignment time for normal runs 	17.7 hours 	9.1 hours
Max alignment time for a normal run 	240 hours 	28.8 hours
Total number of jobs 	2168 	1467
Jobs that took longer than 1 day 	443 	3

The developer of Maq, Heng Li, presented a poster describing the Maq algorithm at CSHL last week and also gave a small workshop talk on issues in short read mapping. He sent these links out to the Maq user list along with a benchmarking comparison of various read mapping tools.

Heng Li’s Comparison of Short-Read Aligners

For the comparison, Heng generated 1 million simulated read-pairs from chromosome X. The numbers themselves are a bit mind-boggling, but fortunately he summarized the results with these notes:

    * Eland: eland is definitely the fastest, much faster than all the competitors. What is more important, eland gives the number of alternative places, which makes it possible for you to get further information about the repetitive structures of the genome and to select reads that can be really confidently mapped. In addition, with the help of additional scripts, Eland IS able to map reads longer than 32bp. Eland is one of the best software I ever used. It would be even superior if Tony could make it easier to use for a user, like me, who wants to run eland independently of the GAPipeline.

    * RMAP: the strength of rmap is to use base qualities to improve the alignment accuracy. I believe it can produce better alignment than maq -se because maq trades accuracy for speed at this point (technically it is a bit hard to explain here). Nonetheless, I think rmap would be more popular if its authors could add support for fastq-like quality string which is now the standard in both Illumina and the Sanger Institute (although maybe not elsewhere). rmap supports longer reads, which is also a gain. Furthermore, I did learn a lot from its way to count the number of mismatches.

    * SOAP: soap is a versatile program. It supports iterative-trimmed alignment, long reads, gapped alignment, TAG alignment and PE mode. Its PE mode is easier to use than eland. In principle, soap and eland should give almost the same number of wrong alignments. However, soap gives 442 more wrong alignments. Further investigation shows that most of these 442 wrong ones are flagged as R? (repeat) by eland.

    * SHRiMP: Actually I was not expecting that a program using seeding +Smith-Waterman could be that fast. So far as I know, all the other software in the list do not do Smith-Waterman (maq does for PE data only), which is why they are fast. SHRiMP’s normodds score has similar meaning to mapping quality. Such score helps to determine whether an alignment is reliable. The most obvious advantage is SHRiMP can map long reads (454/capillary) with the standard gapped alignment. If you only work with small genomes, SHRiMP is a worthy choice. I think SHRiMP would be better if it could make use of paired end information; it would be even better if it could calculate mapping quality. The current normodds score helps but is not exactly the mapping quality. In addition, I also modified probcalc codes because in 1.04 underflow may occur to long reads and leads to “nan” normodds. However, although my revision fixes the underflow, it may lead to some inaccurate normodds.

    * Maq: at the moment maq is easier to use than eland. Supporting SNP calling is maq’s huge gain. Its paired end mode is also highly helpful to recover some repetitive regions. Maq’s random mapping, which is frequently misused by users who have not noticed mapping qualities, may be useful to some people, too, and at least it helps to call SNPs at the verge of repeats.

What a nice guy! Here he is, comparing his own tool against several competitors and he manages to praise the strengths of each one. That takes humility.

More Comments from Heng Li

Ken Chen, a colleague of mine, happened to discuss the benchmarking with Heng at Cold Spring Harbor. According to his evaluation, the current version of recently-published SOAP may be somewhat buggy (it had more mapping errors and crashed on paired-end alignment), but is nevertheless promising because it supports gapped alignment and longer reads. Paired-end alignment is perhaps Maq’s greatest strength; the alignment error rate from Maq for paired-end data is significantly reduced. Heng also mentioned that the upcoming new release of Eland will support longer read lengths (>32 bp) and will also calculate mapping quality scores.

Unbiased Comparisons of Short-Read Aligners

In summary, there are a number of competing tools for short read alignment, each with its own set of strengths, weaknesses, and caveats. It’s hard to trust any benchmarking comparison on tools like these because usually, it’s the developers of one of the tools that publish them. Here’s an idea: what if NHGRI, Illumina, or another group put together a short-read-aligning contest? They generate a few short-read data sets: real, simulated, with/without errors, with/without SNPs and indels, etc. Then, the developers of each aligner are invited to throw their best efforts at it. Every group submits the results to a DCC, which analyzes the results in a simple, unbiased way: # of reads placed correctly/incorrectly. # of SNPs/indels detected, missed, or false-positives. The results are published on a web site or in the literature for all to see. Yeah, I know, there are hurdles, like the fact that most proprietary tool developers would probably chicken out of an unbiased head-to-head comparison, given the stakes. But wouldn’t it be nice to know the results? Unless that happens, however, I think Heng’s analysis is about as unbiased as can be.

Credits

WashU GC Maq version comparisons were sent out by Jim Eldred on 5/01/2008. Heng Li’s benchmarking comparison was sent to the Maq user list on 5/12/2008. Additional comments from Heng Li were reported by Ken Chen on 5/12/2008.



</entry>



<entry [Mon Aug 25 21:34:38 EDT 2008] ASSEMBLY TIMINGS>



mira
====

START
Localtime: Thu Jul  3 02:36:29 2008
END
Localtime: Thu Jul  3 08:39:08 2008

6:02 hours










++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

QUOTE FOR CLC BIO


From: Young, Stuart 
Sent: Monday, July 21, 2008 2:35 AM
To: Khuri, Sawsan
Subject: Next generation assemblers

Hi Sawsan,

It appears that neither the  ‘Genomics Workbench’ or ‘NextGene’ are quite what we’re looking for right now because they don’t perform well or at all when loaded with our most recent batch of human data using the Solexa sequencer. DNAStar releases the demo version of SMGA in a week or so’s time. It might be a good idea to wait until we can test SMGA before we purchase. 

I tried assembling one lane of Solexa data using CLC Bio’s ‘Genomics Workbench’ and SoftGenetics ‘NextGene’ but my laptop froze up in both cases. Genomics Workbench will do smaller data sets quite quickly and it has a nice GUI (graphical user interface). Genomics Workbench took 20 mins to do a reference sequence-based assembly and 200 mins to do a de novo respectively to finish the assembly. 

So neither of the two Windows-platform assemblers I’ve tried so far can assemble large numbers of sequences. But I’m wondering if the people who will use the assembly viewer may also want to use the other functions it has but it seems a lot to pay just for a nice UI.
 
I’ll run some more tests tomorrow and send you the details and comparisons between different assemblies. (I’ll also send you my bullets – I haven’t forgotten).

Cheers,


Stuart.



Genomics workbench
==================

-----Original Message-----
From: Rob Mervis [mailto:rmervis@clcbio.com] 
Sent: Thursday, July 10, 2008 10:19 AM
To: Young, Stuart
Subject: GWB Quote request from Suart Yong, University of Miami

Hi Stuart,

Thanks for your continued interest in the CLC Genomics Workbench.

As per your request below, I have attached 3 quotes;  for 1, 3, and 5 licenses of the Genomics Workbench Software.

Please note the discounts extended for each quantity.  The price breaks we offer that are applicable here are 25% off for quantities 2 - 4, and 35% off for quantities 5-9.  These discounts are applied to the already discounted Academic/Government/Non-profit list pricing of $4999 for a single license.


Please let me know if you have any questions.

Thanks again and best regards,

-Rob Mervis
